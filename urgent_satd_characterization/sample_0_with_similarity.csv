uuid,p_id,project,method,satd_type,start_line_before,end_line_before,start_line_after,end_line_after,comment,commit_before,commit_after,file_path,function_before,function_after,function_before_tokenized,function_after_tokenized,commit_before_time,commit_after_time,survive_time,similarity
158,626,https://www.github.com/apache/flume,toAcked(String),,69,69,72,72,"TODO (jon) this is fails most of the time, and is truly disgusting",https://www.github.com/apache/flume/commit/31ecbbf79,https://www.github.com/apache/flume/commit/7d346a15008ff90d839008d741b4cdb62a8e28f7,src/java/com/cloudera/flume/agent/FlumeNodeWALNotifier.java,"@Override
public void toAcked(String tag) throws IOException {
Map<String, WALManager> mp = node;
for (WALManager wm : mp.values()) {
try {
wm.toAcked(tag);
} catch (IOException ioe) {
// TODO (jon) this is fails most of the time, and is truly disgusting
LOG.info(""Wrong wal manager"" + wm + "" for tag "" + tag);
}
}
}","@Override
public void toAcked(String tag) throws IOException {
Map<String, WALManager> mp = node;
int success = 0;
for (WALManager wm : mp.values()) {
try {
wm.toAcked(tag);
success++;
} catch (IOException ioe) {
// eat it.
}
}
if (success == 0) {
// this is an odd situation
LOG.warn(""No wal managers contained tag "" + tag);
}
if (success > 1) {
// this is weird too
LOG.warn(""Expected exactly one wal manager to contain tag "" + tag
+ "" but "" + success + ""did!"");
}
}","@ Override public void toAcked  ( String tag ) throws IOException { Map < String , WALManager > mp = node ; for ( WALManager wm : mp . values ( ) ) { try { wm . toAcked ( tag ) ; } catch ( IOException ioe ) { // <SATD_START> TODO (jon) this is fails most of the time, and is truly disgusting <SATD_END> LOG . info ( "" Wrong wal manager "" + wm + ""  for tag  "" + tag ) ; } } }","@ Override public void toAcked  ( String tag ) throws IOException { Map < String , WALManager > mp = node ; int success = 0 ; for ( WALManager wm : mp . values ( ) ) { try { wm . toAcked ( tag ) ; success ++ ; } catch ( IOException ioe ) { // eat it. } } if ( success == 0 ) { // this is an odd situation LOG . warn ( "" No wal managers contained tag  "" + tag ) ; } if ( success > 1 ) { // this is weird too LOG . warn ( "" Expected exactly one wal manager to contain tag  "" + tag + ""  but  "" + success + "" did! "" ) ; } }",2011-08-02 16:03:58 +0000,2011-08-02 16:04:16 +0000,0,0.5531914893617021
748,48,https://www.github.com/apache/cassandra,onStart(),,202,202,202,202,"TODO this seems unnecessary -- each memtable flush checks to see if it needs to compact, too",https://www.github.com/apache/cassandra/commit/a1ef3b5be5b,https://www.github.com/apache/cassandra/commit/064a59cdb00361c6b92ce098922b87357cae7736,src/java/org/apache/cassandra/db/ColumnFamilyStore.java,"void onStart() throws IOException
{
/* Do major compaction */
List<File> sstableFiles = new ArrayList<File>();
String[] dataFileDirectories = DatabaseDescriptor.getAllDataFileLocations();
for (String directory : dataFileDirectories)
{
File fileDir = new File(directory);
File[] files = fileDir.listFiles();
for (File file : files)
{
String filename = file.getName();
if (((file.length() == 0) || (filename.contains(""-"" + SSTable.temporaryFile_))) && (filename.contains(columnFamily_)))
{
file.delete();
continue;
}
String[] tblCfName = getTableAndColumnFamilyName(filename);
if (tblCfName[0].equals(table_)
&& tblCfName[1].equals(columnFamily_)
&& filename.contains(""-Data.db""))
{
sstableFiles.add(file.getAbsoluteFile());
}
}
}
Collections.sort(sstableFiles, new FileUtils.FileComparator());
List<String> filenames = new ArrayList<String>();
for (File ssTable : sstableFiles)
{
filenames.add(ssTable.getAbsolutePath());
}
/* Load the index files and the Bloom Filters associated with them. */
for (String filename : filenames)
{
try
            {
SSTable sstable = SSTable.open(filename, StorageService.getPartitioner());
ssTables_.put(filename, sstable);
}
catch (IOException ex)
{
logger_.info(""Deleting corrupted file "" + filename);
FileUtils.delete(filename);
logger_.warn(LogUtil.throwableToString(ex));
}
}
MinorCompactionManager.instance().submit(ColumnFamilyStore.this);
if (table_.equals(Table.SYSTEM_TABLE) && columnFamily_.equals(HintedHandOffManager.HINTS_CF))
{
HintedHandOffManager.instance().submit(this);
}
// TODO this seems unnecessary -- each memtable flush checks to see if it needs to compact, too
MinorCompactionManager.instance().submitPeriodicCompaction(this);
/* submit periodic flusher if required */
int flushPeriod = DatabaseDescriptor.getFlushPeriod(table_, columnFamily_);
if (flushPeriod > 0)
{
PeriodicFlushManager.instance().submitPeriodicFlusher(this, flushPeriod);
}
}","void onStart() throws IOException
{
// scan for data files corresponding to this CF
List<File> sstableFiles = new ArrayList<File>();
String[] dataFileDirectories = DatabaseDescriptor.getAllDataFileLocations();
for (String directory : dataFileDirectories)
{
File fileDir = new File(directory);
File[] files = fileDir.listFiles();
for (File file : files)
{
String filename = file.getName();
if (((file.length() == 0) || (filename.contains(""-"" + SSTable.temporaryFile_))) && (filename.contains(columnFamily_)))
{
file.delete();
continue;
}
String[] tblCfName = getTableAndColumnFamilyName(filename);
if (tblCfName[0].equals(table_)
&& tblCfName[1].equals(columnFamily_)
&& filename.contains(""-Data.db""))
{
sstableFiles.add(file.getAbsoluteFile());
}
}
}
Collections.sort(sstableFiles, new FileUtils.FileComparator());
/* Load the index files and the Bloom Filters associated with them. */
for (File file : sstableFiles)
{
String filename = file.getAbsolutePath();
try
            {
SSTable sstable = SSTable.open(filename, StorageService.getPartitioner());
ssTables_.put(filename, sstable);
}
catch (IOException ex)
{
logger_.error(""Corrupt file "" + filename, ex);
FileUtils.delete(filename);
}
}
// submit initial check-for-compaction request
MinorCompactionManager.instance().submit(ColumnFamilyStore.this);
// schedule hinted handoff
if (table_.equals(Table.SYSTEM_TABLE) && columnFamily_.equals(HintedHandOffManager.HINTS_CF))
{
HintedHandOffManager.instance().submit(this);
}
// schedule periodic flusher if required
int flushPeriod = DatabaseDescriptor.getFlushPeriod(table_, columnFamily_);
if (flushPeriod > 0)
{
PeriodicFlushManager.instance().submitPeriodicFlusher(this, flushPeriod);
}
}","void onStart  ( ) throws IOException  { /* Do major compaction */ List < File > sstableFiles = new ArrayList < File > ( ) ; String [ ] dataFileDirectories = DatabaseDescriptor . getAllDataFileLocations ( ) ; for ( String directory : dataFileDirectories ) { File fileDir = new File ( directory ) ; File [ ] files = fileDir . listFiles ( ) ; for ( File file : files ) { String filename = file . getName ( ) ; if ( ( ( file . length ( ) == 0 ) || ( filename . contains ( "" - "" + SSTable . temporaryFile_ ) ) ) && ( filename . contains ( columnFamily_ ) ) ) { file . delete ( ) ; continue ; } String [ ] tblCfName = getTableAndColumnFamilyName ( filename ) ; if ( tblCfName [ 0 ] . equals ( table_ ) && tblCfName [ 1 ] . equals ( columnFamily_ ) && filename . contains ( "" -Data.db "" ) ) { sstableFiles . add ( file . getAbsoluteFile ( ) ) ; } } } Collections . sort ( sstableFiles , new FileUtils . FileComparator ( ) ) ; List < String > filenames = new ArrayList < String > ( ) ; for ( File ssTable : sstableFiles ) { filenames . add ( ssTable . getAbsolutePath ( ) ) ; } /* Load the index files and the Bloom Filters associated with them. */ for ( String filename : filenames ) { try { SSTable sstable = SSTable . open ( filename , StorageService . getPartitioner ( ) ) ; ssTables_ . put ( filename , sstable ) ; } catch ( IOException ex ) { logger_ . info ( "" Deleting corrupted file  "" + filename ) ; FileUtils . delete ( filename ) ; logger_ . warn ( LogUtil . throwableToString ( ex ) ) ; } } MinorCompactionManager . instance ( ) . submit ( ColumnFamilyStore . this ) ; if ( table_ . equals ( Table . SYSTEM_TABLE ) && columnFamily_ . equals ( HintedHandOffManager . HINTS_CF ) ) { HintedHandOffManager . instance ( ) . submit ( this ) ; } // <SATD_START> TODO this seems unnecessary -- each memtable flush checks to see if it needs to compact, too <SATD_END> MinorCompactionManager . instance ( ) . submitPeriodicCompaction ( this ) ; /* submit periodic flusher if required */ int flushPeriod = DatabaseDescriptor . getFlushPeriod ( table_ , columnFamily_ ) ; if ( flushPeriod > 0 ) { PeriodicFlushManager . instance ( ) . submitPeriodicFlusher ( this , flushPeriod ) ; } }","void onStart  ( ) throws IOException  { // scan for data files corresponding to this CF List < File > sstableFiles = new ArrayList < File > ( ) ; String [ ] dataFileDirectories = DatabaseDescriptor . getAllDataFileLocations ( ) ; for ( String directory : dataFileDirectories ) { File fileDir = new File ( directory ) ; File [ ] files = fileDir . listFiles ( ) ; for ( File file : files ) { String filename = file . getName ( ) ; if ( ( ( file . length ( ) == 0 ) || ( filename . contains ( "" - "" + SSTable . temporaryFile_ ) ) ) && ( filename . contains ( columnFamily_ ) ) ) { file . delete ( ) ; continue ; } String [ ] tblCfName = getTableAndColumnFamilyName ( filename ) ; if ( tblCfName [ 0 ] . equals ( table_ ) && tblCfName [ 1 ] . equals ( columnFamily_ ) && filename . contains ( "" -Data.db "" ) ) { sstableFiles . add ( file . getAbsoluteFile ( ) ) ; } } } Collections . sort ( sstableFiles , new FileUtils . FileComparator ( ) ) ; /* Load the index files and the Bloom Filters associated with them. */ for ( File file : sstableFiles ) { String filename = file . getAbsolutePath ( ) ; try { SSTable sstable = SSTable . open ( filename , StorageService . getPartitioner ( ) ) ; ssTables_ . put ( filename , sstable ) ; } catch ( IOException ex ) { logger_ . error ( "" Corrupt file  "" + filename , ex ) ; FileUtils . delete ( filename ) ; } } // submit initial check-for-compaction request MinorCompactionManager . instance ( ) . submit ( ColumnFamilyStore . this ) ; // schedule hinted handoff if ( table_ . equals ( Table . SYSTEM_TABLE ) && columnFamily_ . equals ( HintedHandOffManager . HINTS_CF ) ) { HintedHandOffManager . instance ( ) . submit ( this ) ; } // schedule periodic flusher if required int flushPeriod = DatabaseDescriptor . getFlushPeriod ( table_ , columnFamily_ ) ; if ( flushPeriod > 0 ) { PeriodicFlushManager . instance ( ) . submitPeriodicFlusher ( this , flushPeriod ) ; } }",2009-04-14 05:12:42 +0000,2009-06-24 19:25:21 +0000,0,0.8372889650110105
2362,84,https://www.github.com/apache/openjpa,setUp(),,38,38,39,42,TODO: Delimiter support is limited to,https://www.github.com/apache/openjpa/commit/cafbd559d2,https://www.github.com/apache/openjpa/commit/5f03f77b5c07befba4c4545d1ec91023ef76e3b5,openjpa-persistence-jdbc/src/test/java/org/apache/openjpa/persistence/delimited/identifiers/noschema/TestNoSchemaManualDelimIdSeqGen.java,"@Override
public void setUp() throws Exception {
// TODO: Delimiter support is limited to 
setUnsupportedDatabases(MySQLDictionary.class);
if (isTestsDisabled())
return;
super.setUp(EntityE.class,DROP_TABLES);
assertNotNull(emf);
conf = (JDBCConfiguration) emf.getConfiguration();
dict = conf.getDBDictionaryInstance();
supportsNativeSequence = dict.nextSequenceQuery != null;
if (supportsNativeSequence) {
em = emf.createEntityManager();
assertNotNull(em);
}
}","@Override
public void setUp() throws Exception {
// TODO: Delimiter support is currently limited to database that use
// double quote as a delimiter.
// Also Disabling DB2 until a SQLCODE -204 issue during the cleanup phase 
// is resolved.
setUnsupportedDatabases(MySQLDictionary.class, DB2Dictionary.class);
if (isTestsDisabled())
return;
super.setUp(EntityE.class); //,DROP_TABLES);
assertNotNull(emf);
conf = (JDBCConfiguration) emf.getConfiguration();
dict = conf.getDBDictionaryInstance();
supportsNativeSequence = dict.nextSequenceQuery != null;
if (supportsNativeSequence) {
em = emf.createEntityManager();
assertNotNull(em);
}
}","@ Override public void setUp  ( ) throws Exception  { // <SATD_START> TODO: Delimiter support is limited to <SATD_END>  setUnsupportedDatabases ( MySQLDictionary . class ) ; if ( isTestsDisabled ( ) ) return ; super . setUp ( EntityE . class , DROP_TABLES ) ; assertNotNull ( emf ) ; conf = ( JDBCConfiguration ) emf . getConfiguration ( ) ; dict = conf . getDBDictionaryInstance ( ) ; supportsNativeSequence = dict . nextSequenceQuery != null ; if ( supportsNativeSequence ) { em = emf . createEntityManager ( ) ; assertNotNull ( em ) ; } }","@ Override public void setUp  ( ) throws Exception  { // TODO: Delimiter support is currently limited to database that use // double quote as a delimiter. // Also Disabling DB2 until a SQLCODE -204 issue during the cleanup phase  // is resolved. setUnsupportedDatabases ( MySQLDictionary . class , DB2Dictionary . class ) ; if ( isTestsDisabled ( ) ) return ; super . setUp ( EntityE . class ) ; //,DROP_TABLES); assertNotNull ( emf ) ; conf = ( JDBCConfiguration ) emf . getConfiguration ( ) ; dict = conf . getDBDictionaryInstance ( ) ; supportsNativeSequence = dict . nextSequenceQuery != null ; if ( supportsNativeSequence ) { em = emf . createEntityManager ( ) ; assertNotNull ( em ) ; } }",2009-09-25 20:15:12 +0000,2009-09-26 01:12:53 +0000,0,0.7708502024291498
3295,156,https://www.github.com/felixb/websms,changeConnectorMenu(),NOT_DESIGN,1045,1045,1045,1045,TODO: Can String name be empty here?,https://www.github.com/felixb/websms/commit/7d74316f4,https://www.github.com/felixb/websms/commit/9b9d28bab0fcd1363c3d54686abbe6747c80b202,src/de/ub0r/android/websms/WebSMS.java,"private void changeConnectorMenu() {
AlertDialog.Builder builder = new AlertDialog.Builder(this);
builder.setIcon(android.R.drawable.ic_menu_share);
builder.setTitle(R.string.change_connector_);
final ArrayList<String> items = new ArrayList<String>();
final ConnectorSpec[] css = getConnectors(
				ConnectorSpec.CAPABILITIES_SEND, ConnectorSpec.STATUS_ENABLED);
SubConnectorSpec[] scs;
String n;
for (ConnectorSpec cs : css) {
scs = cs.getSubConnectors();
if (scs.length <= 1) {
items.add(cs.getName());
} else {
n = cs.getName() + "" - "";
for (SubConnectorSpec sc : scs) {
items.add(n + sc.getName());
}
}
}
scs = null;
n = null;
String name = """";
if (items.size() == 0) {
Toast.makeText(this, R.string.log_noreadyconnector,
					Toast.LENGTH_LONG).show();
} else if (items.size() == 1) {
name = css[0].getName();
}
if (items.size() == 2) {
// Find actual connector, pick the other one from css
if (css[0].getName().equals(prefsConnectorSpec.getName())) {
name = css[1].getName();
} else if (css[1].getName().equals(prefsConnectorSpec.getName())) {
name = css[0].getName();
}
} else {
builder.setItems(items.toArray(new String[0]),
					new DialogInterface.OnClickListener() {
						public void onClick(final DialogInterface d, // .
final int item) {
final SubConnectorSpec[] ret = ConnectorSpec
.getSubConnectorReturnArray();
prefsConnectorSpec = getConnectorByName(items
.get(item), ret);
prefsSubConnectorSpec = ret[0];
WebSMS.this.setButtons();
// save user preferences
final Editor e = PreferenceManager
.getDefaultSharedPreferences(WebSMS.this)
.edit();
e.putString(PREFS_CONNECTOR_ID, prefsConnectorSpec
.getPackage());
e.putString(PREFS_SUBCONNECTOR_ID,
									prefsSubConnectorSpec.getID());
e.commit();
}
					});
builder.create().show();
return;
}
// TODO: Can String name be empty here?
final SubConnectorSpec[] ret = ConnectorSpec
.getSubConnectorReturnArray();
prefsConnectorSpec = getConnectorByName(name, ret);
prefsSubConnectorSpec = ret[0];
WebSMS.this.setButtons();
// save user preferences
final Editor e = PreferenceManager.getDefaultSharedPreferences(
				WebSMS.this).edit();
e.putString(PREFS_CONNECTOR_ID, prefsConnectorSpec.getPackage());
e.putString(PREFS_SUBCONNECTOR_ID, prefsSubConnectorSpec.getID());
e.commit();
}","private void changeConnectorMenu() {
AlertDialog.Builder builder = new AlertDialog.Builder(this);
builder.setIcon(android.R.drawable.ic_menu_share);
builder.setTitle(R.string.change_connector_);
final ArrayList<String> items = new ArrayList<String>();
final ConnectorSpec[] css = getConnectors(
				ConnectorSpec.CAPABILITIES_SEND, ConnectorSpec.STATUS_ENABLED);
SubConnectorSpec[] scs;
String n;
for (ConnectorSpec cs : css) {
scs = cs.getSubConnectors();
if (scs.length <= 1) {
items.add(cs.getName());
} else {
n = cs.getName() + "" - "";
for (SubConnectorSpec sc : scs) {
items.add(n + sc.getName());
}
}
}
scs = null;
n = null;
String name = """";
if (items.size() == 0) {
Toast.makeText(this, R.string.log_noreadyconnector,
					Toast.LENGTH_LONG).show();
} else if (items.size() == 1) {
name = css[0].getName();
}
if (items.size() == 2) {
// Find actual connector, pick the other one from css
if (css[0].getName().equals(prefsConnectorSpec.getName())) {
name = css[1].getName();
} else if (css[1].getName().equals(prefsConnectorSpec.getName())) {
name = css[0].getName();
}
this.saveSelectedConnector(name);
} else {
builder.setItems(items.toArray(new String[0]),
					new DialogInterface.OnClickListener() {
						public void onClick(final DialogInterface d, // .
final int item) {
final SubConnectorSpec[] ret = ConnectorSpec
.getSubConnectorReturnArray();
WebSMS.this.saveSelectedConnector(items.get(item));
}
					});
builder.create().show();
return;
}
}","private void changeConnectorMenu  ( ) { AlertDialog . Builder builder = new AlertDialog . Builder ( this ) ; builder . setIcon ( android . R . drawable . ic_menu_share ) ; builder . setTitle ( R . string . change_connector_ ) ; final ArrayList < String > items = new ArrayList < String > ( ) ; final ConnectorSpec [ ] css = getConnectors ( ConnectorSpec . CAPABILITIES_SEND , ConnectorSpec . STATUS_ENABLED ) ; SubConnectorSpec [ ] scs ; String n ; for ( ConnectorSpec cs : css ) { scs = cs . getSubConnectors ( ) ; if ( scs . length <= 1 ) { items . add ( cs . getName ( ) ) ; } else { n = cs . getName ( ) + ""  -  "" ; for ( SubConnectorSpec sc : scs ) { items . add ( n + sc . getName ( ) ) ; } } } scs = null ; n = null ; String name = "" "" ; if ( items . size ( ) == 0 ) { Toast . makeText ( this , R . string . log_noreadyconnector , Toast . LENGTH_LONG ) . show ( ) ; } else if ( items . size ( ) == 1 ) { name = css [ 0 ] . getName ( ) ; } if ( items . size ( ) == 2 ) { // Find actual connector, pick the other one from css if ( css [ 0 ] . getName ( ) . equals ( prefsConnectorSpec . getName ( ) ) ) { name = css [ 1 ] . getName ( ) ; } else if ( css [ 1 ] . getName ( ) . equals ( prefsConnectorSpec . getName ( ) ) ) { name = css [ 0 ] . getName ( ) ; } } else { builder . setItems ( items . toArray ( new String [ 0 ] ) , new DialogInterface . OnClickListener ( ) { public void onClick ( final DialogInterface d , // . final int item ) { final SubConnectorSpec [ ] ret = ConnectorSpec . getSubConnectorReturnArray ( ) ; prefsConnectorSpec = getConnectorByName ( items . get ( item ) , ret ) ; prefsSubConnectorSpec = ret [ 0 ] ; WebSMS . this . setButtons ( ) ; // save user preferences final Editor e = PreferenceManager . getDefaultSharedPreferences ( WebSMS . this ) . edit ( ) ; e . putString ( PREFS_CONNECTOR_ID , prefsConnectorSpec . getPackage ( ) ) ; e . putString ( PREFS_SUBCONNECTOR_ID , prefsSubConnectorSpec . getID ( ) ) ; e . commit ( ) ; } } ) ; builder . create ( ) . show ( ) ; return ; } // <SATD_START> TODO: Can String name be empty here? <SATD_END> final SubConnectorSpec [ ] ret = ConnectorSpec . getSubConnectorReturnArray ( ) ; prefsConnectorSpec = getConnectorByName ( name , ret ) ; prefsSubConnectorSpec = ret [ 0 ] ; WebSMS . this . setButtons ( ) ; // save user preferences final Editor e = PreferenceManager . getDefaultSharedPreferences ( WebSMS . this ) . edit ( ) ; e . putString ( PREFS_CONNECTOR_ID , prefsConnectorSpec . getPackage ( ) ) ; e . putString ( PREFS_SUBCONNECTOR_ID , prefsSubConnectorSpec . getID ( ) ) ; e . commit ( ) ; }","private void changeConnectorMenu  ( ) { AlertDialog . Builder builder = new AlertDialog . Builder ( this ) ; builder . setIcon ( android . R . drawable . ic_menu_share ) ; builder . setTitle ( R . string . change_connector_ ) ; final ArrayList < String > items = new ArrayList < String > ( ) ; final ConnectorSpec [ ] css = getConnectors ( ConnectorSpec . CAPABILITIES_SEND , ConnectorSpec . STATUS_ENABLED ) ; SubConnectorSpec [ ] scs ; String n ; for ( ConnectorSpec cs : css ) { scs = cs . getSubConnectors ( ) ; if ( scs . length <= 1 ) { items . add ( cs . getName ( ) ) ; } else { n = cs . getName ( ) + ""  -  "" ; for ( SubConnectorSpec sc : scs ) { items . add ( n + sc . getName ( ) ) ; } } } scs = null ; n = null ; String name = "" "" ; if ( items . size ( ) == 0 ) { Toast . makeText ( this , R . string . log_noreadyconnector , Toast . LENGTH_LONG ) . show ( ) ; } else if ( items . size ( ) == 1 ) { name = css [ 0 ] . getName ( ) ; } if ( items . size ( ) == 2 ) { // Find actual connector, pick the other one from css if ( css [ 0 ] . getName ( ) . equals ( prefsConnectorSpec . getName ( ) ) ) { name = css [ 1 ] . getName ( ) ; } else if ( css [ 1 ] . getName ( ) . equals ( prefsConnectorSpec . getName ( ) ) ) { name = css [ 0 ] . getName ( ) ; } this . saveSelectedConnector ( name ) ; } else { builder . setItems ( items . toArray ( new String [ 0 ] ) , new DialogInterface . OnClickListener ( ) { public void onClick ( final DialogInterface d , // . final int item ) { final SubConnectorSpec [ ] ret = ConnectorSpec . getSubConnectorReturnArray ( ) ; WebSMS . this . saveSelectedConnector ( items . get ( item ) ) ; } } ) ; builder . create ( ) . show ( ) ; return ; } }",2010-05-23 13:00:38 +0200,2010-05-23 13:09:50 +0200,0,0.7204678362573099
30,570,https://www.github.com/broadgsa/gatk,addGenotypeCall(GenotypeCall),,114,114,114,114,TODO: fix me aaron,https://www.github.com/broadgsa/gatk/commit/9cd53d3273,https://www.github.com/broadgsa/gatk/commit/0087234ed72fcf4230002ba2fafb23f503521ce5,java/src/org/broadinstitute/sting/utils/genotype/glf/GLFWriter.java,"@Override
public void addGenotypeCall(GenotypeCall locus) {
SSGGenotypeCall call = (SSGGenotypeCall)locus;
LikelihoodObject obj = new LikelihoodObject(call.getLikelihoods(), LikelihoodObject.LIKELIHOOD_TYPE.LOG);
// TODO: fix me aaron
this.addGenotypeCall(GenomeLocParser.getContigInfo(locus.getLocation().getContig()),(int)locus.getLocation().getStart(),(float)0.0,locus.getReferencebase(),0,obj);
}","@Override
public void addGenotypeCall(GenotypeCall locus) {
SSGGenotypeCall call = (SSGGenotypeCall)locus;
LikelihoodObject obj = new LikelihoodObject(call.getLikelihoods(), LikelihoodObject.LIKELIHOOD_TYPE.LOG);
obj.setLikelihoodType(LikelihoodObject.LIKELIHOOD_TYPE.NEGITIVE_LOG); // transform! ... to negitive log likelihoods
this.addGenotypeCall(GenomeLocParser.getContigInfo(locus.getLocation().getContig()),(int)locus.getLocation().getStart(),(float)0.0,locus.getReferencebase(),0,obj);
}","@ Override public void addGenotypeCall  ( GenotypeCall locus ) { SSGGenotypeCall call = ( SSGGenotypeCall ) locus ; LikelihoodObject obj = new LikelihoodObject ( call . getLikelihoods ( ) , LikelihoodObject . LIKELIHOOD_TYPE . LOG ) ; // <SATD_START> TODO: fix me aaron <SATD_END> this . addGenotypeCall ( GenomeLocParser . getContigInfo ( locus . getLocation ( ) . getContig ( ) ) , ( int ) locus . getLocation ( ) . getStart ( ) , ( float ) 0.0 , locus . getReferencebase ( ) , 0 , obj ) ; }","@ Override public void addGenotypeCall  ( GenotypeCall locus ) { SSGGenotypeCall call = ( SSGGenotypeCall ) locus ; LikelihoodObject obj = new LikelihoodObject ( call . getLikelihoods ( ) , LikelihoodObject . LIKELIHOOD_TYPE . LOG ) ; obj . setLikelihoodType ( LikelihoodObject . LIKELIHOOD_TYPE . NEGITIVE_LOG ) ; // transform! ... to negitive log likelihoods this . addGenotypeCall ( GenomeLocParser . getContigInfo ( locus . getLocation ( ) . getContig ( ) ) , ( int ) locus . getLocation ( ) . getStart ( ) , ( float ) 0.0 , locus . getReferencebase ( ) , 0 , obj ) ; }",2009-07-30 07:04:05 +0000,2009-07-30 19:47:37 +0000,0,0.48405253283302063
1205,340,https://www.github.com/jenkinsci/promoted-builds-plugin,getJobs(),NOT_DESIGN,120,120,120,120,TODO: implement this method later,https://www.github.com/jenkinsci/promoted-builds-plugin/commit/9445a833,https://www.github.com/jenkinsci/promoted-builds-plugin/commit/a70c2dc22776b51b46d0eca6d855a385b61c2bb1,src/main/java/hudson/plugins/promoted_builds/conditions/DownstreamPassCondition.java,"@Override
public void onCompleted(AbstractBuild<?,?> build, TaskListener listener) {
// this is not terribly efficient,
for(AbstractProject<?,?> j : Hudson.getInstance().getAllItems(AbstractProject.class)) {
JobPropertyImpl p = j.getProperty(JobPropertyImpl.class);
if(p!=null) {
for (PromotionCriterion c : p.getCriteria()) {
for (PromotionCondition cond : c.getConditions()) {
if (cond instanceof DownstreamPassCondition) {
DownstreamPassCondition dpcond = (DownstreamPassCondition) cond;
if(dpcond.contains(build.getParent()))
// TODO: implement this method later
throw new UnsupportedOperationException();
}
}
}
}
}
}","@Override
public void onCompleted(AbstractBuild<?,?> build, TaskListener listener) {
// this is not terribly efficient,
for(AbstractProject<?,?> j : Hudson.getInstance().getAllItems(AbstractProject.class)) {
JobPropertyImpl p = j.getProperty(JobPropertyImpl.class);
if(p!=null) {
for (PromotionCriterion c : p.getCriteria()) {
boolean considerPromotion = false;
for (PromotionCondition cond : c.getConditions()) {
if (cond instanceof DownstreamPassCondition) {
DownstreamPassCondition dpcond = (DownstreamPassCondition) cond;
if(dpcond.contains(build.getParent()))
considerPromotion = true;
}
}
if(considerPromotion) {
try {
c.considerPromotion(build);
} catch (IOException e) {
e.printStackTrace(listener.error(""Failed to promote a build""));
}
}
}
}
}
}","@ Override public void onCompleted  ( AbstractBuild < ? , ? > build , TaskListener listener ) { // this is not terribly efficient, for ( AbstractProject < ? , ? > j : Hudson . getInstance ( ) . getAllItems ( AbstractProject . class ) ) { JobPropertyImpl p = j . getProperty ( JobPropertyImpl . class ) ; if ( p != null ) { for ( PromotionCriterion c : p . getCriteria ( ) ) { for ( PromotionCondition cond : c . getConditions ( ) ) { if ( cond instanceof DownstreamPassCondition ) { DownstreamPassCondition dpcond = ( DownstreamPassCondition ) cond ; if ( dpcond . contains ( build . getParent ( ) ) ) // <SATD_START> TODO: implement this method later <SATD_END> throw new UnsupportedOperationException ( ) ; } } } } } }","@ Override public void onCompleted  ( AbstractBuild < ? , ? > build , TaskListener listener ) { // this is not terribly efficient, for ( AbstractProject < ? , ? > j : Hudson . getInstance ( ) . getAllItems ( AbstractProject . class ) ) { JobPropertyImpl p = j . getProperty ( JobPropertyImpl . class ) ; if ( p != null ) { for ( PromotionCriterion c : p . getCriteria ( ) ) { boolean considerPromotion = false ; for ( PromotionCondition cond : c . getConditions ( ) ) { if ( cond instanceof DownstreamPassCondition ) { DownstreamPassCondition dpcond = ( DownstreamPassCondition ) cond ; if ( dpcond . contains ( build . getParent ( ) ) ) considerPromotion = true ; } } if ( considerPromotion ) { try { c . considerPromotion ( build ) ; } catch ( IOException e ) { e . printStackTrace ( listener . error ( "" Failed to promote a build "" ) ) ; } } } } } }",2007-10-02 00:42:54 +0000,2007-10-05 18:50:19 +0000,0,0.8002544529262087
2201,667,https://www.github.com/t-oster/visicut,mouseDragged(MouseEvent),,490,490,490,490,TODO: Make sure the bounds of EditRect don't exceed the workspace,https://www.github.com/t-oster/visicut/commit/014e2f15d,https://www.github.com/t-oster/visicut/commit/d12fcf5661ab6415d96175d450b89b4adbda5861,src/com/t_oster/visicut/gui/PreviewPanelKeyboardMouseHandler.java,"public void mouseDragged(MouseEvent evt)
{
if (lastMousePosition != null)
{
Point diff = new Point(evt.getPoint().x - lastMousePosition.x, evt.getPoint().y - lastMousePosition.y);
try
      {
switch (currentAction)
{
case rotatingSet:
{
Rectangle2D bb = getGraphicObjects().getBoundingBox();
Point2D middle = new Point.Double(bb.getCenterX(), bb.getCenterY());
//move back
AffineTransform tr = AffineTransform.getTranslateInstance(middle.getX(), middle.getY());
//rotate
tr.concatenate(AffineTransform.getRotateInstance(1.0 / 100 * Math.max(diff.x, diff.y)));
//center
tr.concatenate(AffineTransform.getTranslateInstance(-middle.getX(), -middle.getY()));
//apply current
tr.concatenate(getGraphicObjects().transform);
getGraphicObjects().setTransform(tr);
this.previewPanel.repaint();
break;
}
case resizingSet:
{
this.previewPanel.getMmToPxTransform().createInverse().deltaTransform(diff, diff);
switch (currentButton)
{
case BOTTOM_RIGHT:
{
int offset = Math.abs(diff.x) > Math.abs(diff.y) ? diff.x : diff.y;
getEditRect().height += (offset * getEditRect().height / getEditRect().width);
getEditRect().width += offset;
break;
}
case BOTTOM_LEFT:
{
int offset = Math.abs(diff.x) > Math.abs(diff.y) ? diff.x : diff.y;
getEditRect().height -= (offset * getEditRect().height / getEditRect().width);
getEditRect().x += offset;
getEditRect().width -= offset;
break;
}
case TOP_RIGHT:
{
int offset = Math.abs(diff.x) > Math.abs(diff.y) ? diff.x : -diff.y;
getEditRect().y -= (offset * getEditRect().height / getEditRect().width);
getEditRect().height += (offset * getEditRect().height / getEditRect().width);
getEditRect().width += offset;
break;
}
case TOP_LEFT:
{
int offset = Math.abs(diff.x) > Math.abs(diff.y) ? diff.x : diff.y;
getEditRect().y += (offset * getEditRect().height / getEditRect().width);
getEditRect().height -= (offset * getEditRect().height / getEditRect().width);
getEditRect().x += offset;
getEditRect().width -= offset;
break;
}
case CENTER_RIGHT:
{
this.getEditRect().width += diff.x;
break;
}
case TOP_CENTER:
{
this.getEditRect().y += diff.y;
this.getEditRect().height -= diff.y;
break;
}
case BOTTOM_CENTER:
{
this.getEditRect().height += diff.y;
break;
}
case CENTER_LEFT:
{
this.getEditRect().x += diff.x;
this.getEditRect().width -= diff.x;
break;
}
}
//TODO: Make sure the bounds of EditRect don't exceed the workspace
this.previewPanel.setEditRectangle(getEditRect());
break;
}
case movingSet:
{
AffineTransform tr = this.previewPanel.getMmToPxTransform();
Point2D.Double d = new Point2D.Double(diff.x, diff.y);
tr.createInverse().deltaTransform(d, d);
this.moveSet(d.x, d.y);
this.previewPanel.repaint();
break;
}
case movingViewport:
{
JViewport vp = (JViewport) this.previewPanel.getParent();
Point loc = vp.getViewPosition();
MouseEvent cur = SwingUtilities.convertMouseEvent(evt.getComponent(), evt, vp);
loc.translate(lastMousePositionInViewport.x-cur.getX(), lastMousePositionInViewport.y-cur.getY());
lastMousePositionInViewport = cur.getPoint();
this.previewPanel.scrollRectToVisible(new Rectangle(loc, vp.getSize()));
break;
}
}
}
catch (NoninvertibleTransformException ex)
{
Logger.getLogger(PreviewPanelKeyboardMouseHandler.class.getName()).log(Level.SEVERE, null, ex);
}
lastMousePosition = evt.getPoint();
}
}","public void mouseDragged(MouseEvent evt)
{
if (lastMousePosition != null)
{
Point diff = new Point(evt.getPoint().x - lastMousePosition.x, evt.getPoint().y - lastMousePosition.y);
try
      {
switch (currentAction)
{
case rotatingSet:
{
Rectangle2D bb = getGraphicObjects().getBoundingBox();
Point2D middle = new Point.Double(bb.getCenterX(), bb.getCenterY());
//move back
AffineTransform tr = AffineTransform.getTranslateInstance(middle.getX(), middle.getY());
//rotate
tr.concatenate(AffineTransform.getRotateInstance(1.0 / 100 * Math.max(diff.x, diff.y)));
//center
tr.concatenate(AffineTransform.getTranslateInstance(-middle.getX(), -middle.getY()));
//apply current
tr.concatenate(getGraphicObjects().transform);
getGraphicObjects().setTransform(tr);
this.previewPanel.repaint();
break;
}
case resizingSet:
{
this.previewPanel.getMmToPxTransform().createInverse().deltaTransform(diff, diff);
switch (currentButton)
{
case BOTTOM_RIGHT:
{
int offset = Math.abs(diff.x) > Math.abs(diff.y) ? diff.x : diff.y;
getEditRect().height += (offset * getEditRect().height / getEditRect().width);
getEditRect().width += offset;
break;
}
case BOTTOM_LEFT:
{
int offset = Math.abs(diff.x) > Math.abs(diff.y) ? diff.x : diff.y;
getEditRect().height -= (offset * getEditRect().height / getEditRect().width);
getEditRect().x += offset;
getEditRect().width -= offset;
break;
}
case TOP_RIGHT:
{
int offset = Math.abs(diff.x) > Math.abs(diff.y) ? diff.x : -diff.y;
getEditRect().y -= (offset * getEditRect().height / getEditRect().width);
getEditRect().height += (offset * getEditRect().height / getEditRect().width);
getEditRect().width += offset;
break;
}
case TOP_LEFT:
{
int offset = Math.abs(diff.x) > Math.abs(diff.y) ? diff.x : diff.y;
getEditRect().y += (offset * getEditRect().height / getEditRect().width);
getEditRect().height -= (offset * getEditRect().height / getEditRect().width);
getEditRect().x += offset;
getEditRect().width -= offset;
break;
}
case CENTER_RIGHT:
{
this.getEditRect().width += diff.x;
break;
}
case TOP_CENTER:
{
this.getEditRect().y += diff.y;
this.getEditRect().height -= diff.y;
break;
}
case BOTTOM_CENTER:
{
this.getEditRect().height += diff.y;
break;
}
case CENTER_LEFT:
{
this.getEditRect().x += diff.x;
this.getEditRect().width -= diff.x;
break;
}
}
if (getEditRect().width < 0.1)
{
getEditRect().width = 0.1;
}
if (getEditRect().height < 0.1)
{
getEditRect().height = 0.1;
}
if (getEditRect().x < 0)
{
getEditRect().x = 0;
}
if (getEditRect().y < 0)
{
getEditRect().y = 0;
}
if (getEditRect().x + getEditRect().width > previewPanel.getAreaSize().x)
{
getEditRect().width = previewPanel.getAreaSize().x - getEditRect().x;
}
if (getEditRect().y + getEditRect().height > previewPanel.getAreaSize().y)
{
getEditRect().height = previewPanel.getAreaSize().y - getEditRect().y;
}
this.previewPanel.setEditRectangle(getEditRect());
break;
}
case movingSet:
{
AffineTransform tr = this.previewPanel.getMmToPxTransform();
Point2D.Double d = new Point2D.Double(diff.x, diff.y);
tr.createInverse().deltaTransform(d, d);
this.moveSet(d.x, d.y);
this.previewPanel.repaint();
break;
}
case movingViewport:
{
JViewport vp = (JViewport) this.previewPanel.getParent();
Point loc = vp.getViewPosition();
MouseEvent cur = SwingUtilities.convertMouseEvent(evt.getComponent(), evt, vp);
loc.translate(lastMousePositionInViewport.x-cur.getX(), lastMousePositionInViewport.y-cur.getY());
lastMousePositionInViewport = cur.getPoint();
this.previewPanel.scrollRectToVisible(new Rectangle(loc, vp.getSize()));
break;
}
}
}
catch (NoninvertibleTransformException ex)
{
Logger.getLogger(PreviewPanelKeyboardMouseHandler.class.getName()).log(Level.SEVERE, null, ex);
}
lastMousePosition = evt.getPoint();
}
}","public void mouseDragged  ( MouseEvent evt ) { if ( lastMousePosition != null ) { Point diff = new Point ( evt . getPoint ( ) . x - lastMousePosition . x , evt . getPoint ( ) . y - lastMousePosition . y ) ; try { switch ( currentAction ) { case rotatingSet : { Rectangle2D bb = getGraphicObjects ( ) . getBoundingBox ( ) ; Point2D middle = new Point . Double ( bb . getCenterX ( ) , bb . getCenterY ( ) ) ; //move back AffineTransform tr = AffineTransform . getTranslateInstance ( middle . getX ( ) , middle . getY ( ) ) ; //rotate tr . concatenate ( AffineTransform . getRotateInstance ( 1.0 / 100 * Math . max ( diff . x , diff . y ) ) ) ; //center tr . concatenate ( AffineTransform . getTranslateInstance ( - middle . getX ( ) , - middle . getY ( ) ) ) ; //apply current tr . concatenate ( getGraphicObjects ( ) . transform ) ; getGraphicObjects ( ) . setTransform ( tr ) ; this . previewPanel . repaint ( ) ; break ; } case resizingSet : { this . previewPanel . getMmToPxTransform ( ) . createInverse ( ) . deltaTransform ( diff , diff ) ; switch ( currentButton ) { case BOTTOM_RIGHT : { int offset = Math . abs ( diff . x ) > Math . abs ( diff . y ) ? diff . x : diff . y ; getEditRect ( ) . height += ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . width += offset ; break ; } case BOTTOM_LEFT : { int offset = Math . abs ( diff . x ) > Math . abs ( diff . y ) ? diff . x : diff . y ; getEditRect ( ) . height -= ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . x += offset ; getEditRect ( ) . width -= offset ; break ; } case TOP_RIGHT : { int offset = Math . abs ( diff . x ) > Math . abs ( diff . y ) ? diff . x : - diff . y ; getEditRect ( ) . y -= ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . height += ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . width += offset ; break ; } case TOP_LEFT : { int offset = Math . abs ( diff . x ) > Math . abs ( diff . y ) ? diff . x : diff . y ; getEditRect ( ) . y += ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . height -= ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . x += offset ; getEditRect ( ) . width -= offset ; break ; } case CENTER_RIGHT : { this . getEditRect ( ) . width += diff . x ; break ; } case TOP_CENTER : { this . getEditRect ( ) . y += diff . y ; this . getEditRect ( ) . height -= diff . y ; break ; } case BOTTOM_CENTER : { this . getEditRect ( ) . height += diff . y ; break ; } case CENTER_LEFT : { this . getEditRect ( ) . x += diff . x ; this . getEditRect ( ) . width -= diff . x ; break ; } } //<SATD_START> TODO: Make sure the bounds of EditRect don't exceed the workspace <SATD_END> this . previewPanel . setEditRectangle ( getEditRect ( ) ) ; break ; } case movingSet : { AffineTransform tr = this . previewPanel . getMmToPxTransform ( ) ; Point2D . Double d = new Point2D . Double ( diff . x , diff . y ) ; tr . createInverse ( ) . deltaTransform ( d , d ) ; this . moveSet ( d . x , d . y ) ; this . previewPanel . repaint ( ) ; break ; } case movingViewport : { JViewport vp = ( JViewport ) this . previewPanel . getParent ( ) ; Point loc = vp . getViewPosition ( ) ; MouseEvent cur = SwingUtilities . convertMouseEvent ( evt . getComponent ( ) , evt , vp ) ; loc . translate ( lastMousePositionInViewport . x - cur . getX ( ) , lastMousePositionInViewport . y - cur . getY ( ) ) ; lastMousePositionInViewport = cur . getPoint ( ) ; this . previewPanel . scrollRectToVisible ( new Rectangle ( loc , vp . getSize ( ) ) ) ; break ; } } } catch ( NoninvertibleTransformException ex ) { Logger . getLogger ( PreviewPanelKeyboardMouseHandler . class . getName ( ) ) . log ( Level . SEVERE , null , ex ) ; } lastMousePosition = evt . getPoint ( ) ; } }","public void mouseDragged  ( MouseEvent evt ) { if ( lastMousePosition != null ) { Point diff = new Point ( evt . getPoint ( ) . x - lastMousePosition . x , evt . getPoint ( ) . y - lastMousePosition . y ) ; try { switch ( currentAction ) { case rotatingSet : { Rectangle2D bb = getGraphicObjects ( ) . getBoundingBox ( ) ; Point2D middle = new Point . Double ( bb . getCenterX ( ) , bb . getCenterY ( ) ) ; //move back AffineTransform tr = AffineTransform . getTranslateInstance ( middle . getX ( ) , middle . getY ( ) ) ; //rotate tr . concatenate ( AffineTransform . getRotateInstance ( 1.0 / 100 * Math . max ( diff . x , diff . y ) ) ) ; //center tr . concatenate ( AffineTransform . getTranslateInstance ( - middle . getX ( ) , - middle . getY ( ) ) ) ; //apply current tr . concatenate ( getGraphicObjects ( ) . transform ) ; getGraphicObjects ( ) . setTransform ( tr ) ; this . previewPanel . repaint ( ) ; break ; } case resizingSet : { this . previewPanel . getMmToPxTransform ( ) . createInverse ( ) . deltaTransform ( diff , diff ) ; switch ( currentButton ) { case BOTTOM_RIGHT : { int offset = Math . abs ( diff . x ) > Math . abs ( diff . y ) ? diff . x : diff . y ; getEditRect ( ) . height += ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . width += offset ; break ; } case BOTTOM_LEFT : { int offset = Math . abs ( diff . x ) > Math . abs ( diff . y ) ? diff . x : diff . y ; getEditRect ( ) . height -= ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . x += offset ; getEditRect ( ) . width -= offset ; break ; } case TOP_RIGHT : { int offset = Math . abs ( diff . x ) > Math . abs ( diff . y ) ? diff . x : - diff . y ; getEditRect ( ) . y -= ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . height += ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . width += offset ; break ; } case TOP_LEFT : { int offset = Math . abs ( diff . x ) > Math . abs ( diff . y ) ? diff . x : diff . y ; getEditRect ( ) . y += ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . height -= ( offset * getEditRect ( ) . height / getEditRect ( ) . width ) ; getEditRect ( ) . x += offset ; getEditRect ( ) . width -= offset ; break ; } case CENTER_RIGHT : { this . getEditRect ( ) . width += diff . x ; break ; } case TOP_CENTER : { this . getEditRect ( ) . y += diff . y ; this . getEditRect ( ) . height -= diff . y ; break ; } case BOTTOM_CENTER : { this . getEditRect ( ) . height += diff . y ; break ; } case CENTER_LEFT : { this . getEditRect ( ) . x += diff . x ; this . getEditRect ( ) . width -= diff . x ; break ; } } if ( getEditRect ( ) . width < 0.1 ) { getEditRect ( ) . width = 0.1 ; } if ( getEditRect ( ) . height < 0.1 ) { getEditRect ( ) . height = 0.1 ; } if ( getEditRect ( ) . x < 0 ) { getEditRect ( ) . x = 0 ; } if ( getEditRect ( ) . y < 0 ) { getEditRect ( ) . y = 0 ; } if ( getEditRect ( ) . x + getEditRect ( ) . width > previewPanel . getAreaSize ( ) . x ) { getEditRect ( ) . width = previewPanel . getAreaSize ( ) . x - getEditRect ( ) . x ; } if ( getEditRect ( ) . y + getEditRect ( ) . height > previewPanel . getAreaSize ( ) . y ) { getEditRect ( ) . height = previewPanel . getAreaSize ( ) . y - getEditRect ( ) . y ; } this . previewPanel . setEditRectangle ( getEditRect ( ) ) ; break ; } case movingSet : { AffineTransform tr = this . previewPanel . getMmToPxTransform ( ) ; Point2D . Double d = new Point2D . Double ( diff . x , diff . y ) ; tr . createInverse ( ) . deltaTransform ( d , d ) ; this . moveSet ( d . x , d . y ) ; this . previewPanel . repaint ( ) ; break ; } case movingViewport : { JViewport vp = ( JViewport ) this . previewPanel . getParent ( ) ; Point loc = vp . getViewPosition ( ) ; MouseEvent cur = SwingUtilities . convertMouseEvent ( evt . getComponent ( ) , evt , vp ) ; loc . translate ( lastMousePositionInViewport . x - cur . getX ( ) , lastMousePositionInViewport . y - cur . getY ( ) ) ; lastMousePositionInViewport = cur . getPoint ( ) ; this . previewPanel . scrollRectToVisible ( new Rectangle ( loc , vp . getSize ( ) ) ) ; break ; } } } catch ( NoninvertibleTransformException ex ) { Logger . getLogger ( PreviewPanelKeyboardMouseHandler . class . getName ( ) ) . log ( Level . SEVERE , null , ex ) ; } lastMousePosition = evt . getPoint ( ) ; } }",2012-10-30 15:04:35 +0100,2012-10-30 21:59:23 +0100,0,0.9144034917555771
1048,248,https://www.github.com/seam/security,fieldMatches(Field),NOT_DESIGN,384,384,302,302,TODO the credentials are stored somewhere else...,https://www.github.com/seam/security/commit/148fd907,https://www.github.com/seam/security/commit/03a520e2503b40e2fdaf7e9a3002b4b2229601f8,impl/src/main/java/org/jboss/seam/security/management/JpaIdentityStore.java,"protected void configureCredentials()
{
// If a credential entity has been explicitly configured, scan it
if (credentialClass != null)
{
List<Property<Object>> props = PropertyQueries.createQuery(credentialClass)
.addCriteria(new PropertyTypeCriteria(PropertyType.VALUE))
.getResultList();
if (props.size() == 1)
{
modelProperties.put(PROPERTY_CREDENTIAL_VALUE, props.get(0));
}
else if (props.size() > 1)
{
throw new IdentityManagementException(
                  ""Ambiguous credential value property in credential class "" +
credentialClass.getName());
}
else
         {
// Search for the value property by name
String[] allowedNames = new String[] { ""credentialValue"", ""password"", 
                  ""passwordHash"", ""credential"", ""value""};
props = PropertyQueries.createQuery(credentialClass)
.addCriteria(new NamedPropertyCriteria(allowedNames))
.getResultList();
search: for (String name : allowedNames)
{
for (Property<Object> prop : props)
{
if (name.equals(prop.getName()))
{
modelProperties.put(PROPERTY_CREDENTIAL_VALUE, prop);
break search;
}
}
}
}
}
else
      {
// TODO the credentials are stored somewhere else... 
}
if (!modelProperties.containsKey(PROPERTY_CREDENTIAL_VALUE))
{
throw new IdentityManagementException(""Error initializing JpaIdentityStore - no credential value property found."");
}
// Scan for a credential type property
List<Property<Object>> props = PropertyQueries.createQuery(credentialClass)
.addCriteria(new PropertyTypeCriteria(PropertyType.TYPE))
.getResultList();
if (props.size() == 1)
{
modelProperties.put(PROPERTY_CREDENTIAL_TYPE, props.get(0));
}
else if (props.size() > 1)
{
throw new IdentityManagementException(
               ""Ambiguous credential type property in credential class "" +
credentialClass.getName());
}
else
      {
// Search for the type property by name
String[] allowedNames = new String[] { ""credentialType"", 
               ""identityObjectCredentialType"", ""type""};
props = PropertyQueries.createQuery(credentialClass)
.addCriteria(new NamedPropertyCriteria(allowedNames))
.getResultList();
search: for (String name : allowedNames)
{
for (Property<Object> prop : props)
{
if (name.equals(prop.getName()))
{
modelProperties.put(PROPERTY_CREDENTIAL_TYPE, prop);
break search;
}
}
}
}
Property<?> typeProp = modelProperties.get(PROPERTY_CREDENTIAL_TYPE);
// If the credential type property isn't a String, then validate the lookup type
if (!String.class.equals(typeProp.getJavaClass()))
{
Property<Object> nameProp = findCredentialTypeNameProperty(typeProp.getJavaClass());
if (nameProp != null)
{
modelProperties.put(PROPERTY_CREDENTIAL_TYPE_NAME, nameProp);
}
else
         {
throw new IdentityManagementException(""Error initializing JpaIdentityStore - no valid credential type name property found."");
}
}
}","protected void configureCredentials()
{
// If a credential entity has been explicitly configured, scan it
if (credentialClass != null)
{
List<Property<Object>> props = PropertyQueries.createQuery(credentialClass)
.addCriteria(new PropertyTypeCriteria(PropertyType.VALUE))
.getResultList();
if (props.size() == 1)
{
modelProperties.put(PROPERTY_CREDENTIAL_VALUE, props.get(0));
}
else if (props.size() > 1)
{
throw new IdentityManagementException(
                  ""Ambiguous credential value property in credential class "" +
credentialClass.getName());
}
else
         {
Property<Object> p = findNamedProperty(credentialClass, ""credentialValue"", 
                  ""password"", ""passwordHash"", ""credential"", ""value"");
if (p != null) modelProperties.put(PROPERTY_CREDENTIAL_VALUE, p);
}
}
else
      {
// The credentials may be stored in the identity class - let's search for it by name
Property<Object> p = findNamedProperty(identityClass, ""credentialValue"", 
               ""password"", ""passwordHash"", ""credential"", ""value"");
if (p != null) modelProperties.put(PROPERTY_CREDENTIAL_VALUE, p);
}
if (!modelProperties.containsKey(PROPERTY_CREDENTIAL_VALUE))
{
throw new IdentityManagementException(""Error initializing JpaIdentityStore - no credential value property found."");
}
// Scan for a credential type property
List<Property<Object>> props = PropertyQueries.createQuery(credentialClass)
.addCriteria(new PropertyTypeCriteria(PropertyType.TYPE))
.getResultList();
if (props.size() == 1)
{
modelProperties.put(PROPERTY_CREDENTIAL_TYPE, props.get(0));
}
else if (props.size() > 1)
{
throw new IdentityManagementException(
               ""Ambiguous credential type property in credential class "" +
credentialClass.getName());
}
else
      {
Property<Object> p = findNamedProperty(credentialClass, ""credentialType"", 
               ""identityObjectCredentialType"", ""type"");
if (p != null) modelProperties.put(PROPERTY_CREDENTIAL_TYPE, p);
}
Property<?> typeProp = modelProperties.get(PROPERTY_CREDENTIAL_TYPE);
// If the credential type property isn't a String, then validate the lookup type
if (!String.class.equals(typeProp.getJavaClass()))
{
Property<Object> nameProp = findNamedProperty(typeProp.getJavaClass(),
               ""credentialObjectTypeName"", ""credentialTypeName"", ""typeName"", ""name"");
if (nameProp != null)
{
modelProperties.put(PROPERTY_CREDENTIAL_TYPE_NAME, nameProp);
}
else
         {
throw new IdentityManagementException(""Error initializing JpaIdentityStore - no valid credential type name property found."");
}
}
}","protected void configureCredentials  ( ) { // If a credential entity has been explicitly configured, scan it if ( credentialClass != null ) { List < Property < Object > > props = PropertyQueries . createQuery ( credentialClass ) . addCriteria ( new PropertyTypeCriteria ( PropertyType . VALUE ) ) . getResultList ( ) ; if ( props . size ( ) == 1 ) { modelProperties . put ( PROPERTY_CREDENTIAL_VALUE , props . get ( 0 ) ) ; } else if ( props . size ( ) > 1 ) { throw new IdentityManagementException ( "" Ambiguous credential value property in credential class  "" + credentialClass . getName ( ) ) ; } else { // Search for the value property by name String [ ] allowedNames = new String [ ] { "" credentialValue "" , "" password "" , "" passwordHash "" , "" credential "" , "" value "" } ; props = PropertyQueries . createQuery ( credentialClass ) . addCriteria ( new NamedPropertyCriteria ( allowedNames ) ) . getResultList ( ) ; search : for ( String name : allowedNames ) { for ( Property < Object > prop : props ) { if ( name . equals ( prop . getName ( ) ) ) { modelProperties . put ( PROPERTY_CREDENTIAL_VALUE , prop ) ; break search ; } } } } } else { // <SATD_START> TODO the credentials are stored somewhere else... <SATD_END>  } if ( ! modelProperties . containsKey ( PROPERTY_CREDENTIAL_VALUE ) ) { throw new IdentityManagementException ( "" Error initializing JpaIdentityStore - no credential value property found. "" ) ; } // Scan for a credential type property List < Property < Object > > props = PropertyQueries . createQuery ( credentialClass ) . addCriteria ( new PropertyTypeCriteria ( PropertyType . TYPE ) ) . getResultList ( ) ; if ( props . size ( ) == 1 ) { modelProperties . put ( PROPERTY_CREDENTIAL_TYPE , props . get ( 0 ) ) ; } else if ( props . size ( ) > 1 ) { throw new IdentityManagementException ( "" Ambiguous credential type property in credential class  "" + credentialClass . getName ( ) ) ; } else { // Search for the type property by name String [ ] allowedNames = new String [ ] { "" credentialType "" , "" identityObjectCredentialType "" , "" type "" } ; props = PropertyQueries . createQuery ( credentialClass ) . addCriteria ( new NamedPropertyCriteria ( allowedNames ) ) . getResultList ( ) ; search : for ( String name : allowedNames ) { for ( Property < Object > prop : props ) { if ( name . equals ( prop . getName ( ) ) ) { modelProperties . put ( PROPERTY_CREDENTIAL_TYPE , prop ) ; break search ; } } } } Property < ? > typeProp = modelProperties . get ( PROPERTY_CREDENTIAL_TYPE ) ; // If the credential type property isn't a String, then validate the lookup type if ( ! String . class . equals ( typeProp . getJavaClass ( ) ) ) { Property < Object > nameProp = findCredentialTypeNameProperty ( typeProp . getJavaClass ( ) ) ; if ( nameProp != null ) { modelProperties . put ( PROPERTY_CREDENTIAL_TYPE_NAME , nameProp ) ; } else { throw new IdentityManagementException ( "" Error initializing JpaIdentityStore - no valid credential type name property found. "" ) ; } } }","protected void configureCredentials  ( ) { // If a credential entity has been explicitly configured, scan it if ( credentialClass != null ) { List < Property < Object > > props = PropertyQueries . createQuery ( credentialClass ) . addCriteria ( new PropertyTypeCriteria ( PropertyType . VALUE ) ) . getResultList ( ) ; if ( props . size ( ) == 1 ) { modelProperties . put ( PROPERTY_CREDENTIAL_VALUE , props . get ( 0 ) ) ; } else if ( props . size ( ) > 1 ) { throw new IdentityManagementException ( "" Ambiguous credential value property in credential class  "" + credentialClass . getName ( ) ) ; } else { Property < Object > p = findNamedProperty ( credentialClass , "" credentialValue "" , "" password "" , "" passwordHash "" , "" credential "" , "" value "" ) ; if ( p != null ) modelProperties . put ( PROPERTY_CREDENTIAL_VALUE , p ) ; } } else { // The credentials may be stored in the identity class - let's search for it by name Property < Object > p = findNamedProperty ( identityClass , "" credentialValue "" , "" password "" , "" passwordHash "" , "" credential "" , "" value "" ) ; if ( p != null ) modelProperties . put ( PROPERTY_CREDENTIAL_VALUE , p ) ; } if ( ! modelProperties . containsKey ( PROPERTY_CREDENTIAL_VALUE ) ) { throw new IdentityManagementException ( "" Error initializing JpaIdentityStore - no credential value property found. "" ) ; } // Scan for a credential type property List < Property < Object > > props = PropertyQueries . createQuery ( credentialClass ) . addCriteria ( new PropertyTypeCriteria ( PropertyType . TYPE ) ) . getResultList ( ) ; if ( props . size ( ) == 1 ) { modelProperties . put ( PROPERTY_CREDENTIAL_TYPE , props . get ( 0 ) ) ; } else if ( props . size ( ) > 1 ) { throw new IdentityManagementException ( "" Ambiguous credential type property in credential class  "" + credentialClass . getName ( ) ) ; } else { Property < Object > p = findNamedProperty ( credentialClass , "" credentialType "" , "" identityObjectCredentialType "" , "" type "" ) ; if ( p != null ) modelProperties . put ( PROPERTY_CREDENTIAL_TYPE , p ) ; } Property < ? > typeProp = modelProperties . get ( PROPERTY_CREDENTIAL_TYPE ) ; // If the credential type property isn't a String, then validate the lookup type if ( ! String . class . equals ( typeProp . getJavaClass ( ) ) ) { Property < Object > nameProp = findNamedProperty ( typeProp . getJavaClass ( ) , "" credentialObjectTypeName "" , "" credentialTypeName "" , "" typeName "" , "" name "" ) ; if ( nameProp != null ) { modelProperties . put ( PROPERTY_CREDENTIAL_TYPE_NAME , nameProp ) ; } else { throw new IdentityManagementException ( "" Error initializing JpaIdentityStore - no valid credential type name property found. "" ) ; } } }",2010-06-04 10:24:09 +0000,2010-06-07 04:12:51 +0000,0,0.39366754617414246
1730,55,https://www.github.com/apache/activemq,"acknowledge(ConnectionContext, MessageAck)",DESIGN,178,178,180,181,TODO is this meant to be == null?,https://www.github.com/apache/activemq/commit/de7f650b16,https://www.github.com/apache/activemq/commit/61ab31e758bb721d0b1982242dc343b614fd4362,activemq-core/src/main/java/org/apache/activemq/broker/region/PrefetchSubscription.java,"synchronized public void acknowledge(final ConnectionContext context, final MessageAck ack) throws Throwable {
// Handle the standard acknowledgment case.
boolean wasFull = isFull();
if( ack.isStandardAck() ) {
// Acknowledge all dispatched messages up till the message id of the acknowledgment.
int index=0;
boolean inAckRange=false;
for (Iterator iter = dispatched.iterator(); iter.hasNext();) {
final MessageReference node = (MessageReference)iter.next();
MessageId messageId = node.getMessageId();
if( ack.getFirstMessageId()==null || ack.getFirstMessageId().equals(messageId)) {
inAckRange = true;
}
if( inAckRange ) {
// Don't remove the nodes until we are committed.
if ( !context.isInTransaction() ) {
iter.remove();
} else {
// setup a Synchronization to remove nodes from the dispatched list.
context.getTransaction().addSynchronization(new Synchronization(){
                            public void afterCommit() throws Throwable {
synchronized(PrefetchSubscription.this) {
// Now that we are committed, we can remove the nodes.
boolean inAckRange=false;
int index=0;
for (Iterator iter = dispatched.iterator(); iter.hasNext();) {
final MessageReference node = (MessageReference)iter.next();
MessageId messageId = node.getMessageId();
if( ack.getFirstMessageId()==null || ack.getFirstMessageId().equals(messageId)) {
inAckRange = true;
}
if( inAckRange ) {
index++;
iter.remove();
if( ack.getLastMessageId().equals(messageId)) {
delivered = Math.max(0, delivered - (index+1));
return;
}
}
}
}
}
                        });
}
index++;
acknowledge(context, ack, node);
if( ack.getLastMessageId().equals(messageId)) {
if ( context.isInTransaction() )
delivered = Math.max(delivered,index+1);
else
delivered = Math.max(0, delivered - (index+1));
if( wasFull && !isFull() ) {
dispatchMatched();
}
return;
} else {
//                        System.out.println(""no match: ""+ack.getLastMessageId()+"",""+messageId);
}
}
}
log.info(""Could not correlate acknowledgment with dispatched message: ""+ack);
} else if( ack.isDeliveredAck() ) {
// Message was delivered but not acknowledged: update pre-fetch counters.
// Acknowledge all dispatched messages up till the message id of the acknowledgment.
int index=0;
for (Iterator iter = dispatched.iterator(); iter.hasNext();index++) {
final MessageReference node = (MessageReference)iter.next();
if( ack.getLastMessageId().equals(node.getMessageId()) ) {
delivered = Math.max(delivered,index+1);
if( wasFull && !isFull() ) {
dispatchMatched();
}
return;
}
}
throw new JMSException(""Could not correlate acknowledgment with dispatched message: ""+ack);
} else if( ack.isPoisonAck() ) {
// Handle the poison ACK case: we need to send the message to a DLQ  
if( ack.isInTransaction() )
throw new JMSException(""Poison ack cannot be transacted: ""+ack);
// Acknowledge all dispatched messages up till the message id of the acknowledgment.
int index=0;
boolean inAckRange=false;
for (Iterator iter = dispatched.iterator(); iter.hasNext();) {
final MessageReference node = (MessageReference)iter.next();
MessageId messageId = node.getMessageId();
if( ack.getFirstMessageId()==null || ack.getFirstMessageId().equals(messageId)) {
inAckRange = true;
}
if( inAckRange ) {
// Send the message to the DLQ
node.incrementReferenceCount();
try {
Message message = node.getMessage();
if( message !=null ) {
// TODO is this meant to be == null?
if( message.getOriginalDestination()!=null )
message.setOriginalDestination(message.getDestination());
ActiveMQDestination originalDestination = message.getOriginalDestination();
if (originalDestination == null) {
originalDestination = message.getDestination();
}
DeadLetterStrategy deadLetterStrategy = node.getRegionDestination().getDeadLetterStrategy();
ActiveMQDestination deadLetterDestination = deadLetterStrategy.getDeadLetterQueueFor(originalDestination);
message.setDestination(deadLetterDestination);
if( message.getOriginalTransactionId()!=null )
message.setOriginalTransactionId(message.getTransactionId());
message.setTransactionId(null);
message.evictMarshlledForm();
boolean originalFlowControl = context.isProducerFlowControl();
try {
context.setProducerFlowControl(false);
context.getBroker().send(context, message);
} finally {
context.setProducerFlowControl(originalFlowControl);
}
}
} finally {
node.decrementReferenceCount();
}
iter.remove();
index++;
acknowledge(context, ack, node);
if( ack.getLastMessageId().equals(messageId)) {
delivered = Math.max(0, delivered - (index+1));
if( wasFull && !isFull() ) {
dispatchMatched();
}
return;
}
}
}
throw new JMSException(""Could not correlate acknowledgment with dispatched message: ""+ack);
}
throw new JMSException(""Invalid acknowledgment: ""+ack);
}","synchronized public void acknowledge(final ConnectionContext context, final MessageAck ack) throws Throwable {
// Handle the standard acknowledgment case.
boolean wasFull = isFull();
if( ack.isStandardAck() ) {
// Acknowledge all dispatched messages up till the message id of the acknowledgment.
int index=0;
boolean inAckRange=false;
for (Iterator iter = dispatched.iterator(); iter.hasNext();) {
final MessageReference node = (MessageReference)iter.next();
MessageId messageId = node.getMessageId();
if( ack.getFirstMessageId()==null || ack.getFirstMessageId().equals(messageId)) {
inAckRange = true;
}
if( inAckRange ) {
// Don't remove the nodes until we are committed.
if ( !context.isInTransaction() ) {
iter.remove();
} else {
// setup a Synchronization to remove nodes from the dispatched list.
context.getTransaction().addSynchronization(new Synchronization(){
                            public void afterCommit() throws Throwable {
synchronized(PrefetchSubscription.this) {
// Now that we are committed, we can remove the nodes.
boolean inAckRange=false;
int index=0;
for (Iterator iter = dispatched.iterator(); iter.hasNext();) {
final MessageReference node = (MessageReference)iter.next();
MessageId messageId = node.getMessageId();
if( ack.getFirstMessageId()==null || ack.getFirstMessageId().equals(messageId)) {
inAckRange = true;
}
if( inAckRange ) {
index++;
iter.remove();
if( ack.getLastMessageId().equals(messageId)) {
delivered = Math.max(0, delivered - (index+1));
return;
}
}
}
}
}
                        });
}
index++;
acknowledge(context, ack, node);
if( ack.getLastMessageId().equals(messageId)) {
if ( context.isInTransaction() )
delivered = Math.max(delivered,index+1);
else
delivered = Math.max(0, delivered - (index+1));
if( wasFull && !isFull() ) {
dispatchMatched();
}
return;
} else {
//                        System.out.println(""no match: ""+ack.getLastMessageId()+"",""+messageId);
}
}
}
log.info(""Could not correlate acknowledgment with dispatched message: ""+ack);
} else if( ack.isDeliveredAck() ) {
// Message was delivered but not acknowledged: update pre-fetch counters.
// Acknowledge all dispatched messages up till the message id of the acknowledgment.
int index=0;
for (Iterator iter = dispatched.iterator(); iter.hasNext();index++) {
final MessageReference node = (MessageReference)iter.next();
if( ack.getLastMessageId().equals(node.getMessageId()) ) {
delivered = Math.max(delivered,index+1);
if( wasFull && !isFull() ) {
dispatchMatched();
}
return;
}
}
throw new JMSException(""Could not correlate acknowledgment with dispatched message: ""+ack);
} else if( ack.isPoisonAck() ) {
// TODO: what if the message is already in a DLQ???
// Handle the poison ACK case: we need to send the message to a DLQ  
if( ack.isInTransaction() )
throw new JMSException(""Poison ack cannot be transacted: ""+ack);
// Acknowledge all dispatched messages up till the message id of the acknowledgment.
int index=0;
boolean inAckRange=false;
for (Iterator iter = dispatched.iterator(); iter.hasNext();) {
final MessageReference node = (MessageReference)iter.next();
MessageId messageId = node.getMessageId();
if( ack.getFirstMessageId()==null || ack.getFirstMessageId().equals(messageId)) {
inAckRange = true;
}
if( inAckRange ) {
// Send the message to the DLQ
node.incrementReferenceCount();
try {
Message message = node.getMessage();
if( message !=null ) {
// The original destination and transaction id do not get filled when the message is first sent,
// it is only populated if the message is routed to another destination like the DLQ
if( message.getOriginalDestination()!=null )
message.setOriginalDestination(message.getDestination());
if( message.getOriginalTransactionId()!=null )
message.setOriginalTransactionId(message.getTransactionId());
DeadLetterStrategy deadLetterStrategy = node.getRegionDestination().getDeadLetterStrategy();
ActiveMQDestination deadLetterDestination = deadLetterStrategy.getDeadLetterQueueFor(message.getDestination());
message.setDestination(deadLetterDestination);
message.setTransactionId(null);
message.evictMarshlledForm();
boolean originalFlowControl = context.isProducerFlowControl();
try {
context.setProducerFlowControl(false);
context.getBroker().send(context, message);
} finally {
context.setProducerFlowControl(originalFlowControl);
}
}
} finally {
node.decrementReferenceCount();
}
iter.remove();
index++;
acknowledge(context, ack, node);
if( ack.getLastMessageId().equals(messageId)) {
delivered = Math.max(0, delivered - (index+1));
if( wasFull && !isFull() ) {
dispatchMatched();
}
return;
}
}
}
throw new JMSException(""Could not correlate acknowledgment with dispatched message: ""+ack);
}
throw new JMSException(""Invalid acknowledgment: ""+ack);
}","synchronized public void acknowledge  ( final ConnectionContext context , final MessageAck ack ) throws Throwable { // Handle the standard acknowledgment case. boolean wasFull = isFull ( ) ; if ( ack . isStandardAck ( ) ) { // Acknowledge all dispatched messages up till the message id of the acknowledgment. int index = 0 ; boolean inAckRange = false ; for ( Iterator iter = dispatched . iterator ( ) ; iter . hasNext ( ) ; ) { final MessageReference node = ( MessageReference ) iter . next ( ) ; MessageId messageId = node . getMessageId ( ) ; if ( ack . getFirstMessageId ( ) == null || ack . getFirstMessageId ( ) . equals ( messageId ) ) { inAckRange = true ; } if ( inAckRange ) { // Don't remove the nodes until we are committed. if ( ! context . isInTransaction ( ) ) { iter . remove ( ) ; } else { // setup a Synchronization to remove nodes from the dispatched list. context . getTransaction ( ) . addSynchronization ( new Synchronization ( ) { public void afterCommit ( ) throws Throwable { synchronized ( PrefetchSubscription . this ) { // Now that we are committed, we can remove the nodes. boolean inAckRange = false ; int index = 0 ; for ( Iterator iter = dispatched . iterator ( ) ; iter . hasNext ( ) ; ) { final MessageReference node = ( MessageReference ) iter . next ( ) ; MessageId messageId = node . getMessageId ( ) ; if ( ack . getFirstMessageId ( ) == null || ack . getFirstMessageId ( ) . equals ( messageId ) ) { inAckRange = true ; } if ( inAckRange ) { index ++ ; iter . remove ( ) ; if ( ack . getLastMessageId ( ) . equals ( messageId ) ) { delivered = Math . max ( 0 , delivered - ( index + 1 ) ) ; return ; } } } } } } ) ; } index ++ ; acknowledge ( context , ack , node ) ; if ( ack . getLastMessageId ( ) . equals ( messageId ) ) { if ( context . isInTransaction ( ) ) delivered = Math . max ( delivered , index + 1 ) ; else delivered = Math . max ( 0 , delivered - ( index + 1 ) ) ; if ( wasFull && ! isFull ( ) ) { dispatchMatched ( ) ; } return ; } else { //                        System.out.println(""no match: ""+ack.getLastMessageId()+"",""+messageId); } } } log . info ( "" Could not correlate acknowledgment with dispatched message:  "" + ack ) ; } else if ( ack . isDeliveredAck ( ) ) { // Message was delivered but not acknowledged: update pre-fetch counters. // Acknowledge all dispatched messages up till the message id of the acknowledgment. int index = 0 ; for ( Iterator iter = dispatched . iterator ( ) ; iter . hasNext ( ) ; index ++ ) { final MessageReference node = ( MessageReference ) iter . next ( ) ; if ( ack . getLastMessageId ( ) . equals ( node . getMessageId ( ) ) ) { delivered = Math . max ( delivered , index + 1 ) ; if ( wasFull && ! isFull ( ) ) { dispatchMatched ( ) ; } return ; } } throw new JMSException ( "" Could not correlate acknowledgment with dispatched message:  "" + ack ) ; } else if ( ack . isPoisonAck ( ) ) { // Handle the poison ACK case: we need to send the message to a DLQ   if ( ack . isInTransaction ( ) ) throw new JMSException ( "" Poison ack cannot be transacted:  "" + ack ) ; // Acknowledge all dispatched messages up till the message id of the acknowledgment. int index = 0 ; boolean inAckRange = false ; for ( Iterator iter = dispatched . iterator ( ) ; iter . hasNext ( ) ; ) { final MessageReference node = ( MessageReference ) iter . next ( ) ; MessageId messageId = node . getMessageId ( ) ; if ( ack . getFirstMessageId ( ) == null || ack . getFirstMessageId ( ) . equals ( messageId ) ) { inAckRange = true ; } if ( inAckRange ) { // Send the message to the DLQ node . incrementReferenceCount ( ) ; try { Message message = node . getMessage ( ) ; if ( message != null ) { // <SATD_START> TODO is this meant to be == null? <SATD_END> if ( message . getOriginalDestination ( ) != null ) message . setOriginalDestination ( message . getDestination ( ) ) ; ActiveMQDestination originalDestination = message . getOriginalDestination ( ) ; if ( originalDestination == null ) { originalDestination = message . getDestination ( ) ; } DeadLetterStrategy deadLetterStrategy = node . getRegionDestination ( ) . getDeadLetterStrategy ( ) ; ActiveMQDestination deadLetterDestination = deadLetterStrategy . getDeadLetterQueueFor ( originalDestination ) ; message . setDestination ( deadLetterDestination ) ; if ( message . getOriginalTransactionId ( ) != null ) message . setOriginalTransactionId ( message . getTransactionId ( ) ) ; message . setTransactionId ( null ) ; message . evictMarshlledForm ( ) ; boolean originalFlowControl = context . isProducerFlowControl ( ) ; try { context . setProducerFlowControl ( false ) ; context . getBroker ( ) . send ( context , message ) ; } finally { context . setProducerFlowControl ( originalFlowControl ) ; } } } finally { node . decrementReferenceCount ( ) ; } iter . remove ( ) ; index ++ ; acknowledge ( context , ack , node ) ; if ( ack . getLastMessageId ( ) . equals ( messageId ) ) { delivered = Math . max ( 0 , delivered - ( index + 1 ) ) ; if ( wasFull && ! isFull ( ) ) { dispatchMatched ( ) ; } return ; } } } throw new JMSException ( "" Could not correlate acknowledgment with dispatched message:  "" + ack ) ; } throw new JMSException ( "" Invalid acknowledgment:  "" + ack ) ; }","synchronized public void acknowledge  ( final ConnectionContext context , final MessageAck ack ) throws Throwable { // Handle the standard acknowledgment case. boolean wasFull = isFull ( ) ; if ( ack . isStandardAck ( ) ) { // Acknowledge all dispatched messages up till the message id of the acknowledgment. int index = 0 ; boolean inAckRange = false ; for ( Iterator iter = dispatched . iterator ( ) ; iter . hasNext ( ) ; ) { final MessageReference node = ( MessageReference ) iter . next ( ) ; MessageId messageId = node . getMessageId ( ) ; if ( ack . getFirstMessageId ( ) == null || ack . getFirstMessageId ( ) . equals ( messageId ) ) { inAckRange = true ; } if ( inAckRange ) { // Don't remove the nodes until we are committed. if ( ! context . isInTransaction ( ) ) { iter . remove ( ) ; } else { // setup a Synchronization to remove nodes from the dispatched list. context . getTransaction ( ) . addSynchronization ( new Synchronization ( ) { public void afterCommit ( ) throws Throwable { synchronized ( PrefetchSubscription . this ) { // Now that we are committed, we can remove the nodes. boolean inAckRange = false ; int index = 0 ; for ( Iterator iter = dispatched . iterator ( ) ; iter . hasNext ( ) ; ) { final MessageReference node = ( MessageReference ) iter . next ( ) ; MessageId messageId = node . getMessageId ( ) ; if ( ack . getFirstMessageId ( ) == null || ack . getFirstMessageId ( ) . equals ( messageId ) ) { inAckRange = true ; } if ( inAckRange ) { index ++ ; iter . remove ( ) ; if ( ack . getLastMessageId ( ) . equals ( messageId ) ) { delivered = Math . max ( 0 , delivered - ( index + 1 ) ) ; return ; } } } } } } ) ; } index ++ ; acknowledge ( context , ack , node ) ; if ( ack . getLastMessageId ( ) . equals ( messageId ) ) { if ( context . isInTransaction ( ) ) delivered = Math . max ( delivered , index + 1 ) ; else delivered = Math . max ( 0 , delivered - ( index + 1 ) ) ; if ( wasFull && ! isFull ( ) ) { dispatchMatched ( ) ; } return ; } else { //                        System.out.println(""no match: ""+ack.getLastMessageId()+"",""+messageId); } } } log . info ( "" Could not correlate acknowledgment with dispatched message:  "" + ack ) ; } else if ( ack . isDeliveredAck ( ) ) { // Message was delivered but not acknowledged: update pre-fetch counters. // Acknowledge all dispatched messages up till the message id of the acknowledgment. int index = 0 ; for ( Iterator iter = dispatched . iterator ( ) ; iter . hasNext ( ) ; index ++ ) { final MessageReference node = ( MessageReference ) iter . next ( ) ; if ( ack . getLastMessageId ( ) . equals ( node . getMessageId ( ) ) ) { delivered = Math . max ( delivered , index + 1 ) ; if ( wasFull && ! isFull ( ) ) { dispatchMatched ( ) ; } return ; } } throw new JMSException ( "" Could not correlate acknowledgment with dispatched message:  "" + ack ) ; } else if ( ack . isPoisonAck ( ) ) { // TODO: what if the message is already in a DLQ??? // Handle the poison ACK case: we need to send the message to a DLQ   if ( ack . isInTransaction ( ) ) throw new JMSException ( "" Poison ack cannot be transacted:  "" + ack ) ; // Acknowledge all dispatched messages up till the message id of the acknowledgment. int index = 0 ; boolean inAckRange = false ; for ( Iterator iter = dispatched . iterator ( ) ; iter . hasNext ( ) ; ) { final MessageReference node = ( MessageReference ) iter . next ( ) ; MessageId messageId = node . getMessageId ( ) ; if ( ack . getFirstMessageId ( ) == null || ack . getFirstMessageId ( ) . equals ( messageId ) ) { inAckRange = true ; } if ( inAckRange ) { // Send the message to the DLQ node . incrementReferenceCount ( ) ; try { Message message = node . getMessage ( ) ; if ( message != null ) { // The original destination and transaction id do not get filled when the message is first sent, // it is only populated if the message is routed to another destination like the DLQ if ( message . getOriginalDestination ( ) != null ) message . setOriginalDestination ( message . getDestination ( ) ) ; if ( message . getOriginalTransactionId ( ) != null ) message . setOriginalTransactionId ( message . getTransactionId ( ) ) ; DeadLetterStrategy deadLetterStrategy = node . getRegionDestination ( ) . getDeadLetterStrategy ( ) ; ActiveMQDestination deadLetterDestination = deadLetterStrategy . getDeadLetterQueueFor ( message . getDestination ( ) ) ; message . setDestination ( deadLetterDestination ) ; message . setTransactionId ( null ) ; message . evictMarshlledForm ( ) ; boolean originalFlowControl = context . isProducerFlowControl ( ) ; try { context . setProducerFlowControl ( false ) ; context . getBroker ( ) . send ( context , message ) ; } finally { context . setProducerFlowControl ( originalFlowControl ) ; } } } finally { node . decrementReferenceCount ( ) ; } iter . remove ( ) ; index ++ ; acknowledge ( context , ack , node ) ; if ( ack . getLastMessageId ( ) . equals ( messageId ) ) { delivered = Math . max ( 0 , delivered - ( index + 1 ) ) ; if ( wasFull && ! isFull ( ) ) { dispatchMatched ( ) ; } return ; } } } throw new JMSException ( "" Could not correlate acknowledgment with dispatched message:  "" + ack ) ; } throw new JMSException ( "" Invalid acknowledgment:  "" + ack ) ; }",2005-12-30 18:25:15 +0000,2005-12-31 16:50:52 +0000,0,0.9102060373742213
3782,120,https://www.github.com/maven-nar/nar-maven-plugin,"addImpliedArgs(boolean, LinkType, Vector)",NOT_DESIGN,93,93,94,94,"FIXME, needed to add exceptions here for MacOS X.",https://www.github.com/maven-nar/nar-maven-plugin/commit/6e69fb4e8,https://www.github.com/maven-nar/nar-maven-plugin/commit/2dac20493cf190fb56f04d1fe22f58c30eac1869,src/net/sf/antcontrib/cpptasks/gcc/GppLinker.java,"protected void addImpliedArgs(boolean debug, LinkType linkType, Vector args) {
super.addImpliedArgs(debug, linkType, args);
if (getIdentifier().indexOf(""mingw"") >= 0) {
if (linkType.isSubsystemConsole()) {
args.addElement(""-mconsole"");
}
if (linkType.isSubsystemGUI()) {
args.addElement(""-mwindows"");
}
}
// FREEHEP, avoid stdc++ if requested
runtimeLibrary = null;
gccLibrary = null;
if (linkType.linkCPP()) {
if (linkType.isStaticRuntime()) {
String[] cmdin = new String[]{""g++"", ""-print-file-name=libstdc++.a""};
String[] cmdout = CaptureStreamHandler.run(cmdin);
if (cmdout.length > 0) {
runtimeLibrary = cmdout[0];
} else {
runtimeLibrary = null;
}
gccLibrary = ""-static-libgcc"";
} else {
runtimeLibrary = ""-lstdc++"";
// FIXME, needed to add exceptions here for MacOS X.
gccLibrary = ""-fexceptions"";
}
} else {
if (linkType.isStaticRuntime()) {
gccLibrary = ""-static-libgcc"";
} else {
gccLibrary = ""-shared-libgcc"";
}
}
// FREEHEP: set flag
linkType.callAddLibrarySets = true;
}","protected void addImpliedArgs(boolean debug, LinkType linkType, Vector args) {
super.addImpliedArgs(debug, linkType, args);
if (getIdentifier().indexOf(""mingw"") >= 0) {
if (linkType.isSubsystemConsole()) {
args.addElement(""-mconsole"");
}
if (linkType.isSubsystemGUI()) {
args.addElement(""-mwindows"");
}
}
// BEGINFREEHEP link or not with libstdc++
runtimeLibrary = null;
gccLibrary = null;
if (linkType.linkCPP()) {
if (linkType.isStaticRuntime()) {
String[] cmdin = new String[]{""g++"", ""-print-file-name=libstdc++.a""};
String[] cmdout = CaptureStreamHandler.run(cmdin);
if (cmdout.length > 0) {
runtimeLibrary = cmdout[0];
} else {
runtimeLibrary = null;
}
gccLibrary = ""-static-libgcc"";
} else {
runtimeLibrary = ""-lstdc++"";
// NOTE: added -fexceptions here for MacOS X
gccLibrary = ""-fexceptions"";
}
} else {
if (linkType.isStaticRuntime()) {
gccLibrary = ""-static-libgcc"";
} else {
gccLibrary = ""-shared-libgcc"";
}
}
// ENDFREEHEP
}","protected void addImpliedArgs  ( boolean debug , LinkType linkType , Vector args ) { super . addImpliedArgs ( debug , linkType , args ) ; if ( getIdentifier ( ) . indexOf ( "" mingw "" ) >= 0 ) { if ( linkType . isSubsystemConsole ( ) ) { args . addElement ( "" -mconsole "" ) ; } if ( linkType . isSubsystemGUI ( ) ) { args . addElement ( "" -mwindows "" ) ; } } // FREEHEP, avoid stdc++ if requested runtimeLibrary = null ; gccLibrary = null ; if ( linkType . linkCPP ( ) ) { if ( linkType . isStaticRuntime ( ) ) { String [ ] cmdin = new String [ ] { "" g++ "" , "" -print-file-name=libstdc++.a "" } ; String [ ] cmdout = CaptureStreamHandler . run ( cmdin ) ; if ( cmdout . length > 0 ) { runtimeLibrary = cmdout [ 0 ] ; } else { runtimeLibrary = null ; } gccLibrary = "" -static-libgcc "" ; } else { runtimeLibrary = "" -lstdc++ "" ; // <SATD_START> FIXME, needed to add exceptions here for MacOS X. <SATD_END> gccLibrary = "" -fexceptions "" ; } } else { if ( linkType . isStaticRuntime ( ) ) { gccLibrary = "" -static-libgcc "" ; } else { gccLibrary = "" -shared-libgcc "" ; } } // FREEHEP: set flag linkType . callAddLibrarySets = true ; }","protected void addImpliedArgs  ( boolean debug , LinkType linkType , Vector args ) { super . addImpliedArgs ( debug , linkType , args ) ; if ( getIdentifier ( ) . indexOf ( "" mingw "" ) >= 0 ) { if ( linkType . isSubsystemConsole ( ) ) { args . addElement ( "" -mconsole "" ) ; } if ( linkType . isSubsystemGUI ( ) ) { args . addElement ( "" -mwindows "" ) ; } } // BEGINFREEHEP link or not with libstdc++ runtimeLibrary = null ; gccLibrary = null ; if ( linkType . linkCPP ( ) ) { if ( linkType . isStaticRuntime ( ) ) { String [ ] cmdin = new String [ ] { "" g++ "" , "" -print-file-name=libstdc++.a "" } ; String [ ] cmdout = CaptureStreamHandler . run ( cmdin ) ; if ( cmdout . length > 0 ) { runtimeLibrary = cmdout [ 0 ] ; } else { runtimeLibrary = null ; } gccLibrary = "" -static-libgcc "" ; } else { runtimeLibrary = "" -lstdc++ "" ; // NOTE: added -fexceptions here for MacOS X gccLibrary = "" -fexceptions "" ; } } else { if ( linkType . isStaticRuntime ( ) ) { gccLibrary = "" -static-libgcc "" ; } else { gccLibrary = "" -shared-libgcc "" ; } } // ENDFREEHEP }",2007-06-19 23:31:06 +0000,2007-07-06 19:06:29 +0000,0,0.7767079321412196
156,390,https://www.github.com/sonarsource/sonarqube,deleteProfile(int),,53,53,53,53,TODO should support deletion of profile with children,https://www.github.com/sonarsource/sonarqube/commit/d79f46b3733b,https://www.github.com/sonarsource/sonarqube/commit/8569b5c29e3577cd2137e9680ea79f4e5ee6db7c,sonar-server/src/main/java/org/sonar/server/configuration/ProfilesManager.java,"public void deleteProfile(int profileId) {
// TODO should support deletion of profile with children
RulesProfile profile = getSession().getEntity(RulesProfile.class, profileId);
if (profile != null && !profile.getProvided()) {
String hql = ""UPDATE "" + ResourceModel.class.getSimpleName() + "" o SET o.rulesProfile=null WHERE o.rulesProfile=:rulesProfile"";
getSession().createQuery(hql).setParameter(""rulesProfile"", profile).executeUpdate();
getSession().remove(profile);
getSession().commit();
}
}","public void deleteProfile(int profileId) {
RulesProfile profile = getSession().getEntity(RulesProfile.class, profileId);
if (profile != null && !profile.getProvided() && getChildren(profile).isEmpty()) {
String hql = ""UPDATE "" + ResourceModel.class.getSimpleName() + "" o SET o.rulesProfile=null WHERE o.rulesProfile=:rulesProfile"";
getSession().createQuery(hql).setParameter(""rulesProfile"", profile).executeUpdate();
getSession().remove(profile);
getSession().commit();
}
}","public void deleteProfile  ( int profileId ) { // <SATD_START> TODO should support deletion of profile with children <SATD_END> RulesProfile profile = getSession ( ) . getEntity ( RulesProfile . class , profileId ) ; if ( profile != null && ! profile . getProvided ( ) ) { String hql = "" UPDATE  "" + ResourceModel . class . getSimpleName ( ) + ""  o SET o.rulesProfile=null WHERE o.rulesProfile=:rulesProfile "" ; getSession ( ) . createQuery ( hql ) . setParameter ( "" rulesProfile "" , profile ) . executeUpdate ( ) ; getSession ( ) . remove ( profile ) ; getSession ( ) . commit ( ) ; } }","public void deleteProfile  ( int profileId ) { RulesProfile profile = getSession ( ) . getEntity ( RulesProfile . class , profileId ) ; if ( profile != null && ! profile . getProvided ( ) && getChildren ( profile ) . isEmpty ( ) ) { String hql = "" UPDATE  "" + ResourceModel . class . getSimpleName ( ) + ""  o SET o.rulesProfile=null WHERE o.rulesProfile=:rulesProfile "" ; getSession ( ) . createQuery ( hql ) . setParameter ( "" rulesProfile "" , profile ) . executeUpdate ( ) ; getSession ( ) . remove ( profile ) ; getSession ( ) . commit ( ) ; } }",2010-12-17 00:05:04 +0000,2010-12-21 11:49:41 +0000,0,0.8926056338028169
774,587,https://www.github.com/eclipse/jetty.project,formatDate(long),,1054,1054,1054,1054,TODO - straight to Buffer?,https://www.github.com/eclipse/jetty.project/commit/da627b843fe,https://www.github.com/eclipse/jetty.project/commit/c53749c23235a74bd8d338172d9b4ab615deb4c7,jetty-http/src/main/java/org/eclipse/jetty/http/HttpFields.java,"public void addSetCookie(
            final String name, 
            final String value, 
            final String domain,
            final String path, 
            final long maxAge,
            final String comment, 
            final boolean isSecure,
            final boolean isHttpOnly, 
            int version)
{
String delim=_maxCookieVersion==0?"""":""\""\\\n\r\t\f\b%+ ;="";
// Check arguments
if (name == null || name.length() == 0) throw new IllegalArgumentException(""Bad cookie name"");
// Format value and params
StringBuilder buf = new StringBuilder(128);
String name_value_params;
boolean quoted = QuotedStringTokenizer.quoteIfNeeded(buf, name, delim);
buf.append('=');
String start=buf.toString();
if (value != null && value.length() > 0)
quoted|=QuotedStringTokenizer.quoteIfNeeded(buf, value, delim);
// upgrade to version 1 cookies if quoted.
if (quoted&&version==0 && _maxCookieVersion>=1)
version=1;
if (version>_maxCookieVersion)
version=_maxCookieVersion;
if (version > 0)
{
buf.append("";Version="");
buf.append(version);
if (comment != null && comment.length() > 0)
{
buf.append("";Comment="");
QuotedStringTokenizer.quoteIfNeeded(buf, comment, delim);
}
}
if (path != null && path.length() > 0)
{
buf.append("";Path="");
if (path.trim().startsWith(""\""""))
buf.append(path);
else
QuotedStringTokenizer.quoteIfNeeded(buf,path,delim);
}
if (domain != null && domain.length() > 0)
{
buf.append("";Domain="");
QuotedStringTokenizer.quoteIfNeeded(buf,domain.toLowerCase(),delim);
}
if (maxAge >= 0)
{
// Always add the expires param as some browsers still don't handle max-age
buf.append("";Expires="");
if (maxAge == 0)
buf.append(__01Jan1970);
else
formatCookieDate(buf, System.currentTimeMillis() + 1000L * maxAge);
if (version >0)
{
buf.append("";Max-Age="");
buf.append(maxAge);
}
}
else if (version > 0)
{
buf.append("";Discard"");
}
if (isSecure)
buf.append("";Secure"");
if (isHttpOnly)
buf.append("";HttpOnly"");
// TODO - straight to Buffer?
name_value_params = buf.toString();
// look for existing cookie
Field field = getField(HttpHeaders.SET_COOKIE_BUFFER);
if (field != null)
{
final int revision=_revision;
while (field!=null)
{
if (field._revision!=revision || field._value!=null && field._value.toString().startsWith(start))
{
field.reset(new ByteArrayBuffer(name_value_params),-1,revision);
return;
}
field=field._next;
}
}
add(HttpHeaders.SET_COOKIE_BUFFER, new ByteArrayBuffer(name_value_params));
// Expire responses with set-cookie headers so they do not get cached.
put(HttpHeaders.EXPIRES_BUFFER, __01Jan1970_BUFFER);
}","public void addSetCookie(
            final String name, 
            final String value, 
            final String domain,
            final String path, 
            final long maxAge,
            final String comment, 
            final boolean isSecure,
            final boolean isHttpOnly, 
            int version)
{
String delim=_maxCookieVersion==0?"""":""\""\\\n\r\t\f\b%+ ;="";
// Check arguments
if (name == null || name.length() == 0) throw new IllegalArgumentException(""Bad cookie name"");
// Format value and params
StringBuilder buf = new StringBuilder(128);
String name_value_params;
boolean quoted = QuotedStringTokenizer.quoteIfNeeded(buf, name, delim);
buf.append('=');
String start=buf.toString();
if (value != null && value.length() > 0)
quoted|=QuotedStringTokenizer.quoteIfNeeded(buf, value, delim);
// upgrade to version 1 cookies if quoted.
if (quoted&&version==0 && _maxCookieVersion>=1)
version=1;
if (version>_maxCookieVersion)
version=_maxCookieVersion;
if (version > 0)
{
buf.append("";Version="");
buf.append(version);
if (comment != null && comment.length() > 0)
{
buf.append("";Comment="");
QuotedStringTokenizer.quoteIfNeeded(buf, comment, delim);
}
}
if (path != null && path.length() > 0)
{
buf.append("";Path="");
if (path.trim().startsWith(""\""""))
buf.append(path);
else
QuotedStringTokenizer.quoteIfNeeded(buf,path,delim);
}
if (domain != null && domain.length() > 0)
{
buf.append("";Domain="");
QuotedStringTokenizer.quoteIfNeeded(buf,domain.toLowerCase(),delim);
}
if (maxAge >= 0)
{
// Always add the expires param as some browsers still don't handle max-age
buf.append("";Expires="");
if (maxAge == 0)
buf.append(__01Jan1970_COOKIE);
else
formatCookieDate(buf, System.currentTimeMillis() + 1000L * maxAge);
if (version >0)
{
buf.append("";Max-Age="");
buf.append(maxAge);
}
}
else if (version > 0)
{
buf.append("";Discard"");
}
if (isSecure)
buf.append("";Secure"");
if (isHttpOnly)
buf.append("";HttpOnly"");
name_value_params = buf.toString();
// look for existing set cookie of same name
Field field = getField(HttpHeaders.SET_COOKIE_BUFFER);
if (field != null)
{
final int revision=_revision;
while (field!=null)
{
if (field._revision==revision && field._value!=null && field._value.toString().startsWith(start))
{
field.reset(new ByteArrayBuffer(name_value_params),-1,revision);
name_value_params=null;
break;
}
field=field._next;
}
}
if (name_value_params!=null)
add(HttpHeaders.SET_COOKIE_BUFFER, new ByteArrayBuffer(name_value_params));
// Expire responses with set-cookie headers so they do not get cached.
put(HttpHeaders.EXPIRES_BUFFER, __01Jan1970_BUFFER);
}","public void addSetCookie  ( final String name , final String value , final String domain , final String path , final long maxAge , final String comment , final boolean isSecure , final boolean isHttpOnly , int version ) { String delim = _maxCookieVersion == 0 ? "" "" : "" \"" \\ \n \r \t \f \b %+ ;= "" ; // Check arguments if ( name == null || name . length ( ) == 0 ) throw new IllegalArgumentException ( "" Bad cookie name "" ) ; // Format value and params StringBuilder buf = new StringBuilder ( 128 ) ; String name_value_params ; boolean quoted = QuotedStringTokenizer . quoteIfNeeded ( buf , name , delim ) ; buf . append ( '=' ) ; String start = buf . toString ( ) ; if ( value != null && value . length ( ) > 0 ) quoted |= QuotedStringTokenizer . quoteIfNeeded ( buf , value , delim ) ; // upgrade to version 1 cookies if quoted. if ( quoted && version == 0 && _maxCookieVersion >= 1 ) version = 1 ; if ( version > _maxCookieVersion ) version = _maxCookieVersion ; if ( version > 0 ) { buf . append ( "" ;Version= "" ) ; buf . append ( version ) ; if ( comment != null && comment . length ( ) > 0 ) { buf . append ( "" ;Comment= "" ) ; QuotedStringTokenizer . quoteIfNeeded ( buf , comment , delim ) ; } } if ( path != null && path . length ( ) > 0 ) { buf . append ( "" ;Path= "" ) ; if ( path . trim ( ) . startsWith ( "" \"" "" ) ) buf . append ( path ) ; else QuotedStringTokenizer . quoteIfNeeded ( buf , path , delim ) ; } if ( domain != null && domain . length ( ) > 0 ) { buf . append ( "" ;Domain= "" ) ; QuotedStringTokenizer . quoteIfNeeded ( buf , domain . toLowerCase ( ) , delim ) ; } if ( maxAge >= 0 ) { // Always add the expires param as some browsers still don't handle max-age buf . append ( "" ;Expires= "" ) ; if ( maxAge == 0 ) buf . append ( __01Jan1970 ) ; else formatCookieDate ( buf , System . currentTimeMillis ( ) + 1000L * maxAge ) ; if ( version > 0 ) { buf . append ( "" ;Max-Age= "" ) ; buf . append ( maxAge ) ; } } else if ( version > 0 ) { buf . append ( "" ;Discard "" ) ; } if ( isSecure ) buf . append ( "" ;Secure "" ) ; if ( isHttpOnly ) buf . append ( "" ;HttpOnly "" ) ; // <SATD_START> TODO - straight to Buffer? <SATD_END> name_value_params = buf . toString ( ) ; // look for existing cookie Field field = getField ( HttpHeaders . SET_COOKIE_BUFFER ) ; if ( field != null ) { final int revision = _revision ; while ( field != null ) { if ( field . _revision != revision || field . _value != null && field . _value . toString ( ) . startsWith ( start ) ) { field . reset ( new ByteArrayBuffer ( name_value_params ) , - 1 , revision ) ; return ; } field = field . _next ; } } add ( HttpHeaders . SET_COOKIE_BUFFER , new ByteArrayBuffer ( name_value_params ) ) ; // Expire responses with set-cookie headers so they do not get cached. put ( HttpHeaders . EXPIRES_BUFFER , __01Jan1970_BUFFER ) ; }","public void addSetCookie  ( final String name , final String value , final String domain , final String path , final long maxAge , final String comment , final boolean isSecure , final boolean isHttpOnly , int version ) { String delim = _maxCookieVersion == 0 ? "" "" : "" \"" \\ \n \r \t \f \b %+ ;= "" ; // Check arguments if ( name == null || name . length ( ) == 0 ) throw new IllegalArgumentException ( "" Bad cookie name "" ) ; // Format value and params StringBuilder buf = new StringBuilder ( 128 ) ; String name_value_params ; boolean quoted = QuotedStringTokenizer . quoteIfNeeded ( buf , name , delim ) ; buf . append ( '=' ) ; String start = buf . toString ( ) ; if ( value != null && value . length ( ) > 0 ) quoted |= QuotedStringTokenizer . quoteIfNeeded ( buf , value , delim ) ; // upgrade to version 1 cookies if quoted. if ( quoted && version == 0 && _maxCookieVersion >= 1 ) version = 1 ; if ( version > _maxCookieVersion ) version = _maxCookieVersion ; if ( version > 0 ) { buf . append ( "" ;Version= "" ) ; buf . append ( version ) ; if ( comment != null && comment . length ( ) > 0 ) { buf . append ( "" ;Comment= "" ) ; QuotedStringTokenizer . quoteIfNeeded ( buf , comment , delim ) ; } } if ( path != null && path . length ( ) > 0 ) { buf . append ( "" ;Path= "" ) ; if ( path . trim ( ) . startsWith ( "" \"" "" ) ) buf . append ( path ) ; else QuotedStringTokenizer . quoteIfNeeded ( buf , path , delim ) ; } if ( domain != null && domain . length ( ) > 0 ) { buf . append ( "" ;Domain= "" ) ; QuotedStringTokenizer . quoteIfNeeded ( buf , domain . toLowerCase ( ) , delim ) ; } if ( maxAge >= 0 ) { // Always add the expires param as some browsers still don't handle max-age buf . append ( "" ;Expires= "" ) ; if ( maxAge == 0 ) buf . append ( __01Jan1970_COOKIE ) ; else formatCookieDate ( buf , System . currentTimeMillis ( ) + 1000L * maxAge ) ; if ( version > 0 ) { buf . append ( "" ;Max-Age= "" ) ; buf . append ( maxAge ) ; } } else if ( version > 0 ) { buf . append ( "" ;Discard "" ) ; } if ( isSecure ) buf . append ( "" ;Secure "" ) ; if ( isHttpOnly ) buf . append ( "" ;HttpOnly "" ) ; name_value_params = buf . toString ( ) ; // look for existing set cookie of same name Field field = getField ( HttpHeaders . SET_COOKIE_BUFFER ) ; if ( field != null ) { final int revision = _revision ; while ( field != null ) { if ( field . _revision == revision && field . _value != null && field . _value . toString ( ) . startsWith ( start ) ) { field . reset ( new ByteArrayBuffer ( name_value_params ) , - 1 , revision ) ; name_value_params = null ; break ; } field = field . _next ; } } if ( name_value_params != null ) add ( HttpHeaders . SET_COOKIE_BUFFER , new ByteArrayBuffer ( name_value_params ) ) ; // Expire responses with set-cookie headers so they do not get cached. put ( HttpHeaders . EXPIRES_BUFFER , __01Jan1970_BUFFER ) ; }",2009-03-24 21:07:27 +0000,2011-05-17 06:55:40 +0000,0,0.8087586085113897
1646,193,https://www.github.com/graylog2/graylog2-server,testChunksToByteArray(),,106,106,138,138,TODO review the generated test code and remove the default call to fail.,https://www.github.com/graylog2/graylog2-server/commit/81c21bc5e76,https://www.github.com/graylog2/graylog2-server/commit/bc62bc8bacb24f99eb8da68dac50c58599f79d08,src/test/java/org/graylog2/inputs/gelf/GELFChunkManagerTest.java,"@Test
public void testChunksToByteArray() throws Exception {
System.out.println(""chunksToByteArray"");
String messageId = """";
GELFChunkManager instance = new GELFChunkManager();
byte[] expResult = null;
byte[] result = instance.chunksToByteArray(messageId);
assertEquals(expResult, result);
// TODO review the generated test code and remove the default call to fail.
fail(""The test case is a prototype."");
}","@Test
public void testChunksToByteArray() throws Exception {
GELFChunkManager mgr = new GELFChunkManager();
byte[] b1 = TestHelper.gzipCompress(""nothing"");
byte[] b2 = TestHelper.gzipCompress(""tosee"");
byte[] b3 = TestHelper.gzipCompress(""here"");
byte[] b12 = ArrayUtils.addAll(b1, b2);
byte[] expected = ArrayUtils.addAll(b12, b3);
String msgId = ""foobar00"";
mgr.insert(new GELFMessageChunk(TestHelper.buildGELFMessageChunk(msgId, 0, 3, b1)));
mgr.insert(new GELFMessageChunk(TestHelper.buildGELFMessageChunk(msgId, 1, 3, b2)));
mgr.insert(new GELFMessageChunk(TestHelper.buildGELFMessageChunk(msgId, 2, 3, b3)));
// And another message, to confuse stuff.
mgr.insert(new GELFMessageChunk(TestHelper.buildGELFMessageChunk(""hahahaha"", 2, 3, b1)));
assertArrayEquals(expected, mgr.chunksToByteArray(TestHelper.toHex(msgId)));
}","@ Test public void testChunksToByteArray  ( ) throws Exception  { System . out . println ( "" chunksToByteArray "" ) ; String messageId = "" "" ; GELFChunkManager instance = new GELFChunkManager ( ) ; byte [ ] expResult = null ; byte [ ] result = instance . chunksToByteArray ( messageId ) ; assertEquals ( expResult , result ) ; // <SATD_START> TODO review the generated test code and remove the default call to fail. <SATD_END> fail ( "" The test case is a prototype. "" ) ; }","@ Test public void testChunksToByteArray  ( ) throws Exception  { GELFChunkManager mgr = new GELFChunkManager ( ) ; byte [ ] b1 = TestHelper . gzipCompress ( "" nothing "" ) ; byte [ ] b2 = TestHelper . gzipCompress ( "" tosee "" ) ; byte [ ] b3 = TestHelper . gzipCompress ( "" here "" ) ; byte [ ] b12 = ArrayUtils . addAll ( b1 , b2 ) ; byte [ ] expected = ArrayUtils . addAll ( b12 , b3 ) ; String msgId = "" foobar00 "" ; mgr . insert ( new GELFMessageChunk ( TestHelper . buildGELFMessageChunk ( msgId , 0 , 3 , b1 ) ) ) ; mgr . insert ( new GELFMessageChunk ( TestHelper . buildGELFMessageChunk ( msgId , 1 , 3 , b2 ) ) ) ; mgr . insert ( new GELFMessageChunk ( TestHelper . buildGELFMessageChunk ( msgId , 2 , 3 , b3 ) ) ) ; // And another message, to confuse stuff. mgr . insert ( new GELFMessageChunk ( TestHelper . buildGELFMessageChunk ( "" hahahaha "" , 2 , 3 , b1 ) ) ) ; assertArrayEquals ( expected , mgr . chunksToByteArray ( TestHelper . toHex ( msgId ) ) ) ; }",2012-04-16 17:59:05 +0200,2012-04-16 23:21:41 +0200,0,0.21374045801526717
103,90,https://www.github.com/apache/directory-studio,run(IAction),NOT_DESIGN,98,98,98,98,TODO ADD A LOGGER,https://www.github.com/apache/directory-studio/commit/4b9cece110,https://www.github.com/apache/directory-studio/commit/b666e3344e86998aa9e9e6bd1ce185dab79b24e0,ldapstudio-apacheds-configuration/src/main/java/org/apache/directory/ldapstudio/apacheds/configuration/actions/OpenEditorAction.java,"public void run( IAction action )
{
ServerConfiguration serverConfiguration = new ServerConfiguration();
serverConfiguration.setAllowAnonymousAccess( true );
serverConfiguration.setEnableAccessControl( true );
serverConfiguration.setEnableChangePassword( true );
serverConfiguration.setEnableKerberos( true );
serverConfiguration.setEnableNTP( true );
serverConfiguration.setMaxSizeLimit( 10 );
serverConfiguration.setMaxThreads( 20 );
serverConfiguration.setMaxTimeLimit( 30 );
serverConfiguration.setPassword( ""secret"" );
serverConfiguration.setPath( ""/usr/local/apacheds-1.5.0/conf/server.xml"" );
serverConfiguration.setPort( 10389 );
serverConfiguration.setPrincipal( ""uid=admin,ou=system"" );
serverConfiguration.setSynchronizationPeriod( 40 );
serverConfiguration.addExtendedOperation( new ExtendedOperation(
            ""org.apache.directory.server.ldap.support.extended.GracefulShutdownHandler"" ) );
serverConfiguration.addExtendedOperation( new ExtendedOperation(
            ""org.apache.directory.server.ldap.support.extended.LaunchDiagnosticUiHandler"" ) );
serverConfiguration.addInterceptor( new Interceptor( ""NormalizationService"" ) );
serverConfiguration.addInterceptor( new Interceptor( ""AuthenticationService"" ) );
serverConfiguration.addInterceptor( new Interceptor( ""ReferalService"" ) );
serverConfiguration.addInterceptor( new Interceptor( ""AuthorizationService"" ) );
Partition partition = new Partition( ""System Partition"" );
partition.setSuffix( ""ou=system"" );
Attributes attributes = new BasicAttributes( true );
Attribute attribute = new BasicAttribute( ""dc"" );
attribute.add( ""example"" );
attribute.add( ""com"" );
attributes.put( attribute );
partition.setContextEntry( attributes );
partition.setEnableOptimizer( true );
partition.setCacheSize( 1000 );
partition.setSynchronizationOnWrite( true );
partition.addIndexedAttribute( new IndexedAttribute( ""cn"", 100 ) );
partition.addIndexedAttribute( new IndexedAttribute( ""ou"", 30 ) );
partition.setSystemPartition( true );
serverConfiguration.addPartition( partition );
Partition partition2 = new Partition( ""Example Partition"" );
partition2.setSuffix( ""dc=example, dc=com"" );
// TODO Add Context Entry
partition2.setEnableOptimizer( false );
partition2.setCacheSize( 500 );
partition2.setSynchronizationOnWrite( false );
partition2.addIndexedAttribute( new IndexedAttribute( ""uid"", 50 ) );
partition2.addIndexedAttribute( new IndexedAttribute( ""dc"", 15 ) );
partition2.setSystemPartition( false );
serverConfiguration.addPartition( partition2 );
IWorkbenchPage page = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage();
try
        {
page.openEditor( new ServerConfigurationEditorInput( serverConfiguration ), ServerConfigurationEditor.ID );
}
catch ( PartInitException e )
{
// TODO ADD A LOGGER
e.printStackTrace();
}
}","public void run( IAction action )
{
ServerConfiguration serverConfiguration = new ServerConfiguration();
serverConfiguration.setAllowAnonymousAccess( true );
serverConfiguration.setEnableAccessControl( true );
serverConfiguration.setEnableChangePassword( true );
serverConfiguration.setEnableKerberos( true );
serverConfiguration.setEnableNTP( true );
serverConfiguration.setMaxSizeLimit( 10 );
serverConfiguration.setMaxThreads( 20 );
serverConfiguration.setMaxTimeLimit( 30 );
serverConfiguration.setPassword( ""secret"" );
serverConfiguration.setPath( ""/usr/local/apacheds-1.5.0/conf/server.xml"" );
serverConfiguration.setPort( 10389 );
serverConfiguration.setPrincipal( ""uid=admin,ou=system"" );
serverConfiguration.setSynchronizationPeriod( 40 );
serverConfiguration.addExtendedOperation( new ExtendedOperation(
            ""org.apache.directory.server.ldap.support.extended.GracefulShutdownHandler"" ) );
serverConfiguration.addExtendedOperation( new ExtendedOperation(
            ""org.apache.directory.server.ldap.support.extended.LaunchDiagnosticUiHandler"" ) );
serverConfiguration.addInterceptor( new Interceptor( ""NormalizationService"" ) );
serverConfiguration.addInterceptor( new Interceptor( ""AuthenticationService"" ) );
serverConfiguration.addInterceptor( new Interceptor( ""ReferalService"" ) );
serverConfiguration.addInterceptor( new Interceptor( ""AuthorizationService"" ) );
Partition partition = new Partition( ""System Partition"" );
partition.setSuffix( ""ou=system"" );
Attributes attributes = new BasicAttributes( true );
Attribute attribute = new BasicAttribute( ""dc"" );
attribute.add( ""example"" );
attribute.add( ""com"" );
attributes.put( attribute );
partition.setContextEntry( attributes );
partition.setEnableOptimizer( true );
partition.setCacheSize( 1000 );
partition.setSynchronizationOnWrite( true );
partition.addIndexedAttribute( new IndexedAttribute( ""cn"", 100 ) );
partition.addIndexedAttribute( new IndexedAttribute( ""ou"", 30 ) );
partition.setSystemPartition( true );
serverConfiguration.addPartition( partition );
Partition partition2 = new Partition( ""Example Partition"" );
partition2.setSuffix( ""dc=example, dc=com"" );
// TODO Add Context Entry
partition2.setEnableOptimizer( false );
partition2.setCacheSize( 500 );
partition2.setSynchronizationOnWrite( false );
partition2.addIndexedAttribute( new IndexedAttribute( ""uid"", 50 ) );
partition2.addIndexedAttribute( new IndexedAttribute( ""dc"", 15 ) );
partition2.setSystemPartition( false );
serverConfiguration.addPartition( partition2 );
IWorkbenchPage page = PlatformUI.getWorkbench().getActiveWorkbenchWindow().getActivePage();
try
        {
page.openEditor( new ServerConfigurationEditorInput( serverConfiguration ), ServerConfigurationEditor.ID );
}
catch ( PartInitException e )
{
Activator.getDefault().getLog().log(
                new Status( Status.ERROR, Activator.PLUGIN_ID, Status.OK, e.getMessage(), e.getCause() ) );
}
}","public void run  ( IAction action ) { ServerConfiguration serverConfiguration = new ServerConfiguration ( ) ; serverConfiguration . setAllowAnonymousAccess ( true ) ; serverConfiguration . setEnableAccessControl ( true ) ; serverConfiguration . setEnableChangePassword ( true ) ; serverConfiguration . setEnableKerberos ( true ) ; serverConfiguration . setEnableNTP ( true ) ; serverConfiguration . setMaxSizeLimit ( 10 ) ; serverConfiguration . setMaxThreads ( 20 ) ; serverConfiguration . setMaxTimeLimit ( 30 ) ; serverConfiguration . setPassword ( "" secret "" ) ; serverConfiguration . setPath ( "" /usr/local/apacheds-1.5.0/conf/server.xml "" ) ; serverConfiguration . setPort ( 10389 ) ; serverConfiguration . setPrincipal ( "" uid=admin,ou=system "" ) ; serverConfiguration . setSynchronizationPeriod ( 40 ) ; serverConfiguration . addExtendedOperation ( new ExtendedOperation ( "" org.apache.directory.server.ldap.support.extended.GracefulShutdownHandler "" ) ) ; serverConfiguration . addExtendedOperation ( new ExtendedOperation ( "" org.apache.directory.server.ldap.support.extended.LaunchDiagnosticUiHandler "" ) ) ; serverConfiguration . addInterceptor ( new Interceptor ( "" NormalizationService "" ) ) ; serverConfiguration . addInterceptor ( new Interceptor ( "" AuthenticationService "" ) ) ; serverConfiguration . addInterceptor ( new Interceptor ( "" ReferalService "" ) ) ; serverConfiguration . addInterceptor ( new Interceptor ( "" AuthorizationService "" ) ) ; Partition partition = new Partition ( "" System Partition "" ) ; partition . setSuffix ( "" ou=system "" ) ; Attributes attributes = new BasicAttributes ( true ) ; Attribute attribute = new BasicAttribute ( "" dc "" ) ; attribute . add ( "" example "" ) ; attribute . add ( "" com "" ) ; attributes . put ( attribute ) ; partition . setContextEntry ( attributes ) ; partition . setEnableOptimizer ( true ) ; partition . setCacheSize ( 1000 ) ; partition . setSynchronizationOnWrite ( true ) ; partition . addIndexedAttribute ( new IndexedAttribute ( "" cn "" , 100 ) ) ; partition . addIndexedAttribute ( new IndexedAttribute ( "" ou "" , 30 ) ) ; partition . setSystemPartition ( true ) ; serverConfiguration . addPartition ( partition ) ; Partition partition2 = new Partition ( "" Example Partition "" ) ; partition2 . setSuffix ( "" dc=example, dc=com "" ) ; // TODO Add Context Entry partition2 . setEnableOptimizer ( false ) ; partition2 . setCacheSize ( 500 ) ; partition2 . setSynchronizationOnWrite ( false ) ; partition2 . addIndexedAttribute ( new IndexedAttribute ( "" uid "" , 50 ) ) ; partition2 . addIndexedAttribute ( new IndexedAttribute ( "" dc "" , 15 ) ) ; partition2 . setSystemPartition ( false ) ; serverConfiguration . addPartition ( partition2 ) ; IWorkbenchPage page = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) . getActivePage ( ) ; try { page . openEditor ( new ServerConfigurationEditorInput ( serverConfiguration ) , ServerConfigurationEditor . ID ) ; } catch ( PartInitException e ) { // <SATD_START> TODO ADD A LOGGER <SATD_END> e . printStackTrace ( ) ; } }","public void run  ( IAction action ) { ServerConfiguration serverConfiguration = new ServerConfiguration ( ) ; serverConfiguration . setAllowAnonymousAccess ( true ) ; serverConfiguration . setEnableAccessControl ( true ) ; serverConfiguration . setEnableChangePassword ( true ) ; serverConfiguration . setEnableKerberos ( true ) ; serverConfiguration . setEnableNTP ( true ) ; serverConfiguration . setMaxSizeLimit ( 10 ) ; serverConfiguration . setMaxThreads ( 20 ) ; serverConfiguration . setMaxTimeLimit ( 30 ) ; serverConfiguration . setPassword ( "" secret "" ) ; serverConfiguration . setPath ( "" /usr/local/apacheds-1.5.0/conf/server.xml "" ) ; serverConfiguration . setPort ( 10389 ) ; serverConfiguration . setPrincipal ( "" uid=admin,ou=system "" ) ; serverConfiguration . setSynchronizationPeriod ( 40 ) ; serverConfiguration . addExtendedOperation ( new ExtendedOperation ( "" org.apache.directory.server.ldap.support.extended.GracefulShutdownHandler "" ) ) ; serverConfiguration . addExtendedOperation ( new ExtendedOperation ( "" org.apache.directory.server.ldap.support.extended.LaunchDiagnosticUiHandler "" ) ) ; serverConfiguration . addInterceptor ( new Interceptor ( "" NormalizationService "" ) ) ; serverConfiguration . addInterceptor ( new Interceptor ( "" AuthenticationService "" ) ) ; serverConfiguration . addInterceptor ( new Interceptor ( "" ReferalService "" ) ) ; serverConfiguration . addInterceptor ( new Interceptor ( "" AuthorizationService "" ) ) ; Partition partition = new Partition ( "" System Partition "" ) ; partition . setSuffix ( "" ou=system "" ) ; Attributes attributes = new BasicAttributes ( true ) ; Attribute attribute = new BasicAttribute ( "" dc "" ) ; attribute . add ( "" example "" ) ; attribute . add ( "" com "" ) ; attributes . put ( attribute ) ; partition . setContextEntry ( attributes ) ; partition . setEnableOptimizer ( true ) ; partition . setCacheSize ( 1000 ) ; partition . setSynchronizationOnWrite ( true ) ; partition . addIndexedAttribute ( new IndexedAttribute ( "" cn "" , 100 ) ) ; partition . addIndexedAttribute ( new IndexedAttribute ( "" ou "" , 30 ) ) ; partition . setSystemPartition ( true ) ; serverConfiguration . addPartition ( partition ) ; Partition partition2 = new Partition ( "" Example Partition "" ) ; partition2 . setSuffix ( "" dc=example, dc=com "" ) ; // TODO Add Context Entry partition2 . setEnableOptimizer ( false ) ; partition2 . setCacheSize ( 500 ) ; partition2 . setSynchronizationOnWrite ( false ) ; partition2 . addIndexedAttribute ( new IndexedAttribute ( "" uid "" , 50 ) ) ; partition2 . addIndexedAttribute ( new IndexedAttribute ( "" dc "" , 15 ) ) ; partition2 . setSystemPartition ( false ) ; serverConfiguration . addPartition ( partition2 ) ; IWorkbenchPage page = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) . getActivePage ( ) ; try { page . openEditor ( new ServerConfigurationEditorInput ( serverConfiguration ) , ServerConfigurationEditor . ID ) ; } catch ( PartInitException e ) { Activator . getDefault ( ) . getLog ( ) . log ( new Status ( Status . ERROR , Activator . PLUGIN_ID , Status . OK , e . getMessage ( ) , e . getCause ( ) ) ) ; } }",2007-04-04 17:10:44 +0000,2007-04-16 15:08:36 +0000,0,0.9659292749878896
314,617,https://www.github.com/apache/sqoop,"importTable(String, String, Configuration)",DESIGN,122,122,122,122,TODO(aaron): This is really insecure.,https://www.github.com/apache/sqoop/commit/bf65299ba,https://www.github.com/apache/sqoop/commit/3c322c9969b4fe775803db91a52f3a5fd77eb010,src/java/org/apache/hadoop/sqoop/manager/LocalMySQLManager.java,"public void importTable(String tableName, String jarFile, Configuration conf)
throws IOException, ImportError {
LOG.info(""Beginning mysqldump fast path import"");
if (options.getFileLayout() != ImportOptions.FileLayout.TextFile) {
// TODO(aaron): Support SequenceFile-based load-in
LOG.warn(""File import layout "" + options.getFileLayout()
+ "" is not supported by"");
LOG.warn(""MySQL local import; import will proceed as text files."");
}
ArrayList<String> args = new ArrayList<String>();
// We need to parse the connect string URI to determine the database
// name. Using java.net.URL directly on the connect string will fail because
// Java doesn't respect arbitrary JDBC-based schemes. So we chop off the scheme
// (everything before '://') and replace it with 'http', which we know will work.
String connectString = options.getConnectString();
String databaseName = null;
try {
String sanitizedString = null;
int schemeEndOffset = connectString.indexOf(""://"");
if (-1 == schemeEndOffset) {
// couldn't find one? try our best here.
sanitizedString = ""http://"" + connectString;
LOG.warn(""Could not find database access scheme in connect string "" + connectString);
} else {
sanitizedString = ""http"" + connectString.substring(schemeEndOffset);
}
URL connectUrl = new URL(sanitizedString);
databaseName = connectUrl.getPath();
} catch (MalformedURLException mue) {
LOG.error(""Malformed connect string URL: "" + connectString
+ ""; reason is "" + mue.toString());
}
if (null == databaseName) {
throw new ImportError(""Could not determine database name"");
}
// database name was found from the 'path' part of the URL; trim leading '/'
while (databaseName.startsWith(""/"")) {
databaseName = databaseName.substring(1);
}
LOG.info(""Performing import of table "" + tableName + "" from database "" + databaseName);
args.add(MYSQL_DUMP_CMD); // requires that this is on the path.
args.add(""--skip-opt"");
args.add(""--compact"");
args.add(""--no-create-db"");
args.add(""--no-create-info"");
String username = options.getUsername();
if (null != username) {
args.add(""--user="" + username);
}
String password = options.getPassword();
if (null != password) {
// TODO(aaron): This is really insecure.
args.add(""--password="" + password);
}
String whereClause = options.getWhereClause();
if (null != whereClause) {
// Don't use the --where=""<whereClause>"" version because spaces in it can confuse
// Java, and adding in surrounding quotes confuses Java as well.
args.add(""-w"");
args.add(whereClause);
}
args.add(""--quick""); // no buffering
// TODO(aaron): Add a flag to allow --lock-tables instead for MyISAM data
args.add(""--single-transaction"");
args.add(databaseName);
args.add(tableName);
Process p = null;
try {
// begin the import in an external process.
LOG.debug(""Starting mysqldump with arguments:"");
for (String arg : args) {
LOG.debug(""  "" + arg);
}
p = Runtime.getRuntime().exec(args.toArray(new String[0]));
// read from the pipe, into HDFS.
InputStream is = p.getInputStream();
OutputStream os = null;
BufferedReader r = null;
BufferedWriter w = null;
try {
r = new BufferedReader(new InputStreamReader(is));
// create the paths/files in HDFS 
FileSystem fs = FileSystem.get(conf);
String warehouseDir = options.getWarehouseDir();
Path destDir = null;
if (null != warehouseDir) {
destDir = new Path(new Path(warehouseDir), tableName);
} else {
destDir = new Path(tableName);
}
LOG.debug(""Writing to filesystem: "" + conf.get(""fs.default.name""));
LOG.debug(""Creating destination directory "" + destDir);
fs.mkdirs(destDir);
Path destFile = new Path(destDir, ""data-00000"");
LOG.debug(""Opening output file: "" + destFile);
if (fs.exists(destFile)) {
Path canonicalDest = destFile.makeQualified(fs);
throw new IOException(""Destination file "" + canonicalDest + "" already exists"");
}
os = fs.create(destFile);
w = new BufferedWriter(new OutputStreamWriter(os));
// Actually do the read/write transfer loop here.
int preambleLen = -1; // set to this for ""undefined""
while (true) {
String inLine = r.readLine();
if (null == inLine) {
break; // EOF.
}
// this line is of the form ""INSERT .. VALUES ( actual value text );""
// strip the leading preamble up to the '(' and the trailing ');'.
if (preambleLen == -1) {
// we haven't determined how long the preamble is. It's constant
// across all lines, so just figure this out once.
String recordStartMark = ""VALUES ("";
preambleLen = inLine.indexOf(recordStartMark) + recordStartMark.length();
}
// chop off the leading and trailing text as we write the
// output to HDFS.
w.write(inLine, preambleLen, inLine.length() - 2 - preambleLen);
w.newLine();
}
} finally {
LOG.info(""Transfer loop complete."");
if (null != r) {
try {
r.close();
} catch (IOException ioe) {
LOG.info(""Error closing FIFO stream: "" + ioe.toString());
}
}
if (null != w) {
try {
w.close();
} catch (IOException ioe) {
LOG.info(""Error closing HDFS stream: "" + ioe.toString());
}
}
}
} finally {
int result = 0;
if (null != p) {
while (true) {
try {
result = p.waitFor();
} catch (InterruptedException ie) {
// interrupted; loop around.
continue;
}
break;
}
}
if (0 != result) {
throw new IOException(""mysqldump terminated with status ""
+ Integer.toString(result));
}
}
}","public void importTable(String tableName, String jarFile, Configuration conf)
throws IOException, ImportError {
LOG.info(""Beginning mysqldump fast path import"");
if (options.getFileLayout() != ImportOptions.FileLayout.TextFile) {
// TODO(aaron): Support SequenceFile-based load-in
LOG.warn(""File import layout "" + options.getFileLayout()
+ "" is not supported by"");
LOG.warn(""MySQL local import; import will proceed as text files."");
}
ArrayList<String> args = new ArrayList<String>();
// We need to parse the connect string URI to determine the database
// name. Using java.net.URL directly on the connect string will fail because
// Java doesn't respect arbitrary JDBC-based schemes. So we chop off the scheme
// (everything before '://') and replace it with 'http', which we know will work.
String connectString = options.getConnectString();
String databaseName = null;
try {
String sanitizedString = null;
int schemeEndOffset = connectString.indexOf(""://"");
if (-1 == schemeEndOffset) {
// couldn't find one? try our best here.
sanitizedString = ""http://"" + connectString;
LOG.warn(""Could not find database access scheme in connect string "" + connectString);
} else {
sanitizedString = ""http"" + connectString.substring(schemeEndOffset);
}
URL connectUrl = new URL(sanitizedString);
databaseName = connectUrl.getPath();
} catch (MalformedURLException mue) {
LOG.error(""Malformed connect string URL: "" + connectString
+ ""; reason is "" + mue.toString());
}
if (null == databaseName) {
throw new ImportError(""Could not determine database name"");
}
// database name was found from the 'path' part of the URL; trim leading '/'
while (databaseName.startsWith(""/"")) {
databaseName = databaseName.substring(1);
}
LOG.info(""Performing import of table "" + tableName + "" from database "" + databaseName);
Process p = null;
args.add(MYSQL_DUMP_CMD); // requires that this is on the path.
String password = options.getPassword();
String passwordFile = null;
try {
// --defaults-file must be the first argument.
if (null != password && password.length() > 0) {
passwordFile = writePasswordFile();
args.add(""--defaults-file="" + passwordFile);
}
String whereClause = options.getWhereClause();
if (null != whereClause) {
// Don't use the --where=""<whereClause>"" version because spaces in it can confuse
// Java, and adding in surrounding quotes confuses Java as well.
args.add(""-w"");
args.add(whereClause);
}
args.add(""--skip-opt"");
args.add(""--compact"");
args.add(""--no-create-db"");
args.add(""--no-create-info"");
args.add(""--quick""); // no buffering
// TODO(aaron): Add a flag to allow --lock-tables instead for MyISAM data
args.add(""--single-transaction"");
String username = options.getUsername();
if (null != username) {
args.add(""--user="" + username);
}
args.add(databaseName);
args.add(tableName);
// begin the import in an external process.
LOG.debug(""Starting mysqldump with arguments:"");
for (String arg : args) {
LOG.debug(""  "" + arg);
}
p = Runtime.getRuntime().exec(args.toArray(new String[0]));
// read from the pipe, into HDFS.
InputStream is = p.getInputStream();
OutputStream os = null;
BufferedReader r = null;
BufferedWriter w = null;
try {
r = new BufferedReader(new InputStreamReader(is));
// create the paths/files in HDFS 
FileSystem fs = FileSystem.get(conf);
String warehouseDir = options.getWarehouseDir();
Path destDir = null;
if (null != warehouseDir) {
destDir = new Path(new Path(warehouseDir), tableName);
} else {
destDir = new Path(tableName);
}
LOG.debug(""Writing to filesystem: "" + conf.get(""fs.default.name""));
LOG.debug(""Creating destination directory "" + destDir);
fs.mkdirs(destDir);
Path destFile = new Path(destDir, ""data-00000"");
LOG.debug(""Opening output file: "" + destFile);
if (fs.exists(destFile)) {
Path canonicalDest = destFile.makeQualified(fs);
throw new IOException(""Destination file "" + canonicalDest + "" already exists"");
}
os = fs.create(destFile);
w = new BufferedWriter(new OutputStreamWriter(os));
// Actually do the read/write transfer loop here.
int preambleLen = -1; // set to this for ""undefined""
while (true) {
String inLine = r.readLine();
if (null == inLine) {
break; // EOF.
}
// this line is of the form ""INSERT .. VALUES ( actual value text );""
// strip the leading preamble up to the '(' and the trailing ');'.
if (preambleLen == -1) {
// we haven't determined how long the preamble is. It's constant
// across all lines, so just figure this out once.
String recordStartMark = ""VALUES ("";
preambleLen = inLine.indexOf(recordStartMark) + recordStartMark.length();
}
// chop off the leading and trailing text as we write the
// output to HDFS.
w.write(inLine, preambleLen, inLine.length() - 2 - preambleLen);
w.newLine();
}
} finally {
LOG.info(""Transfer loop complete."");
if (null != r) {
try {
r.close();
} catch (IOException ioe) {
LOG.info(""Error closing FIFO stream: "" + ioe.toString());
}
}
if (null != w) {
try {
w.close();
} catch (IOException ioe) {
LOG.info(""Error closing HDFS stream: "" + ioe.toString());
}
}
}
} finally {
int result = 0;
if (null != p) {
while (true) {
try {
result = p.waitFor();
} catch (InterruptedException ie) {
// interrupted; loop around.
continue;
}
break;
}
}
// Remove the password file.
if (null != passwordFile) {
if (!new File(passwordFile).delete()) {
LOG.error(""Could not remove mysql password file "" + passwordFile);
LOG.error(""You should remove this file to protect your credentials."");
}
}
if (0 != result) {
throw new IOException(""mysqldump terminated with status ""
+ Integer.toString(result));
}
}
}","public void importTable  ( String tableName , String jarFile , Configuration conf ) throws IOException , ImportError { LOG . info ( "" Beginning mysqldump fast path import "" ) ; if ( options . getFileLayout ( ) != ImportOptions . FileLayout . TextFile ) { // TODO(aaron): Support SequenceFile-based load-in LOG . warn ( "" File import layout  "" + options . getFileLayout ( ) + ""  is not supported by "" ) ; LOG . warn ( "" MySQL local import; import will proceed as text files. "" ) ; } ArrayList < String > args = new ArrayList < String > ( ) ; // We need to parse the connect string URI to determine the database // name. Using java.net.URL directly on the connect string will fail because // Java doesn't respect arbitrary JDBC-based schemes. So we chop off the scheme // (everything before '://') and replace it with 'http', which we know will work. String connectString = options . getConnectString ( ) ; String databaseName = null ; try { String sanitizedString = null ; int schemeEndOffset = connectString . indexOf ( "" :// "" ) ; if ( - 1 == schemeEndOffset ) { // couldn't find one? try our best here. sanitizedString = "" http:// "" + connectString ; LOG . warn ( "" Could not find database access scheme in connect string  "" + connectString ) ; } else { sanitizedString = "" http "" + connectString . substring ( schemeEndOffset ) ; } URL connectUrl = new URL ( sanitizedString ) ; databaseName = connectUrl . getPath ( ) ; } catch ( MalformedURLException mue ) { LOG . error ( "" Malformed connect string URL:  "" + connectString + "" ; reason is  "" + mue . toString ( ) ) ; } if ( null == databaseName ) { throw new ImportError ( "" Could not determine database name "" ) ; } // database name was found from the 'path' part of the URL; trim leading '/' while ( databaseName . startsWith ( "" / "" ) ) { databaseName = databaseName . substring ( 1 ) ; } LOG . info ( "" Performing import of table  "" + tableName + ""  from database  "" + databaseName ) ; args . add ( MYSQL_DUMP_CMD ) ; // requires that this is on the path. args . add ( "" --skip-opt "" ) ; args . add ( "" --compact "" ) ; args . add ( "" --no-create-db "" ) ; args . add ( "" --no-create-info "" ) ; String username = options . getUsername ( ) ; if ( null != username ) { args . add ( "" --user= "" + username ) ; } String password = options . getPassword ( ) ; if ( null != password ) { // <SATD_START> TODO(aaron): This is really insecure. <SATD_END> args . add ( "" --password= "" + password ) ; } String whereClause = options . getWhereClause ( ) ; if ( null != whereClause ) { // Don't use the --where=""<whereClause>"" version because spaces in it can confuse // Java, and adding in surrounding quotes confuses Java as well. args . add ( "" -w "" ) ; args . add ( whereClause ) ; } args . add ( "" --quick "" ) ; // no buffering // TODO(aaron): Add a flag to allow --lock-tables instead for MyISAM data args . add ( "" --single-transaction "" ) ; args . add ( databaseName ) ; args . add ( tableName ) ; Process p = null ; try { // begin the import in an external process. LOG . debug ( "" Starting mysqldump with arguments: "" ) ; for ( String arg : args ) { LOG . debug ( ""    "" + arg ) ; } p = Runtime . getRuntime ( ) . exec ( args . toArray ( new String [ 0 ] ) ) ; // read from the pipe, into HDFS. InputStream is = p . getInputStream ( ) ; OutputStream os = null ; BufferedReader r = null ; BufferedWriter w = null ; try { r = new BufferedReader ( new InputStreamReader ( is ) ) ; // create the paths/files in HDFS  FileSystem fs = FileSystem . get ( conf ) ; String warehouseDir = options . getWarehouseDir ( ) ; Path destDir = null ; if ( null != warehouseDir ) { destDir = new Path ( new Path ( warehouseDir ) , tableName ) ; } else { destDir = new Path ( tableName ) ; } LOG . debug ( "" Writing to filesystem:  "" + conf . get ( "" fs.default.name "" ) ) ; LOG . debug ( "" Creating destination directory  "" + destDir ) ; fs . mkdirs ( destDir ) ; Path destFile = new Path ( destDir , "" data-00000 "" ) ; LOG . debug ( "" Opening output file:  "" + destFile ) ; if ( fs . exists ( destFile ) ) { Path canonicalDest = destFile . makeQualified ( fs ) ; throw new IOException ( "" Destination file  "" + canonicalDest + ""  already exists "" ) ; } os = fs . create ( destFile ) ; w = new BufferedWriter ( new OutputStreamWriter ( os ) ) ; // Actually do the read/write transfer loop here. int preambleLen = - 1 ; // set to this for ""undefined"" while ( true ) { String inLine = r . readLine ( ) ; if ( null == inLine ) { break ; // EOF. } // this line is of the form ""INSERT .. VALUES ( actual value text );"" // strip the leading preamble up to the '(' and the trailing ');'. if ( preambleLen == - 1 ) { // we haven't determined how long the preamble is. It's constant // across all lines, so just figure this out once. String recordStartMark = "" VALUES ( "" ; preambleLen = inLine . indexOf ( recordStartMark ) + recordStartMark . length ( ) ; } // chop off the leading and trailing text as we write the // output to HDFS. w . write ( inLine , preambleLen , inLine . length ( ) - 2 - preambleLen ) ; w . newLine ( ) ; } } finally { LOG . info ( "" Transfer loop complete. "" ) ; if ( null != r ) { try { r . close ( ) ; } catch ( IOException ioe ) { LOG . info ( "" Error closing FIFO stream:  "" + ioe . toString ( ) ) ; } } if ( null != w ) { try { w . close ( ) ; } catch ( IOException ioe ) { LOG . info ( "" Error closing HDFS stream:  "" + ioe . toString ( ) ) ; } } } } finally { int result = 0 ; if ( null != p ) { while ( true ) { try { result = p . waitFor ( ) ; } catch ( InterruptedException ie ) { // interrupted; loop around. continue ; } break ; } } if ( 0 != result ) { throw new IOException ( "" mysqldump terminated with status  "" + Integer . toString ( result ) ) ; } } }","public void importTable  ( String tableName , String jarFile , Configuration conf ) throws IOException , ImportError { LOG . info ( "" Beginning mysqldump fast path import "" ) ; if ( options . getFileLayout ( ) != ImportOptions . FileLayout . TextFile ) { // TODO(aaron): Support SequenceFile-based load-in LOG . warn ( "" File import layout  "" + options . getFileLayout ( ) + ""  is not supported by "" ) ; LOG . warn ( "" MySQL local import; import will proceed as text files. "" ) ; } ArrayList < String > args = new ArrayList < String > ( ) ; // We need to parse the connect string URI to determine the database // name. Using java.net.URL directly on the connect string will fail because // Java doesn't respect arbitrary JDBC-based schemes. So we chop off the scheme // (everything before '://') and replace it with 'http', which we know will work. String connectString = options . getConnectString ( ) ; String databaseName = null ; try { String sanitizedString = null ; int schemeEndOffset = connectString . indexOf ( "" :// "" ) ; if ( - 1 == schemeEndOffset ) { // couldn't find one? try our best here. sanitizedString = "" http:// "" + connectString ; LOG . warn ( "" Could not find database access scheme in connect string  "" + connectString ) ; } else { sanitizedString = "" http "" + connectString . substring ( schemeEndOffset ) ; } URL connectUrl = new URL ( sanitizedString ) ; databaseName = connectUrl . getPath ( ) ; } catch ( MalformedURLException mue ) { LOG . error ( "" Malformed connect string URL:  "" + connectString + "" ; reason is  "" + mue . toString ( ) ) ; } if ( null == databaseName ) { throw new ImportError ( "" Could not determine database name "" ) ; } // database name was found from the 'path' part of the URL; trim leading '/' while ( databaseName . startsWith ( "" / "" ) ) { databaseName = databaseName . substring ( 1 ) ; } LOG . info ( "" Performing import of table  "" + tableName + ""  from database  "" + databaseName ) ; Process p = null ; args . add ( MYSQL_DUMP_CMD ) ; // requires that this is on the path. String password = options . getPassword ( ) ; String passwordFile = null ; try { // --defaults-file must be the first argument. if ( null != password && password . length ( ) > 0 ) { passwordFile = writePasswordFile ( ) ; args . add ( "" --defaults-file= "" + passwordFile ) ; } String whereClause = options . getWhereClause ( ) ; if ( null != whereClause ) { // Don't use the --where=""<whereClause>"" version because spaces in it can confuse // Java, and adding in surrounding quotes confuses Java as well. args . add ( "" -w "" ) ; args . add ( whereClause ) ; } args . add ( "" --skip-opt "" ) ; args . add ( "" --compact "" ) ; args . add ( "" --no-create-db "" ) ; args . add ( "" --no-create-info "" ) ; args . add ( "" --quick "" ) ; // no buffering // TODO(aaron): Add a flag to allow --lock-tables instead for MyISAM data args . add ( "" --single-transaction "" ) ; String username = options . getUsername ( ) ; if ( null != username ) { args . add ( "" --user= "" + username ) ; } args . add ( databaseName ) ; args . add ( tableName ) ; // begin the import in an external process. LOG . debug ( "" Starting mysqldump with arguments: "" ) ; for ( String arg : args ) { LOG . debug ( ""    "" + arg ) ; } p = Runtime . getRuntime ( ) . exec ( args . toArray ( new String [ 0 ] ) ) ; // read from the pipe, into HDFS. InputStream is = p . getInputStream ( ) ; OutputStream os = null ; BufferedReader r = null ; BufferedWriter w = null ; try { r = new BufferedReader ( new InputStreamReader ( is ) ) ; // create the paths/files in HDFS  FileSystem fs = FileSystem . get ( conf ) ; String warehouseDir = options . getWarehouseDir ( ) ; Path destDir = null ; if ( null != warehouseDir ) { destDir = new Path ( new Path ( warehouseDir ) , tableName ) ; } else { destDir = new Path ( tableName ) ; } LOG . debug ( "" Writing to filesystem:  "" + conf . get ( "" fs.default.name "" ) ) ; LOG . debug ( "" Creating destination directory  "" + destDir ) ; fs . mkdirs ( destDir ) ; Path destFile = new Path ( destDir , "" data-00000 "" ) ; LOG . debug ( "" Opening output file:  "" + destFile ) ; if ( fs . exists ( destFile ) ) { Path canonicalDest = destFile . makeQualified ( fs ) ; throw new IOException ( "" Destination file  "" + canonicalDest + ""  already exists "" ) ; } os = fs . create ( destFile ) ; w = new BufferedWriter ( new OutputStreamWriter ( os ) ) ; // Actually do the read/write transfer loop here. int preambleLen = - 1 ; // set to this for ""undefined"" while ( true ) { String inLine = r . readLine ( ) ; if ( null == inLine ) { break ; // EOF. } // this line is of the form ""INSERT .. VALUES ( actual value text );"" // strip the leading preamble up to the '(' and the trailing ');'. if ( preambleLen == - 1 ) { // we haven't determined how long the preamble is. It's constant // across all lines, so just figure this out once. String recordStartMark = "" VALUES ( "" ; preambleLen = inLine . indexOf ( recordStartMark ) + recordStartMark . length ( ) ; } // chop off the leading and trailing text as we write the // output to HDFS. w . write ( inLine , preambleLen , inLine . length ( ) - 2 - preambleLen ) ; w . newLine ( ) ; } } finally { LOG . info ( "" Transfer loop complete. "" ) ; if ( null != r ) { try { r . close ( ) ; } catch ( IOException ioe ) { LOG . info ( "" Error closing FIFO stream:  "" + ioe . toString ( ) ) ; } } if ( null != w ) { try { w . close ( ) ; } catch ( IOException ioe ) { LOG . info ( "" Error closing HDFS stream:  "" + ioe . toString ( ) ) ; } } } } finally { int result = 0 ; if ( null != p ) { while ( true ) { try { result = p . waitFor ( ) ; } catch ( InterruptedException ie ) { // interrupted; loop around. continue ; } break ; } } // Remove the password file. if ( null != passwordFile ) { if ( ! new File ( passwordFile ) . delete ( ) ) { LOG . error ( "" Could not remove mysql password file  "" + passwordFile ) ; LOG . error ( "" You should remove this file to protect your credentials. "" ) ; } } if ( 0 != result ) { throw new IOException ( "" mysqldump terminated with status  "" + Integer . toString ( result ) ) ; } } }",2011-07-22 20:03:19 +0000,2011-07-22 20:03:22 +0000,0,0.8594425146149284
2234,207,https://www.github.com/cbeust/testng,testRetryCounts(),DESIGN,21,21,21,21,TODO re-enabled after #740 or #1104 is fixed/merged,https://www.github.com/cbeust/testng/commit/041aba591,https://www.github.com/cbeust/testng/commit/b2db8d216270dedf740e6f683540289b34d26197,src/test/java/test/retryAnalyzer/dataprovider/RetryAnalyzerWithDataProviderTest.java,"@Test
public void testRetryCounts() {
TestNG tng = create(RetryCountTest.class);
TestListenerAdapter tla = new TestListenerAdapter();
tng.addListener(tla);
tng.run();
// TODO re-enabled after #740 or #1104 is fixed/merged
//    assertEquals(tla.getPassedTests().size(), 1);
assertEquals(tla.getPassedTests().get(0).getParameters(), new String[]{""c""});
assertEquals(tla.getFailedTests().size(), 3);
assertEquals(tla.getSkippedTests().size(), 9);
}","@Test
public void testRetryCounts() {
TestNG tng = create(RetryCountTest.class);
TestListenerAdapter tla = new TestListenerAdapter();
tng.addListener(tla);
tng.run();
assertEquals(tla.getPassedTests().size(), 1);
assertEquals(tla.getPassedTests().get(0).getParameters(), new String[]{""c""});
assertEquals(tla.getFailedTests().size(), 3);
assertEquals(tla.getSkippedTests().size(), 9);
}","@ Test public void testRetryCounts  ( ) { TestNG tng = create ( RetryCountTest . class ) ; TestListenerAdapter tla = new TestListenerAdapter ( ) ; tng . addListener ( tla ) ; tng . run ( ) ; // <SATD_START> TODO re-enabled after #740 or #1104 is fixed/merged <SATD_END> //    assertEquals(tla.getPassedTests().size(), 1); assertEquals ( tla . getPassedTests ( ) . get ( 0 ) . getParameters ( ) , new String [ ] { "" c "" } ) ; assertEquals ( tla . getFailedTests ( ) . size ( ) , 3 ) ; assertEquals ( tla . getSkippedTests ( ) . size ( ) , 9 ) ; }","@ Test public void testRetryCounts  ( ) { TestNG tng = create ( RetryCountTest . class ) ; TestListenerAdapter tla = new TestListenerAdapter ( ) ; tng . addListener ( tla ) ; tng . run ( ) ; assertEquals ( tla . getPassedTests ( ) . size ( ) , 1 ) ; assertEquals ( tla . getPassedTests ( ) . get ( 0 ) . getParameters ( ) , new String [ ] { "" c "" } ) ; assertEquals ( tla . getFailedTests ( ) . size ( ) , 3 ) ; assertEquals ( tla . getSkippedTests ( ) . size ( ) , 9 ) ; }",2016-07-28 19:07:26 +0200,2016-07-28 19:37:13 +0200,0,0.8821218074656189
1036,624,https://www.github.com/dana-i2cat/opennaas,updateVRRPIp(VCPENetworkModel),,202,202,202,202,TODO Recover the VRRPProtocolEndpoint,https://www.github.com/dana-i2cat/opennaas/commit/369232fcde,https://www.github.com/dana-i2cat/opennaas/commit/145d95ba041235c281d6f19caf06c2ac61679b7c,extensions/bundles/vcpe/src/main/java/org/opennaas/extensions/vcpe/capability/builder/VCPENetworkBuilder.java,"@Override
public void updateVRRPIp(VCPENetworkModel model) throws CapabilityException {
log.debug(""Updating VRRP ip"");
try {
Router lr1 = (Router) VCPENetworkModelHelper.getElementByTemplateName(model, VCPETemplate.VCPE1_ROUTER);
Router lr2 = (Router) VCPENetworkModelHelper.getElementByTemplateName(model, VCPETemplate.VCPE2_ROUTER);
IResource router1Resource = getResourceManager().getResource(
					getResourceManager().getIdentifierFromResourceName(""router"", lr1.getName()));
IResource router2Resource = getResourceManager().getResource(
					getResourceManager().getIdentifierFromResourceName(""router"", lr2.getName()));
IVRRPCapability capability1 = (IVRRPCapability) router1Resource.getCapabilityByInterface(IVRRPCapability.class);
// TODO Recover the VRRPProtocolEndpoint
capability1.updateVRRPVirtualIPAddress(null);
IVRRPCapability capability2 = (IVRRPCapability) router2Resource.getCapabilityByInterface(IVRRPCapability.class);
// TODO Recover the VRRPProtocolEndpoint
capability2.updateVRRPVirtualIPAddress(null);
} catch (ResourceException e) {
throw new CapabilityException(e);
}
}","@Override
public void updateVRRPIp(VCPENetworkModel vcpeModel) throws CapabilityException {
log.debug(""Updating VRRP ip"");
try {
Router lr1 = (Router) VCPENetworkModelHelper.getElementByTemplateName(vcpeModel, VCPETemplate.VCPE1_ROUTER);
Router lr2 = (Router) VCPENetworkModelHelper.getElementByTemplateName(vcpeModel, VCPETemplate.VCPE2_ROUTER);
IResource router1 = getResourceManager().getResource(
					getResourceManager().getIdentifierFromResourceName(""router"", lr1.getName()));
IResource router2 = getResourceManager().getResource(
					getResourceManager().getIdentifierFromResourceName(""router"", lr2.getName()));
IVRRPCapability capability1 = (IVRRPCapability) router1.getCapabilityByInterface(IVRRPCapability.class);
IVRRPCapability capability2 = (IVRRPCapability) router2.getCapabilityByInterface(IVRRPCapability.class);
VRRPProtocolEndpoint endpointRouter1 = getVRRPProtocolEndpointDeepCopy((ComputerSystem) router1.getModel());
((VRRPGroup) endpointRouter1.getService()).setVirtualIPAddress(vcpeModel.getVrrp().getVirtualIPAddress());
VRRPProtocolEndpoint endpointRouter2 = getVRRPProtocolEndpointDeepCopy((ComputerSystem) router2.getModel());
((VRRPGroup) endpointRouter2.getService()).setVirtualIPAddress(vcpeModel.getVrrp().getVirtualIPAddress());
capability1.updateVRRPVirtualIPAddress(endpointRouter1);
capability2.updateVRRPVirtualIPAddress(endpointRouter2);
execute(router1);
execute(router2);
} catch (Exception e) {
throw new CapabilityException(e);
}
}","@ Override public void updateVRRPIp  ( VCPENetworkModel model ) throws CapabilityException { log . debug ( "" Updating VRRP ip "" ) ; try { Router lr1 = ( Router ) VCPENetworkModelHelper . getElementByTemplateName ( model , VCPETemplate . VCPE1_ROUTER ) ; Router lr2 = ( Router ) VCPENetworkModelHelper . getElementByTemplateName ( model , VCPETemplate . VCPE2_ROUTER ) ; IResource router1Resource = getResourceManager ( ) . getResource ( getResourceManager ( ) . getIdentifierFromResourceName ( "" router "" , lr1 . getName ( ) ) ) ; IResource router2Resource = getResourceManager ( ) . getResource ( getResourceManager ( ) . getIdentifierFromResourceName ( "" router "" , lr2 . getName ( ) ) ) ; IVRRPCapability capability1 = ( IVRRPCapability ) router1Resource . getCapabilityByInterface ( IVRRPCapability . class ) ; // <SATD_START> TODO Recover the VRRPProtocolEndpoint <SATD_END> capability1 . updateVRRPVirtualIPAddress ( null ) ; IVRRPCapability capability2 = ( IVRRPCapability ) router2Resource . getCapabilityByInterface ( IVRRPCapability . class ) ; // <SATD_START> TODO Recover the VRRPProtocolEndpoint <SATD_END> capability2 . updateVRRPVirtualIPAddress ( null ) ; } catch ( ResourceException e ) { throw new CapabilityException ( e ) ; } }","@ Override public void updateVRRPIp  ( VCPENetworkModel vcpeModel ) throws CapabilityException { log . debug ( "" Updating VRRP ip "" ) ; try { Router lr1 = ( Router ) VCPENetworkModelHelper . getElementByTemplateName ( vcpeModel , VCPETemplate . VCPE1_ROUTER ) ; Router lr2 = ( Router ) VCPENetworkModelHelper . getElementByTemplateName ( vcpeModel , VCPETemplate . VCPE2_ROUTER ) ; IResource router1 = getResourceManager ( ) . getResource ( getResourceManager ( ) . getIdentifierFromResourceName ( "" router "" , lr1 . getName ( ) ) ) ; IResource router2 = getResourceManager ( ) . getResource ( getResourceManager ( ) . getIdentifierFromResourceName ( "" router "" , lr2 . getName ( ) ) ) ; IVRRPCapability capability1 = ( IVRRPCapability ) router1 . getCapabilityByInterface ( IVRRPCapability . class ) ; IVRRPCapability capability2 = ( IVRRPCapability ) router2 . getCapabilityByInterface ( IVRRPCapability . class ) ; VRRPProtocolEndpoint endpointRouter1 = getVRRPProtocolEndpointDeepCopy ( ( ComputerSystem ) router1 . getModel ( ) ) ; ( ( VRRPGroup ) endpointRouter1 . getService ( ) ) . setVirtualIPAddress ( vcpeModel . getVrrp ( ) . getVirtualIPAddress ( ) ) ; VRRPProtocolEndpoint endpointRouter2 = getVRRPProtocolEndpointDeepCopy ( ( ComputerSystem ) router2 . getModel ( ) ) ; ( ( VRRPGroup ) endpointRouter2 . getService ( ) ) . setVirtualIPAddress ( vcpeModel . getVrrp ( ) . getVirtualIPAddress ( ) ) ; capability1 . updateVRRPVirtualIPAddress ( endpointRouter1 ) ; capability2 . updateVRRPVirtualIPAddress ( endpointRouter2 ) ; execute ( router1 ) ; execute ( router2 ) ; } catch ( Exception e ) { throw new CapabilityException ( e ) ; } }",2012-12-13 14:41:14 +0100,2012-12-14 15:02:38 +0100,0,0.5603864734299517
149,51,https://www.github.com/voldemort/voldemort,"balanceTargetCluster(Cluster, Cluster, List<StoreDefinition>, String, int, boolean, boolean, int, boolean, int, int, int)",,295,295,295,295,TODO: make this an arg,https://www.github.com/voldemort/voldemort/commit/7c9a7393eb,https://www.github.com/voldemort/voldemort/commit/8ff31453505f3a8fdc3cd4a0d22dd701329f184e,src/java/voldemort/utils/RebalanceUtils.java,"public static void balanceTargetCluster(final Cluster currentCluster,
                                            final Cluster targetCluster,
                                            final List<StoreDefinition> storeDefs,
                                            final String outputDir,
                                            final int tries,
                                            final boolean keepPrimaryPartitionsInSameZone,
                                            final boolean permitCrossZoneMoves,
                                            final int varyNumPartitionsPerNode,
                                            final boolean enableRandomSwaps,
                                            final int swapAttempts,
                                            final int swapSuccesses,
                                            final int maxContiguousPartitionsPerZone) {
HashMap<StoreDefinition, Integer> uniqueStores = KeyDistributionGenerator.getUniqueStoreDefinitionsWithCounts(storeDefs);
List<ByteArray> keys = KeyDistributionGenerator.generateKeys(KeyDistributionGenerator.DEFAULT_NUM_KEYS);
Cluster minCluster = targetCluster;
int minMoves = Integer.MAX_VALUE;
// double minStdDev = Double.MAX_VALUE;
double minMaxMinRatio = Double.MAX_VALUE;
Cluster nextCluster;
int xzonePartitionsMoved;
// TODO: make this an arg
final boolean enableGreedySwaps = true;
final int greedySwapAttempts = 1;
for(int numTries = 0; numTries < tries; numTries++) {
nextCluster = targetCluster;
xzonePartitionsMoved = 0;
if(maxContiguousPartitionsPerZone > 0) {
int contigPartitionsMoved = 0;
do {
Pair<Cluster, Integer> contigPartPerZone = RebalanceUtils.balanceContiguousPartitionsPerZone(nextCluster,
                                                                                                                 maxContiguousPartitionsPerZone);
nextCluster = contigPartPerZone.getFirst();
contigPartitionsMoved = contigPartPerZone.getSecond();
xzonePartitionsMoved += contigPartPerZone.getSecond();
Pair<Cluster, Integer> balanceXZone = RebalanceUtils.balanceNumPartitionsPerZone(nextCluster);
nextCluster = balanceXZone.getFirst();
xzonePartitionsMoved += balanceXZone.getSecond();
System.out.println(""Looping to evenly balance partitions across zones while limiting contiguous partitions: ""
+ contigPartitionsMoved);
} while(contigPartitionsMoved > 0);
}
Pair<Cluster, Integer> numPartPerZone = RebalanceUtils.balanceNumberOfPartitionsPerNode(nextCluster,
                                                                                                    storeDefs,
                                                                                                    keepPrimaryPartitionsInSameZone,
                                                                                                    permitCrossZoneMoves,
                                                                                                    varyNumPartitionsPerNode);
nextCluster = numPartPerZone.getFirst();
int currentMoves = xzonePartitionsMoved + numPartPerZone.getSecond();
if(enableRandomSwaps) {
Pair<Cluster, Integer> shuffleCluster = RebalanceUtils.randomShufflePartitions(nextCluster,
                                                                                               swapAttempts,
                                                                                               swapSuccesses,
                                                                                               storeDefs,
                                                                                               uniqueStores,
                                                                                               keys);
nextCluster = shuffleCluster.getFirst();
currentMoves += shuffleCluster.getSecond();
}
if(enableGreedySwaps) {
Pair<Cluster, Integer> shuffleCluster = RebalanceUtils.greedyShufflePartitions(nextCluster,
                                                                                               greedySwapAttempts,
                                                                                               storeDefs);
nextCluster = shuffleCluster.getFirst();
currentMoves += shuffleCluster.getSecond();
}
double currentMaxMinRatio = analyzeBalance(nextCluster, storeDefs, false);
System.out.println(""Optimization number "" + numTries + "": ""
+ numPartPerZone.getSecond() + "" moves, "" + currentMaxMinRatio
+ "" max/min ratio"");
System.out.println(""Current min moves: "" + minMoves + ""; current max/min ratio: ""
+ minMaxMinRatio);
if(currentMaxMinRatio <= minMaxMinRatio) {
if(currentMoves > minMoves) {
System.out.println(""Warning: the newly chosen cluster requires ""
+ (currentMoves - minMoves) + "" addition moves!"");
}
minMoves = currentMoves;
minMaxMinRatio = currentMaxMinRatio;
minCluster = nextCluster;
System.out.println(""Current distribution"");
System.out.println(KeyDistributionGenerator.printOverallDistribution(currentCluster,
                                                                                     storeDefs,
                                                                                     keys));
System.out.println(""-------------------------\n"");
System.out.println(""Target distribution"");
System.out.println(KeyDistributionGenerator.printOverallDistribution(minCluster,
                                                                                     storeDefs,
                                                                                     keys));
System.out.println(""=========================\n"");
// If output directory exists, output the optimized cluster
if(outputDir != null) {
try {
FileUtils.writeStringToFile(new File(outputDir,
                                                             RebalanceUtils.finalClusterFileName
+ numTries),
                                                    new ClusterMapper().writeCluster(minCluster));
} catch(Exception e) {}
}
}
}
System.out.println(""\n=========================="");
System.out.println(""Final distribution"");
System.out.println(KeyDistributionGenerator.printOverallDistribution(minCluster,
                                                                             storeDefs,
                                                                             keys));
System.out.println(""=========================\n"");
analyzeBalance(minCluster, storeDefs, true);
// If output directory exists, output the optimized cluster
if(outputDir != null) {
try {
FileUtils.writeStringToFile(new File(outputDir, RebalanceUtils.finalClusterFileName),
                                            new ClusterMapper().writeCluster(minCluster));
} catch(Exception e) {}
}
return;
}","public static void balanceTargetCluster(final Cluster currentCluster,
                                            final Cluster targetCluster,
                                            final List<StoreDefinition> storeDefs,
                                            final String outputDir,
                                            final int tries,
                                            final boolean keepPrimaryPartitionsInSameZone,
                                            final boolean permitCrossZoneMoves,
                                            final int varyNumPartitionsPerNode,
                                            final boolean enableRandomSwaps,
                                            final int randomSwapAttempts,
                                            final int randomSwapSuccesses,
                                            final boolean enableGreedySwaps,
                                            final int greedySwapAttempts,
                                            final int greedySwapMaxPartitionsPerNode,
                                            final int greedySwapMaxPartitionsPerZone,
                                            final int maxContiguousPartitionsPerZone) {
List<ByteArray> keys = KeyDistributionGenerator.generateKeys(KeyDistributionGenerator.DEFAULT_NUM_KEYS);
Cluster minCluster = targetCluster;
int minMoves = Integer.MAX_VALUE;
double minMaxMinRatio = Double.MAX_VALUE;
Cluster nextCluster;
int xzonePartitionsMoved;
for(int numTries = 0; numTries < tries; numTries++) {
nextCluster = targetCluster;
xzonePartitionsMoved = 0;
if(maxContiguousPartitionsPerZone > 0) {
int contigPartitionsMoved = 0;
do {
Pair<Cluster, Integer> contigPartPerZone = RebalanceUtils.balanceContiguousPartitionsPerZone(nextCluster,
                                                                                                                 maxContiguousPartitionsPerZone);
nextCluster = contigPartPerZone.getFirst();
contigPartitionsMoved = contigPartPerZone.getSecond();
xzonePartitionsMoved += contigPartPerZone.getSecond();
Pair<Cluster, Integer> balanceXZone = RebalanceUtils.balanceNumPartitionsPerZone(nextCluster);
nextCluster = balanceXZone.getFirst();
xzonePartitionsMoved += balanceXZone.getSecond();
System.out.println(""Looping to evenly balance partitions across zones while limiting contiguous partitions: ""
+ contigPartitionsMoved);
} while(contigPartitionsMoved > 0);
}
Pair<Cluster, Integer> numPartPerZone = RebalanceUtils.balanceNumberOfPartitionsPerNode(nextCluster,
                                                                                                    storeDefs,
                                                                                                    keepPrimaryPartitionsInSameZone,
                                                                                                    permitCrossZoneMoves,
                                                                                                    varyNumPartitionsPerNode);
nextCluster = numPartPerZone.getFirst();
int currentMoves = xzonePartitionsMoved + numPartPerZone.getSecond();
if(enableRandomSwaps) {
Pair<Cluster, Integer> shuffleCluster = RebalanceUtils.randomShufflePartitions(nextCluster,
                                                                                               randomSwapAttempts,
                                                                                               randomSwapSuccesses,
                                                                                               storeDefs);
nextCluster = shuffleCluster.getFirst();
currentMoves += shuffleCluster.getSecond();
}
if(enableGreedySwaps) {
Pair<Cluster, Integer> shuffleCluster = RebalanceUtils.greedyShufflePartitions(nextCluster,
                                                                                               greedySwapAttempts,
                                                                                               greedySwapMaxPartitionsPerNode,
                                                                                               greedySwapMaxPartitionsPerZone,
                                                                                               storeDefs);
nextCluster = shuffleCluster.getFirst();
currentMoves += shuffleCluster.getSecond();
}
double currentMaxMinRatio = analyzeBalance(nextCluster, storeDefs, false);
System.out.println(""Optimization number "" + numTries + "": ""
+ numPartPerZone.getSecond() + "" moves, "" + currentMaxMinRatio
+ "" max/min ratio"");
System.out.println(""Current min moves: "" + minMoves + ""; current max/min ratio: ""
+ minMaxMinRatio);
if(currentMaxMinRatio <= minMaxMinRatio) {
if(currentMoves > minMoves) {
System.out.println(""Warning: the newly chosen cluster requires ""
+ (currentMoves - minMoves) + "" addition moves!"");
}
minMoves = currentMoves;
minMaxMinRatio = currentMaxMinRatio;
minCluster = nextCluster;
System.out.println(""Current distribution"");
System.out.println(KeyDistributionGenerator.printOverallDistribution(currentCluster,
                                                                                     storeDefs,
                                                                                     keys));
System.out.println(""-------------------------\n"");
System.out.println(""Target distribution"");
System.out.println(KeyDistributionGenerator.printOverallDistribution(minCluster,
                                                                                     storeDefs,
                                                                                     keys));
System.out.println(""=========================\n"");
// If output directory exists, output the optimized cluster
if(outputDir != null) {
try {
FileUtils.writeStringToFile(new File(outputDir,
                                                             RebalanceUtils.finalClusterFileName
+ numTries),
                                                    new ClusterMapper().writeCluster(minCluster));
} catch(Exception e) {}
}
}
}
System.out.println(""\n=========================="");
System.out.println(""Final distribution"");
System.out.println(KeyDistributionGenerator.printOverallDistribution(minCluster,
                                                                             storeDefs,
                                                                             keys));
System.out.println(""=========================\n"");
analyzeBalance(minCluster, storeDefs, true);
// If output directory exists, output the optimized cluster
if(outputDir != null) {
try {
FileUtils.writeStringToFile(new File(outputDir, RebalanceUtils.finalClusterFileName),
                                            new ClusterMapper().writeCluster(minCluster));
} catch(Exception e) {}
}
return;
}","public static void balanceTargetCluster  ( final Cluster currentCluster , final Cluster targetCluster , final List < StoreDefinition > storeDefs , final String outputDir , final int tries , final boolean keepPrimaryPartitionsInSameZone , final boolean permitCrossZoneMoves , final int varyNumPartitionsPerNode , final boolean enableRandomSwaps , final int swapAttempts , final int swapSuccesses , final int maxContiguousPartitionsPerZone ) { HashMap < StoreDefinition , Integer > uniqueStores = KeyDistributionGenerator . getUniqueStoreDefinitionsWithCounts ( storeDefs ) ; List < ByteArray > keys = KeyDistributionGenerator . generateKeys ( KeyDistributionGenerator . DEFAULT_NUM_KEYS ) ; Cluster minCluster = targetCluster ; int minMoves = Integer . MAX_VALUE ; // double minStdDev = Double.MAX_VALUE; double minMaxMinRatio = Double . MAX_VALUE ; Cluster nextCluster ; int xzonePartitionsMoved ; // <SATD_START> TODO: make this an arg <SATD_END> final boolean enableGreedySwaps = true ; final int greedySwapAttempts = 1 ; for ( int numTries = 0 ; numTries < tries ; numTries ++ ) { nextCluster = targetCluster ; xzonePartitionsMoved = 0 ; if ( maxContiguousPartitionsPerZone > 0 ) { int contigPartitionsMoved = 0 ; do { Pair < Cluster , Integer > contigPartPerZone = RebalanceUtils . balanceContiguousPartitionsPerZone ( nextCluster , maxContiguousPartitionsPerZone ) ; nextCluster = contigPartPerZone . getFirst ( ) ; contigPartitionsMoved = contigPartPerZone . getSecond ( ) ; xzonePartitionsMoved += contigPartPerZone . getSecond ( ) ; Pair < Cluster , Integer > balanceXZone = RebalanceUtils . balanceNumPartitionsPerZone ( nextCluster ) ; nextCluster = balanceXZone . getFirst ( ) ; xzonePartitionsMoved += balanceXZone . getSecond ( ) ; System . out . println ( "" Looping to evenly balance partitions across zones while limiting contiguous partitions:  "" + contigPartitionsMoved ) ; } while ( contigPartitionsMoved > 0 ) ; } Pair < Cluster , Integer > numPartPerZone = RebalanceUtils . balanceNumberOfPartitionsPerNode ( nextCluster , storeDefs , keepPrimaryPartitionsInSameZone , permitCrossZoneMoves , varyNumPartitionsPerNode ) ; nextCluster = numPartPerZone . getFirst ( ) ; int currentMoves = xzonePartitionsMoved + numPartPerZone . getSecond ( ) ; if ( enableRandomSwaps ) { Pair < Cluster , Integer > shuffleCluster = RebalanceUtils . randomShufflePartitions ( nextCluster , swapAttempts , swapSuccesses , storeDefs , uniqueStores , keys ) ; nextCluster = shuffleCluster . getFirst ( ) ; currentMoves += shuffleCluster . getSecond ( ) ; } if ( enableGreedySwaps ) { Pair < Cluster , Integer > shuffleCluster = RebalanceUtils . greedyShufflePartitions ( nextCluster , greedySwapAttempts , storeDefs ) ; nextCluster = shuffleCluster . getFirst ( ) ; currentMoves += shuffleCluster . getSecond ( ) ; } double currentMaxMinRatio = analyzeBalance ( nextCluster , storeDefs , false ) ; System . out . println ( "" Optimization number  "" + numTries + "" :  "" + numPartPerZone . getSecond ( ) + ""  moves,  "" + currentMaxMinRatio + ""  max/min ratio "" ) ; System . out . println ( "" Current min moves:  "" + minMoves + "" ; current max/min ratio:  "" + minMaxMinRatio ) ; if ( currentMaxMinRatio <= minMaxMinRatio ) { if ( currentMoves > minMoves ) { System . out . println ( "" Warning: the newly chosen cluster requires  "" + ( currentMoves - minMoves ) + ""  addition moves! "" ) ; } minMoves = currentMoves ; minMaxMinRatio = currentMaxMinRatio ; minCluster = nextCluster ; System . out . println ( "" Current distribution "" ) ; System . out . println ( KeyDistributionGenerator . printOverallDistribution ( currentCluster , storeDefs , keys ) ) ; System . out . println ( "" ------------------------- \n "" ) ; System . out . println ( "" Target distribution "" ) ; System . out . println ( KeyDistributionGenerator . printOverallDistribution ( minCluster , storeDefs , keys ) ) ; System . out . println ( "" ========================= \n "" ) ; // If output directory exists, output the optimized cluster if ( outputDir != null ) { try { FileUtils . writeStringToFile ( new File ( outputDir , RebalanceUtils . finalClusterFileName + numTries ) , new ClusterMapper ( ) . writeCluster ( minCluster ) ) ; } catch ( Exception e ) { } } } } System . out . println ( "" \n ========================== "" ) ; System . out . println ( "" Final distribution "" ) ; System . out . println ( KeyDistributionGenerator . printOverallDistribution ( minCluster , storeDefs , keys ) ) ; System . out . println ( "" ========================= \n "" ) ; analyzeBalance ( minCluster , storeDefs , true ) ; // If output directory exists, output the optimized cluster if ( outputDir != null ) { try { FileUtils . writeStringToFile ( new File ( outputDir , RebalanceUtils . finalClusterFileName ) , new ClusterMapper ( ) . writeCluster ( minCluster ) ) ; } catch ( Exception e ) { } } return ; }","public static void balanceTargetCluster  ( final Cluster currentCluster , final Cluster targetCluster , final List < StoreDefinition > storeDefs , final String outputDir , final int tries , final boolean keepPrimaryPartitionsInSameZone , final boolean permitCrossZoneMoves , final int varyNumPartitionsPerNode , final boolean enableRandomSwaps , final int randomSwapAttempts , final int randomSwapSuccesses , final boolean enableGreedySwaps , final int greedySwapAttempts , final int greedySwapMaxPartitionsPerNode , final int greedySwapMaxPartitionsPerZone , final int maxContiguousPartitionsPerZone ) { List < ByteArray > keys = KeyDistributionGenerator . generateKeys ( KeyDistributionGenerator . DEFAULT_NUM_KEYS ) ; Cluster minCluster = targetCluster ; int minMoves = Integer . MAX_VALUE ; double minMaxMinRatio = Double . MAX_VALUE ; Cluster nextCluster ; int xzonePartitionsMoved ; for ( int numTries = 0 ; numTries < tries ; numTries ++ ) { nextCluster = targetCluster ; xzonePartitionsMoved = 0 ; if ( maxContiguousPartitionsPerZone > 0 ) { int contigPartitionsMoved = 0 ; do { Pair < Cluster , Integer > contigPartPerZone = RebalanceUtils . balanceContiguousPartitionsPerZone ( nextCluster , maxContiguousPartitionsPerZone ) ; nextCluster = contigPartPerZone . getFirst ( ) ; contigPartitionsMoved = contigPartPerZone . getSecond ( ) ; xzonePartitionsMoved += contigPartPerZone . getSecond ( ) ; Pair < Cluster , Integer > balanceXZone = RebalanceUtils . balanceNumPartitionsPerZone ( nextCluster ) ; nextCluster = balanceXZone . getFirst ( ) ; xzonePartitionsMoved += balanceXZone . getSecond ( ) ; System . out . println ( "" Looping to evenly balance partitions across zones while limiting contiguous partitions:  "" + contigPartitionsMoved ) ; } while ( contigPartitionsMoved > 0 ) ; } Pair < Cluster , Integer > numPartPerZone = RebalanceUtils . balanceNumberOfPartitionsPerNode ( nextCluster , storeDefs , keepPrimaryPartitionsInSameZone , permitCrossZoneMoves , varyNumPartitionsPerNode ) ; nextCluster = numPartPerZone . getFirst ( ) ; int currentMoves = xzonePartitionsMoved + numPartPerZone . getSecond ( ) ; if ( enableRandomSwaps ) { Pair < Cluster , Integer > shuffleCluster = RebalanceUtils . randomShufflePartitions ( nextCluster , randomSwapAttempts , randomSwapSuccesses , storeDefs ) ; nextCluster = shuffleCluster . getFirst ( ) ; currentMoves += shuffleCluster . getSecond ( ) ; } if ( enableGreedySwaps ) { Pair < Cluster , Integer > shuffleCluster = RebalanceUtils . greedyShufflePartitions ( nextCluster , greedySwapAttempts , greedySwapMaxPartitionsPerNode , greedySwapMaxPartitionsPerZone , storeDefs ) ; nextCluster = shuffleCluster . getFirst ( ) ; currentMoves += shuffleCluster . getSecond ( ) ; } double currentMaxMinRatio = analyzeBalance ( nextCluster , storeDefs , false ) ; System . out . println ( "" Optimization number  "" + numTries + "" :  "" + numPartPerZone . getSecond ( ) + ""  moves,  "" + currentMaxMinRatio + ""  max/min ratio "" ) ; System . out . println ( "" Current min moves:  "" + minMoves + "" ; current max/min ratio:  "" + minMaxMinRatio ) ; if ( currentMaxMinRatio <= minMaxMinRatio ) { if ( currentMoves > minMoves ) { System . out . println ( "" Warning: the newly chosen cluster requires  "" + ( currentMoves - minMoves ) + ""  addition moves! "" ) ; } minMoves = currentMoves ; minMaxMinRatio = currentMaxMinRatio ; minCluster = nextCluster ; System . out . println ( "" Current distribution "" ) ; System . out . println ( KeyDistributionGenerator . printOverallDistribution ( currentCluster , storeDefs , keys ) ) ; System . out . println ( "" ------------------------- \n "" ) ; System . out . println ( "" Target distribution "" ) ; System . out . println ( KeyDistributionGenerator . printOverallDistribution ( minCluster , storeDefs , keys ) ) ; System . out . println ( "" ========================= \n "" ) ; // If output directory exists, output the optimized cluster if ( outputDir != null ) { try { FileUtils . writeStringToFile ( new File ( outputDir , RebalanceUtils . finalClusterFileName + numTries ) , new ClusterMapper ( ) . writeCluster ( minCluster ) ) ; } catch ( Exception e ) { } } } } System . out . println ( "" \n ========================== "" ) ; System . out . println ( "" Final distribution "" ) ; System . out . println ( KeyDistributionGenerator . printOverallDistribution ( minCluster , storeDefs , keys ) ) ; System . out . println ( "" ========================= \n "" ) ; analyzeBalance ( minCluster , storeDefs , true ) ; // If output directory exists, output the optimized cluster if ( outputDir != null ) { try { FileUtils . writeStringToFile ( new File ( outputDir , RebalanceUtils . finalClusterFileName ) , new ClusterMapper ( ) . writeCluster ( minCluster ) ) ; } catch ( Exception e ) { } } return ; }",2013/3/20 11:50,2013/3/20 11:50,0,0.6056644880174292
506,684,https://www.github.com/apache/ambari,"transition(NodeImpl, NodeEvent)",,295,295,295,295,TODO update health status to ???,https://www.github.com/apache/ambari/commit/0c5f8d21dc9,https://www.github.com/apache/ambari/commit/e3e237a088626235d518087a25069115ea905bd4,ambari-server/src/main/java/org/apache/ambari/server/state/live/node/NodeImpl.java,"@Override
public void transition(NodeImpl node, NodeEvent event) {
NodeHeartbeatTimedOutEvent e = (NodeHeartbeatTimedOutEvent) event;
// TODO Audit logs
LOG.info(""Node transitioned to heartbeat timed out state""
+ "", node="" + e.nodeName
+ "", lastHeartbeatTime="" + node.getLastHeartbeatTime());
// TODO update health status to ???
}","@Override
public void transition(NodeImpl node, NodeEvent event) {
NodeHeartbeatTimedOutEvent e = (NodeHeartbeatTimedOutEvent) event;
// TODO Audit logs
LOG.info(""Node transitioned to heartbeat timed out state""
+ "", node="" + e.nodeName
+ "", lastHeartbeatTime="" + node.getLastHeartbeatTime());
node.getHealthStatus().setHealthStatus(HealthStatus.UNKNOWN);
}","@ Override public void transition  ( NodeImpl node , NodeEvent event ) { NodeHeartbeatTimedOutEvent e = ( NodeHeartbeatTimedOutEvent ) event ; // TODO Audit logs LOG . info ( "" Node transitioned to heartbeat timed out state "" + "" , node= "" + e . nodeName + "" , lastHeartbeatTime= "" + node . getLastHeartbeatTime ( ) ) ; // <SATD_START> TODO update health status to ??? <SATD_END> }","@ Override public void transition  ( NodeImpl node , NodeEvent event ) { NodeHeartbeatTimedOutEvent e = ( NodeHeartbeatTimedOutEvent ) event ; // TODO Audit logs LOG . info ( "" Node transitioned to heartbeat timed out state "" + "" , node= "" + e . nodeName + "" , lastHeartbeatTime= "" + node . getLastHeartbeatTime ( ) ) ; node . getHealthStatus ( ) . setHealthStatus ( HealthStatus . UNKNOWN ) ; }",2012-09-07 15:11:12 +0000,2012-09-08 00:03:34 +0000,0,0.8402061855670103
905,194,https://www.github.com/apache/jmeter,propertyChange(PropertyChangeEvent),,411,411,419,420,TODO: how to bring the editor back in view & focus?,https://www.github.com/apache/jmeter/commit/15102e47e8e,https://www.github.com/apache/jmeter/commit/ec4531045a6101ac7915540f08e72d21309d38eb,src/core/org/apache/jmeter/testbeans/gui/WrapperEditor.java,"public void propertyChange(PropertyChangeEvent event) {
String text = guiEditor.getAsText();
if (isValidValue(text)) {
lastValidValue = text;
firePropertyChange();
} else {
// TODO: how to bring the editor back in view & focus?
JOptionPane.showMessageDialog(guiEditor.getCustomEditor().getParent(),
			        JMeterUtils.getResString(""property_editor.value_is_invalid_message""),//$NON-NLS-1$
JMeterUtils.getResString(""property_editor.value_is_invalid_title""),  //$NON-NLS-1$
JOptionPane.WARNING_MESSAGE);
// Revert to the previous value:
guiEditor.setAsText(lastValidValue);
}
}","public void propertyChange(PropertyChangeEvent event) {
String text = fixGetAsTextBug(guiEditor.getAsText());
if (isValidValue(text)) {
lastValidValue = text;
firePropertyChange();
} else {
if (GuiPackage.getInstance() == null){
log.warn(""Invalid value: ""+text+"" ""+guiEditor);
} else {
JOptionPane.showMessageDialog(guiEditor.getCustomEditor().getParent(),
			       JMeterUtils.getResString(""property_editor.value_is_invalid_message""),//$NON-NLS-1$
JMeterUtils.getResString(""property_editor.value_is_invalid_title""),  //$NON-NLS-1$
JOptionPane.WARNING_MESSAGE);
}
// Revert to the previous value:
guiEditor.setAsText(lastValidValue);
}
}","public void propertyChange  ( PropertyChangeEvent event ) { String text = guiEditor . getAsText ( ) ; if ( isValidValue ( text ) ) { lastValidValue = text ; firePropertyChange ( ) ; } else { // <SATD_START> TODO: how to bring the editor back in view & focus? <SATD_END> JOptionPane . showMessageDialog ( guiEditor . getCustomEditor ( ) . getParent ( ) , JMeterUtils . getResString ( "" property_editor.value_is_invalid_message "" ) , //$NON-NLS-1$ JMeterUtils . getResString ( "" property_editor.value_is_invalid_title "" ) , //$NON-NLS-1$ JOptionPane . WARNING_MESSAGE ) ; // Revert to the previous value: guiEditor . setAsText ( lastValidValue ) ; } }","public void propertyChange  ( PropertyChangeEvent event ) { String text = fixGetAsTextBug ( guiEditor . getAsText ( ) ) ; if ( isValidValue ( text ) ) { lastValidValue = text ; firePropertyChange ( ) ; } else { if ( GuiPackage . getInstance ( ) == null ) { log . warn ( "" Invalid value:  "" + text + ""   "" + guiEditor ) ; } else { JOptionPane . showMessageDialog ( guiEditor . getCustomEditor ( ) . getParent ( ) , JMeterUtils . getResString ( "" property_editor.value_is_invalid_message "" ) , //$NON-NLS-1$ JMeterUtils . getResString ( "" property_editor.value_is_invalid_title "" ) , //$NON-NLS-1$ JOptionPane . WARNING_MESSAGE ) ; } // Revert to the previous value: guiEditor . setAsText ( lastValidValue ) ; } }",2005-07-12 20:51:09 +0000,2008-04-13 21:48:26 +0000,0,0.8470588235294118
1990,110,https://www.github.com/apache/shiro,"postHandle(HttpServletRequest, HttpServletResponse)",DESIGN,296,296,296,296,TODO this is ugly - think of a way to make it cleaner (add method to WebSessionFactory interface?),https://www.github.com/apache/shiro/commit/95d2ef885,https://www.github.com/apache/shiro/commit/70a1873d02a88801acb06e9d765993ed7010daed,src/org/jsecurity/web/support/SecurityContextWebInterceptor.java,"public void postHandle( HttpServletRequest request, HttpServletResponse response )
throws Exception {
SecurityContext securityContext = getSecurityContext( request, response );
if ( securityContext != null ) {
//make sure it is valid:
try {
securityContext.getAllPrincipals();
} catch ( InvalidSecurityContextException e ) {
if  ( log.isTraceEnabled() ) {
log.trace( ""SecurityContext was invalidated during the request - returning quietly (a new "" +
""one will be created on the next request)."" );
}
return;
}
bindForSubsequentRequests( request, response, securityContext );
Session session = null;
try {
session = securityContext.getSession( false );
if ( session != null ) {
//TODO this is ugly - think of a way to make it cleaner (add method to WebSessionFactory interface?)
WebSessionFactory wsf = getWebSessionFactory();
if ( wsf instanceof DefaultWebSessionFactory ) {
( (DefaultWebSessionFactory)wsf ).storeSessionId( session, request, response );
}
}
} catch ( JSecurityException e ) {
if ( log.isWarnEnabled() ) {
log.warn( ""Encountered exception while trying to bind JSecurity Session for subsequent requests.  "" +
""Ignoring and returning (next request will create a new session if necessary)."", e );
}
}
}
}","public void postHandle( HttpServletRequest request, HttpServletResponse response )
throws Exception {
SecurityContext securityContext = getSecurityContext( request, response );
if ( securityContext != null ) {
//make sure it is valid:
try {
securityContext.getAllPrincipals();
} catch ( InvalidSecurityContextException e ) {
if ( log.isTraceEnabled() ) {
log.trace( ""SecurityContext was invalidated during the request - returning quietly (a new "" +
""one will be created on the next request)."" );
}
return;
}
bindForSubsequentRequests( request, response, securityContext );
}
getSessionWebInterceptor().postHandle( request, response );
}","public void postHandle  ( HttpServletRequest request , HttpServletResponse response ) throws Exception { SecurityContext securityContext = getSecurityContext ( request , response ) ; if ( securityContext != null ) { //make sure it is valid: try { securityContext . getAllPrincipals ( ) ; } catch ( InvalidSecurityContextException e ) { if ( log . isTraceEnabled ( ) ) { log . trace ( "" SecurityContext was invalidated during the request - returning quietly (a new  "" + "" one will be created on the next request). "" ) ; } return ; } bindForSubsequentRequests ( request , response , securityContext ) ; Session session = null ; try { session = securityContext . getSession ( false ) ; if ( session != null ) { //<SATD_START> TODO this is ugly - think of a way to make it cleaner (add method to WebSessionFactory interface?) <SATD_END> WebSessionFactory wsf = getWebSessionFactory ( ) ; if ( wsf instanceof DefaultWebSessionFactory ) { ( ( DefaultWebSessionFactory ) wsf ) . storeSessionId ( session , request , response ) ; } } } catch ( JSecurityException e ) { if ( log . isWarnEnabled ( ) ) { log . warn ( "" Encountered exception while trying to bind JSecurity Session for subsequent requests.   "" + "" Ignoring and returning (next request will create a new session if necessary). "" , e ) ; } } } }","public void postHandle  ( HttpServletRequest request , HttpServletResponse response ) throws Exception { SecurityContext securityContext = getSecurityContext ( request , response ) ; if ( securityContext != null ) { //make sure it is valid: try { securityContext . getAllPrincipals ( ) ; } catch ( InvalidSecurityContextException e ) { if ( log . isTraceEnabled ( ) ) { log . trace ( "" SecurityContext was invalidated during the request - returning quietly (a new  "" + "" one will be created on the next request). "" ) ; } return ; } bindForSubsequentRequests ( request , response , securityContext ) ; } getSessionWebInterceptor ( ) . postHandle ( request , response ) ; }",2007-08-28 04:09:35 +0000,2007-08-30 19:59:03 +0000,0,0.6145251396648045
1248,116,https://www.github.com/jpmoresmau/eclipsefp,initializeDefaults(IPreferenceStore),DESIGN,142,142,141,141,TODO invoke autodetection?,https://www.github.com/jpmoresmau/eclipsefp/commit/a28871ead,https://www.github.com/jpmoresmau/eclipsefp/commit/f82680a8dd2dfef7e65ccd75aab75c1a72ec3a8b,net.sf.eclipsefp.haskell.ui/src/net/sf/eclipsefp/haskell/ui/internal/preferences/scion/ScionPP.java,"public static void initializeDefaults(final IPreferenceStore store) {
// TODO invoke autodetection?
store.setDefault(SCION_SERVER_EXECUTABLE, """");
}","public static void initializeDefaults(final IPreferenceStore store) {
// scion might be on the path...
store.setDefault(SCION_SERVER_EXECUTABLE, getServerExecutableName());
}","public static void initializeDefaults  ( final IPreferenceStore store ) { // <SATD_START> TODO invoke autodetection? <SATD_END> store . setDefault ( SCION_SERVER_EXECUTABLE , "" "" ) ; }","public static void initializeDefaults  ( final IPreferenceStore store ) { // scion might be on the path... store . setDefault ( SCION_SERVER_EXECUTABLE , getServerExecutableName ( ) ) ; }",2009-07-18 12:38:26 +0200,2009-08-25 16:27:30 +0200,0,0.738544474393531
3254,52,https://www.github.com/apache/maven,execute(),DESIGN,197,197,197,197,TODO: we should really just trust the plugin classloader?,https://www.github.com/apache/maven/commit/baca1f7841,https://www.github.com/apache/maven/commit/01e6c8daa613e61e2fc13dc9edcd850f88a5da99,maven-plugins/maven-surefire-plugin/src/main/java/org/apache/maven/test/SurefirePlugin.java,"public void execute()
throws MojoExecutionException
{
if ( ""pom"".equals( project.getPackaging() ) )
{
return;
}
// ----------------------------------------------------------------------
// Setup the surefire booter
// ----------------------------------------------------------------------
SurefireBooter surefireBooter = new SurefireBooter();
getLog().info( ""Setting reports dir: "" + reportsDirectory );
surefireBooter.setReportsDirectory( reportsDirectory );
// ----------------------------------------------------------------------
// Check to see if we are running a single test. The raw parameter will
// come through if it has not been set.
// ----------------------------------------------------------------------
if ( test != null )
{
// FooTest -> **/FooTest.java
List includes = new ArrayList();
List excludes = new ArrayList();
String[] testRegexes = split( test, "","", -1 );
for ( int i = 0; i < testRegexes.length; i++ )
{
includes.add( ""**/"" + testRegexes[i] + "".java"" );
}
surefireBooter.addBattery( ""org.codehaus.surefire.battery.DirectoryBattery"",
                                       new Object[]{basedir, includes, excludes} );
}
else
        {
// defaults here, qdox doesn't like the end javadoc value
if ( includes == null )
{
includes = new ArrayList();
includes.add( ""**/*Test.java"" );
}
if ( excludes == null )
{
excludes = new ArrayList();
excludes.add( ""**/Abstract*Test.java"" );
}
surefireBooter.addBattery( ""org.codehaus.surefire.battery.DirectoryBattery"",
                                       new Object[]{basedir, includes, excludes} );
}
// ----------------------------------------------------------------------
//
// ----------------------------------------------------------------------
System.setProperty( ""basedir"", basedir );
// Add all system properties configured by the user
if ( systemProperties != null )
{
Enumeration propertyKeys = systemProperties.propertyNames();
while ( propertyKeys.hasMoreElements() )
{
String key = (String) propertyKeys.nextElement();
System.setProperty( key, systemProperties.getProperty( key ) );
getLog().debug( ""Setting system property ["" + key + ""]=["" + systemProperties.getProperty( key ) + ""]"" );
}
}
// TODO: we should really just trust the plugin classloader?
try
        {
DefaultArtifact artifact = new DefaultArtifact( ""junit"", ""junit"", ""3.8.1"", ""jar"" );
File file = new File( localRepository.getBasedir(), localRepository.pathOf( artifact ) );
surefireBooter.addClassPathUrl( file.getAbsolutePath() );
artifact = new DefaultArtifact( ""surefire"", ""surefire"", ""1.2"", ""jar"" );
file = new File( localRepository.getBasedir(), localRepository.pathOf( artifact ) );
surefireBooter.addClassPathUrl( file.getAbsolutePath() );
}
catch ( ArtifactPathFormatException e )
{
throw new MojoExecutionException( ""Error finding surefire JAR"", e );
}
surefireBooter.addClassPathUrl( new File( classesDirectory ).getPath() );
surefireBooter.addClassPathUrl( new File( testClassesDirectory ).getPath() );
for ( Iterator i = classpathElements.iterator(); i.hasNext(); )
{
surefireBooter.addClassPathUrl( (String) i.next() );
}
surefireBooter.addReport( ""org.codehaus.surefire.report.ConsoleReporter"" );
surefireBooter.addReport( ""org.codehaus.surefire.report.FileReporter"" );
boolean success = false;
try
        {
success = surefireBooter.run();
}
catch ( Exception e )
{
// TODO: better handling
throw new MojoExecutionException( ""Error executing surefire"", e );
}
if ( !success )
{
throw new MojoExecutionException( ""There are some test failures."" );
}
}","public void execute()
throws MojoExecutionException
{
if ( ""pom"".equals( project.getPackaging() ) )
{
return;
}
// ----------------------------------------------------------------------
// Setup the surefire booter
// ----------------------------------------------------------------------
SurefireBooter surefireBooter = new SurefireBooter();
getLog().info( ""Setting reports dir: "" + reportsDirectory );
surefireBooter.setReportsDirectory( reportsDirectory );
// ----------------------------------------------------------------------
// Check to see if we are running a single test. The raw parameter will
// come through if it has not been set.
// ----------------------------------------------------------------------
if ( test != null )
{
// FooTest -> **/FooTest.java
List includes = new ArrayList();
List excludes = new ArrayList();
String[] testRegexes = split( test, "","", -1 );
for ( int i = 0; i < testRegexes.length; i++ )
{
includes.add( ""**/"" + testRegexes[i] + "".java"" );
}
surefireBooter.addBattery( ""org.codehaus.surefire.battery.DirectoryBattery"",
                                       new Object[]{basedir, includes, excludes} );
}
else
        {
// defaults here, qdox doesn't like the end javadoc value
if ( includes == null )
{
includes = new ArrayList();
includes.add( ""**/*Test.java"" );
}
if ( excludes == null )
{
excludes = new ArrayList();
excludes.add( ""**/Abstract*Test.java"" );
}
surefireBooter.addBattery( ""org.codehaus.surefire.battery.DirectoryBattery"",
                                       new Object[]{basedir, includes, excludes} );
}
// ----------------------------------------------------------------------
//
// ----------------------------------------------------------------------
System.setProperty( ""basedir"", basedir );
// Add all system properties configured by the user
if ( systemProperties != null )
{
Enumeration propertyKeys = systemProperties.propertyNames();
while ( propertyKeys.hasMoreElements() )
{
String key = (String) propertyKeys.nextElement();
System.setProperty( key, systemProperties.getProperty( key ) );
getLog().debug( ""Setting system property ["" + key + ""]=["" + systemProperties.getProperty( key ) + ""]"" );
}
}
for ( Iterator i = pluginArtifacts.iterator(); i.hasNext(); )
{
Artifact artifact = (Artifact) i.next();
surefireBooter.addClassPathUrl( artifact.getFile().getAbsolutePath() );
}
surefireBooter.addClassPathUrl( new File( classesDirectory ).getPath() );
surefireBooter.addClassPathUrl( new File( testClassesDirectory ).getPath() );
for ( Iterator i = classpathElements.iterator(); i.hasNext(); )
{
surefireBooter.addClassPathUrl( (String) i.next() );
}
surefireBooter.addReport( ""org.codehaus.surefire.report.ConsoleReporter"" );
surefireBooter.addReport( ""org.codehaus.surefire.report.FileReporter"" );
boolean success = false;
try
        {
success = surefireBooter.run();
}
catch ( Exception e )
{
// TODO: better handling
throw new MojoExecutionException( ""Error executing surefire"", e );
}
if ( !success )
{
throw new MojoExecutionException( ""There are some test failures."" );
}
}","public void execute  ( ) throws MojoExecutionException { if ( "" pom "" . equals ( project . getPackaging ( ) ) ) { return ; } // ---------------------------------------------------------------------- // Setup the surefire booter // ---------------------------------------------------------------------- SurefireBooter surefireBooter = new SurefireBooter ( ) ; getLog ( ) . info ( "" Setting reports dir:  "" + reportsDirectory ) ; surefireBooter . setReportsDirectory ( reportsDirectory ) ; // ---------------------------------------------------------------------- // Check to see if we are running a single test. The raw parameter will // come through if it has not been set. // ---------------------------------------------------------------------- if ( test != null ) { // FooTest -> **/FooTest.java List includes = new ArrayList ( ) ; List excludes = new ArrayList ( ) ; String [ ] testRegexes = split ( test , "" , "" , - 1 ) ; for ( int i = 0 ; i < testRegexes . length ; i ++ ) { includes . add ( "" **/ "" + testRegexes [ i ] + "" .java "" ) ; } surefireBooter . addBattery ( "" org.codehaus.surefire.battery.DirectoryBattery "" , new Object [ ] { basedir , includes , excludes } ) ; } else { // defaults here, qdox doesn't like the end javadoc value if ( includes == null ) { includes = new ArrayList ( ) ; includes . add ( "" **/*Test.java "" ) ; } if ( excludes == null ) { excludes = new ArrayList ( ) ; excludes . add ( "" **/Abstract*Test.java "" ) ; } surefireBooter . addBattery ( "" org.codehaus.surefire.battery.DirectoryBattery "" , new Object [ ] { basedir , includes , excludes } ) ; } // ---------------------------------------------------------------------- // // ---------------------------------------------------------------------- System . setProperty ( "" basedir "" , basedir ) ; // Add all system properties configured by the user if ( systemProperties != null ) { Enumeration propertyKeys = systemProperties . propertyNames ( ) ; while ( propertyKeys . hasMoreElements ( ) ) { String key = ( String ) propertyKeys . nextElement ( ) ; System . setProperty ( key , systemProperties . getProperty ( key ) ) ; getLog ( ) . debug ( "" Setting system property [ "" + key + "" ]=[ "" + systemProperties . getProperty ( key ) + "" ] "" ) ; } } // <SATD_START> TODO: we should really just trust the plugin classloader? <SATD_END> try { DefaultArtifact artifact = new DefaultArtifact ( "" junit "" , "" junit "" , "" 3.8.1 "" , "" jar "" ) ; File file = new File ( localRepository . getBasedir ( ) , localRepository . pathOf ( artifact ) ) ; surefireBooter . addClassPathUrl ( file . getAbsolutePath ( ) ) ; artifact = new DefaultArtifact ( "" surefire "" , "" surefire "" , "" 1.2 "" , "" jar "" ) ; file = new File ( localRepository . getBasedir ( ) , localRepository . pathOf ( artifact ) ) ; surefireBooter . addClassPathUrl ( file . getAbsolutePath ( ) ) ; } catch ( ArtifactPathFormatException e ) { throw new MojoExecutionException ( "" Error finding surefire JAR "" , e ) ; } surefireBooter . addClassPathUrl ( new File ( classesDirectory ) . getPath ( ) ) ; surefireBooter . addClassPathUrl ( new File ( testClassesDirectory ) . getPath ( ) ) ; for ( Iterator i = classpathElements . iterator ( ) ; i . hasNext ( ) ; ) { surefireBooter . addClassPathUrl ( ( String ) i . next ( ) ) ; } surefireBooter . addReport ( "" org.codehaus.surefire.report.ConsoleReporter "" ) ; surefireBooter . addReport ( "" org.codehaus.surefire.report.FileReporter "" ) ; boolean success = false ; try { success = surefireBooter . run ( ) ; } catch ( Exception e ) { // TODO: better handling throw new MojoExecutionException ( "" Error executing surefire "" , e ) ; } if ( ! success ) { throw new MojoExecutionException ( "" There are some test failures. "" ) ; } }","public void execute  ( ) throws MojoExecutionException { if ( "" pom "" . equals ( project . getPackaging ( ) ) ) { return ; } // ---------------------------------------------------------------------- // Setup the surefire booter // ---------------------------------------------------------------------- SurefireBooter surefireBooter = new SurefireBooter ( ) ; getLog ( ) . info ( "" Setting reports dir:  "" + reportsDirectory ) ; surefireBooter . setReportsDirectory ( reportsDirectory ) ; // ---------------------------------------------------------------------- // Check to see if we are running a single test. The raw parameter will // come through if it has not been set. // ---------------------------------------------------------------------- if ( test != null ) { // FooTest -> **/FooTest.java List includes = new ArrayList ( ) ; List excludes = new ArrayList ( ) ; String [ ] testRegexes = split ( test , "" , "" , - 1 ) ; for ( int i = 0 ; i < testRegexes . length ; i ++ ) { includes . add ( "" **/ "" + testRegexes [ i ] + "" .java "" ) ; } surefireBooter . addBattery ( "" org.codehaus.surefire.battery.DirectoryBattery "" , new Object [ ] { basedir , includes , excludes } ) ; } else { // defaults here, qdox doesn't like the end javadoc value if ( includes == null ) { includes = new ArrayList ( ) ; includes . add ( "" **/*Test.java "" ) ; } if ( excludes == null ) { excludes = new ArrayList ( ) ; excludes . add ( "" **/Abstract*Test.java "" ) ; } surefireBooter . addBattery ( "" org.codehaus.surefire.battery.DirectoryBattery "" , new Object [ ] { basedir , includes , excludes } ) ; } // ---------------------------------------------------------------------- // // ---------------------------------------------------------------------- System . setProperty ( "" basedir "" , basedir ) ; // Add all system properties configured by the user if ( systemProperties != null ) { Enumeration propertyKeys = systemProperties . propertyNames ( ) ; while ( propertyKeys . hasMoreElements ( ) ) { String key = ( String ) propertyKeys . nextElement ( ) ; System . setProperty ( key , systemProperties . getProperty ( key ) ) ; getLog ( ) . debug ( "" Setting system property [ "" + key + "" ]=[ "" + systemProperties . getProperty ( key ) + "" ] "" ) ; } } for ( Iterator i = pluginArtifacts . iterator ( ) ; i . hasNext ( ) ; ) { Artifact artifact = ( Artifact ) i . next ( ) ; surefireBooter . addClassPathUrl ( artifact . getFile ( ) . getAbsolutePath ( ) ) ; } surefireBooter . addClassPathUrl ( new File ( classesDirectory ) . getPath ( ) ) ; surefireBooter . addClassPathUrl ( new File ( testClassesDirectory ) . getPath ( ) ) ; for ( Iterator i = classpathElements . iterator ( ) ; i . hasNext ( ) ; ) { surefireBooter . addClassPathUrl ( ( String ) i . next ( ) ) ; } surefireBooter . addReport ( "" org.codehaus.surefire.report.ConsoleReporter "" ) ; surefireBooter . addReport ( "" org.codehaus.surefire.report.FileReporter "" ) ; boolean success = false ; try { success = surefireBooter . run ( ) ; } catch ( Exception e ) { // TODO: better handling throw new MojoExecutionException ( "" Error executing surefire "" , e ) ; } if ( ! success ) { throw new MojoExecutionException ( "" There are some test failures. "" ) ; } }",2005-04-04 03:48:01 +0000,2005-06-17 06:49:57 +0000,0,0.666858955869628
1000,660,https://www.github.com/unc-libraries/carolina-digital-repository,process(Exchange),,100,100,100,100,TODO this is a placeholder until a partial update for reorder is worked out,https://www.github.com/unc-libraries/carolina-digital-repository/commit/f276fcdcf3,https://www.github.com/unc-libraries/carolina-digital-repository/commit/f302c9af1f9f292e501ab3ebb29c7cabfb1f7ad1,services-camel/src/main/java/edu/unc/lib/cdr/CdrEventToSolrUpdateProcessor.java,"@Override
public void process(Exchange exchange) throws Exception {
final Message in = exchange.getIn();
Document body = (Document) in.getBody();
Element contentBody = body.getRootElement().getChild(""content"", JDOMNamespaceUtil.ATOM_NS);
if (contentBody == null || contentBody.getChildren().size() == 0) {
return;
}
String solrActionType = (String) in.getHeader(CdrSolrUpdateAction);
if (solrActionType == null || solrActionType.equals(""none"")) {
return;
}
parent = contentBody.getChildText(""parent"", JDOMNamespaceUtil.CDR_MESSAGE_NS);
mode = contentBody.getChildText(""mode"", JDOMNamespaceUtil.CDR_MESSAGE_NS);
subjects = populateList(""subjects"", contentBody);
String targetId = JMSMessageUtil.getPid(body);
if (MOVE.equals(solrActionType)) {
SolrUpdateRequest request = new ChildSetRequest(targetId, subjects,
                    IndexingActionType.MOVE);
this.offer(request);
} else if (ADD.equals(solrActionType)) {
SolrUpdateRequest request = new ChildSetRequest(targetId, subjects,
                    IndexingActionType.ADD_SET_TO_PARENT);
this.offer(request);
} else if (REORDER.equals(solrActionType)) {
// TODO this is a placeholder until a partial update for reorder is worked out
for (String pidString : populateList(""reordered"", contentBody)) {
this.offer(pidString, IndexingActionType.ADD);
}
} else if (INDEX.equals(solrActionType)) {
String operation = contentBody.getName();
IndexingActionType indexingAction = IndexingActionType.getAction(IndexingActionType.namespace
+ operation);
if (indexingAction != null) {
if (IndexingActionType.SET_DEFAULT_WEB_OBJECT.equals(indexingAction)) {
SolrUpdateRequest request = new ChildSetRequest(targetId, subjects,
                            IndexingActionType.SET_DEFAULT_WEB_OBJECT);
this.offer(request);
} else {
for (String pidString : subjects) {
this.offer(pidString, indexingAction);
}
}
}
} else if (REINDEX.equals(solrActionType)) {
// Determine which kind of reindex to perform based on the mode
if (mode.equals(""inplace"")) {
this.offer(parent, IndexingActionType.RECURSIVE_REINDEX);
} else {
this.offer(parent, IndexingActionType.CLEAN_REINDEX);
}
} else if (PUBLISH.equals(solrActionType)) {
for (String pidString : subjects) {
this.offer(pidString, IndexingActionType.UPDATE_STATUS);
}
} else if (EDIT_TYPE.equals(solrActionType)) {
SolrUpdateRequest request = new ChildSetRequest(targetId, subjects,
                    IndexingActionType.UPDATE_TYPE);
this.offer(request);
}
}","@Override
public void process(Exchange exchange) throws Exception {
final Message in = exchange.getIn();
Document body = (Document) in.getBody();
if (body == null) {
log.warn(""Event message contained no body"");
return;
}
Element content = body.getRootElement().getChild(""content"", JDOMNamespaceUtil.ATOM_NS);
Element contentBody = content.getChildren().get(0);
if (contentBody == null || contentBody.getChildren().size() == 0) {
log.warn(""Event message contained no body content"");
return;
}
String targetId = JMSMessageUtil.getPid(body);
String solrActionType = (String) in.getHeader(CdrSolrUpdateAction);
if (solrActionType == null || solrActionType.equals(""none"")) {
log.warn(""No solr update action specified, ignoring event for object {}"", targetId);
return;
}
List<String> subjects = populateList(""subjects"", contentBody);
if (MOVE.equals(solrActionType)) {
offer(targetId, IndexingActionType.MOVE, subjects);
} else if (ADD.equals(solrActionType)) {
offer(targetId, IndexingActionType.ADD_SET_TO_PARENT, subjects);
} else if (INDEX.equals(solrActionType)) {
String operation = contentBody.getName();
IndexingActionType indexingAction = IndexingActionType.getAction(IndexingActionType.namespace
+ operation);
if (indexingAction != null) {
if (IndexingActionType.SET_DEFAULT_WEB_OBJECT.equals(indexingAction)) {
offer(targetId, IndexingActionType.SET_DEFAULT_WEB_OBJECT, subjects);
} else {
for (String pidString : subjects) {
offer(pidString, indexingAction);
}
}
}
} else if (PUBLISH.equals(solrActionType)) {
for (String pidString : subjects) {
offer(pidString, IndexingActionType.UPDATE_STATUS);
}
} else {
log.warn(""Invalid solr update action {}, ignoring event for object {}"", solrActionType, targetId);
return;
}
}","@ Override public void process  ( Exchange exchange ) throws Exception { final Message in = exchange . getIn ( ) ; Document body = ( Document ) in . getBody ( ) ; Element contentBody = body . getRootElement ( ) . getChild ( "" content "" , JDOMNamespaceUtil . ATOM_NS ) ; if ( contentBody == null || contentBody . getChildren ( ) . size ( ) == 0 ) { return ; } String solrActionType = ( String ) in . getHeader ( CdrSolrUpdateAction ) ; if ( solrActionType == null || solrActionType . equals ( "" none "" ) ) { return ; } parent = contentBody . getChildText ( "" parent "" , JDOMNamespaceUtil . CDR_MESSAGE_NS ) ; mode = contentBody . getChildText ( "" mode "" , JDOMNamespaceUtil . CDR_MESSAGE_NS ) ; subjects = populateList ( "" subjects "" , contentBody ) ; String targetId = JMSMessageUtil . getPid ( body ) ; if ( MOVE . equals ( solrActionType ) ) { SolrUpdateRequest request = new ChildSetRequest ( targetId , subjects , IndexingActionType . MOVE ) ; this . offer ( request ) ; } else if ( ADD . equals ( solrActionType ) ) { SolrUpdateRequest request = new ChildSetRequest ( targetId , subjects , IndexingActionType . ADD_SET_TO_PARENT ) ; this . offer ( request ) ; } else if ( REORDER . equals ( solrActionType ) ) { // <SATD_START> TODO this is a placeholder until a partial update for reorder is worked out <SATD_END> for ( String pidString : populateList ( "" reordered "" , contentBody ) ) { this . offer ( pidString , IndexingActionType . ADD ) ; } } else if ( INDEX . equals ( solrActionType ) ) { String operation = contentBody . getName ( ) ; IndexingActionType indexingAction = IndexingActionType . getAction ( IndexingActionType . namespace + operation ) ; if ( indexingAction != null ) { if ( IndexingActionType . SET_DEFAULT_WEB_OBJECT . equals ( indexingAction ) ) { SolrUpdateRequest request = new ChildSetRequest ( targetId , subjects , IndexingActionType . SET_DEFAULT_WEB_OBJECT ) ; this . offer ( request ) ; } else { for ( String pidString : subjects ) { this . offer ( pidString , indexingAction ) ; } } } } else if ( REINDEX . equals ( solrActionType ) ) { // Determine which kind of reindex to perform based on the mode if ( mode . equals ( "" inplace "" ) ) { this . offer ( parent , IndexingActionType . RECURSIVE_REINDEX ) ; } else { this . offer ( parent , IndexingActionType . CLEAN_REINDEX ) ; } } else if ( PUBLISH . equals ( solrActionType ) ) { for ( String pidString : subjects ) { this . offer ( pidString , IndexingActionType . UPDATE_STATUS ) ; } } else if ( EDIT_TYPE . equals ( solrActionType ) ) { SolrUpdateRequest request = new ChildSetRequest ( targetId , subjects , IndexingActionType . UPDATE_TYPE ) ; this . offer ( request ) ; } }","@ Override public void process  ( Exchange exchange ) throws Exception { final Message in = exchange . getIn ( ) ; Document body = ( Document ) in . getBody ( ) ; if ( body == null ) { log . warn ( "" Event message contained no body "" ) ; return ; } Element content = body . getRootElement ( ) . getChild ( "" content "" , JDOMNamespaceUtil . ATOM_NS ) ; Element contentBody = content . getChildren ( ) . get ( 0 ) ; if ( contentBody == null || contentBody . getChildren ( ) . size ( ) == 0 ) { log . warn ( "" Event message contained no body content "" ) ; return ; } String targetId = JMSMessageUtil . getPid ( body ) ; String solrActionType = ( String ) in . getHeader ( CdrSolrUpdateAction ) ; if ( solrActionType == null || solrActionType . equals ( "" none "" ) ) { log . warn ( "" No solr update action specified, ignoring event for object {} "" , targetId ) ; return ; } List < String > subjects = populateList ( "" subjects "" , contentBody ) ; if ( MOVE . equals ( solrActionType ) ) { offer ( targetId , IndexingActionType . MOVE , subjects ) ; } else if ( ADD . equals ( solrActionType ) ) { offer ( targetId , IndexingActionType . ADD_SET_TO_PARENT , subjects ) ; } else if ( INDEX . equals ( solrActionType ) ) { String operation = contentBody . getName ( ) ; IndexingActionType indexingAction = IndexingActionType . getAction ( IndexingActionType . namespace + operation ) ; if ( indexingAction != null ) { if ( IndexingActionType . SET_DEFAULT_WEB_OBJECT . equals ( indexingAction ) ) { offer ( targetId , IndexingActionType . SET_DEFAULT_WEB_OBJECT , subjects ) ; } else { for ( String pidString : subjects ) { offer ( pidString , indexingAction ) ; } } } } else if ( PUBLISH . equals ( solrActionType ) ) { for ( String pidString : subjects ) { offer ( pidString , IndexingActionType . UPDATE_STATUS ) ; } } else { log . warn ( "" Invalid solr update action {}, ignoring event for object {} "" , solrActionType , targetId ) ; return ; } }",2017/9/1 16:42,2017/10/6 16:58,0,0.5184221933246641
2651,727,https://www.github.com/eclipse/tycho,"generateMetadata(IArtifactFacade, List<Map<String, String>>, Set<IInstallableUnit>, Set<IArtifactDescriptor>, PublisherInfo)",,51,51,51,51,TODO remove this when fix for Eclipse bug #332444 is integrated,https://www.github.com/eclipse/tycho/commit/5138050656,https://www.github.com/eclipse/tycho/commit/6058f319e0b19d736ef04b3d04c44901b2fa143b,tycho-bundles/org.eclipse.tycho.p2.resolver.impl/src/main/java/org/eclipse/tycho/p2/impl/publisher/AbstractMetadataGenerator.java,"protected void generateMetadata(IArtifactFacade artifact, List<Map<String, String>> environments,
            Set<IInstallableUnit> units, Set<IArtifactDescriptor> artifacts, PublisherInfo publisherInfo) {
// TODO remove this when fix for Eclipse bug #332444 is integrated
if (publisherInfo.getMetadataRepository() == null) {
publisherInfo.setMetadataRepository(new DummyMetadataRepository());
}
for (IPublisherAdvice advice : getPublisherAdvice(artifact)) {
publisherInfo.addAdvice(advice);
}
List<IPublisherAction> actions = getPublisherActions(artifact, environments);
publish(units, artifacts, publisherInfo, actions);
}","protected void generateMetadata(IArtifactFacade artifact, List<Map<String, String>> environments,
            Set<IInstallableUnit> units, Set<IArtifactDescriptor> artifacts, PublisherInfo publisherInfo) {
for (IPublisherAdvice advice : getPublisherAdvice(artifact)) {
publisherInfo.addAdvice(advice);
}
List<IPublisherAction> actions = getPublisherActions(artifact, environments);
publish(units, artifacts, publisherInfo, actions);
}","protected void generateMetadata  ( IArtifactFacade artifact , List < Map < String , String > > environments , Set < IInstallableUnit > units , Set < IArtifactDescriptor > artifacts , PublisherInfo publisherInfo ) { // <SATD_START> TODO remove this when fix for Eclipse bug #332444 is integrated <SATD_END> if ( publisherInfo . getMetadataRepository ( ) == null ) { publisherInfo . setMetadataRepository ( new DummyMetadataRepository ( ) ) ; } for ( IPublisherAdvice advice : getPublisherAdvice ( artifact ) ) { publisherInfo . addAdvice ( advice ) ; } List < IPublisherAction > actions = getPublisherActions ( artifact , environments ) ; publish ( units , artifacts , publisherInfo , actions ) ; }","protected void generateMetadata  ( IArtifactFacade artifact , List < Map < String , String > > environments , Set < IInstallableUnit > units , Set < IArtifactDescriptor > artifacts , PublisherInfo publisherInfo ) { for ( IPublisherAdvice advice : getPublisherAdvice ( artifact ) ) { publisherInfo . addAdvice ( advice ) ; } List < IPublisherAction > actions = getPublisherActions ( artifact , environments ) ; publish ( units , artifacts , publisherInfo , actions ) ; }",2011-09-19 11:51:45 +0200,2011-10-21 10:56:09 +0200,0,0.3876500857632933
162,280,https://www.github.com/eclipse-ee4j/beanvalidation-tck,testConstructorParameterConstraintsAreDeclaredByAnnotingParameters(),DESIGN,102,102,102,102,TODO Use wildcard constructor once BV API is updated (BVAL-358),https://www.github.com/eclipse-ee4j/beanvalidation-tck/commit/3b1bd8b7c,https://www.github.com/eclipse-ee4j/beanvalidation-tck/commit/afbe402c388f3facabb0957b1ab6948045480626,tests/src/main/java/org/hibernate/beanvalidation/tck/tests/constraints/application/method/MethodValidationRequirementTest.java,"@Test
@SpecAssertion(section = ""4.5.2"", id = ""a"")
public void testConstructorParameterConstraintsAreDeclaredByAnnotingParameters()
throws Exception {
//TODO Use wildcard constructor once BV API is updated (BVAL-358)
//Constructor<?> constructor = getParameterConstrainedConstructor();
Constructor constructor = CalendarService.class.getConstructor( String.class );
Object[] parameterValues = new Object[1];
Set<ConstraintViolation<Object>> constraintViolations = executableValidator.validateConstructorParameters(
				constructor,
				parameterValues
		);
assertNotNull( constraintViolations );
assertCorrectNumberOfViolations( constraintViolations, 1 );
assertCorrectConstraintTypes( constraintViolations, NotNull.class );
}","@Test
@SpecAssertion(section = ""4.5.2"", id = ""a"")
public void testConstructorParameterConstraintsAreDeclaredByAnnotingParameters()
throws Exception {
Constructor<?> constructor = CalendarService.class.getConstructor( String.class );
Object[] parameterValues = new Object[1];
Set<ConstraintViolation<Object>> constraintViolations = executableValidator.validateConstructorParameters(
				constructor,
				parameterValues
		);
assertNotNull( constraintViolations );
assertCorrectNumberOfViolations( constraintViolations, 1 );
assertCorrectConstraintTypes( constraintViolations, NotNull.class );
}","@ Test @ SpecAssertion ( section = "" 4.5.2 "" , id = "" a "" ) public void testConstructorParameterConstraintsAreDeclaredByAnnotingParameters  ( ) throws Exception { //<SATD_START> TODO Use wildcard constructor once BV API is updated (BVAL-358) <SATD_END> //Constructor<?> constructor = getParameterConstrainedConstructor(); Constructor constructor = CalendarService . class . getConstructor ( String . class ) ; Object [ ] parameterValues = new Object [ 1 ] ; Set < ConstraintViolation < Object > > constraintViolations = executableValidator . validateConstructorParameters ( constructor , parameterValues ) ; assertNotNull ( constraintViolations ) ; assertCorrectNumberOfViolations ( constraintViolations , 1 ) ; assertCorrectConstraintTypes ( constraintViolations , NotNull . class ) ; }","@ Test @ SpecAssertion ( section = "" 4.5.2 "" , id = "" a "" ) public void testConstructorParameterConstraintsAreDeclaredByAnnotingParameters  ( ) throws Exception { Constructor < ? > constructor = CalendarService . class . getConstructor ( String . class ) ; Object [ ] parameterValues = new Object [ 1 ] ; Set < ConstraintViolation < Object > > constraintViolations = executableValidator . validateConstructorParameters ( constructor , parameterValues ) ; assertNotNull ( constraintViolations ) ; assertCorrectNumberOfViolations ( constraintViolations , 1 ) ; assertCorrectConstraintTypes ( constraintViolations , NotNull . class ) ; }",2013-01-16 17:15:26 +0100,2013-02-05 09:17:35 +0100,0,0.8712174524982407
97,745,https://www.github.com/picketlink/picketlink,"add(IdentityContext, AttributedType)",,121,121,121,121,TODO set the owner property,https://www.github.com/picketlink/picketlink/commit/39976ccb42,https://www.github.com/picketlink/picketlink/commit/4f61d2c9cce743bbc62fe35b4f9b7d0a242ce72a,modules/idm/impl/src/main/java/org/picketlink/idm/jpa/internal/JPAIdentityStore.java,"@Override
public void add(IdentityContext context, AttributedType value) {
if (IdentityType.class.isInstance(value)) {
EntityGraph graph = EntityGraph.create(value, config.getIdentityModel());
graph.setProperty(config.getIdentityModel().getIdentityClassProperty(), value.getClass().getName());
graph.persist(getEntityManager(context));
} else if (Relationship.class.isInstance(value)) {
Relationship relationship = (Relationship) value;
EntityGraph graph = EntityGraph.create(relationship, config.getRelationshipModel());
graph.setProperty(config.getRelationshipModel().getRelationshipClassProperty(), relationship.getClass().getName());
// For each of the identities participating in the relationship, create a new node in the graph
Class<?> relationshipIdentityClass = config.getRelationshipModel().getRelationshipMember().getDeclaringClass();
Set<Property<? extends IdentityType>> identityProperties = relationshipMetadata.getRelationshipIdentityProperties(
                    relationship.getClass());
for (Property<? extends IdentityType> property : identityProperties) {
Object entity = graph.createEntity(relationshipIdentityClass);
graph.createNode(entity, false);
// If the relationship member property is a String, set the identifier as the value
if (String.class.equals(config.getRelationshipModel().getRelationshipMember().getJavaClass())) {
IdentityType relationshipIdentity = property.getValue(relationship);
// We use the convention ""Identity ID:Partition ID"" to store identity references
// TODO maybe replace this with an IdentityReference instead?
graph.setProperty(config.getRelationshipModel().getRelationshipMember(),
                            String.format(""%s:%s"", relationshipIdentity.getId(), relationshipIdentity.getPartition().getId()));
} else {
// Otherwise we set the value to the entity with the specified identifier
AttributedType member = (AttributedType) config.getRelationshipModel().getRelationshipMember().getValue(relationship);
String identifier = member.getId();
Object identityEntity = lookupEntityByParameter(context, config.getIdentityModel(), IdentityType.class, ""id"", identifier);
graph.setProperty(config.getRelationshipModel().getRelationshipMember(), identityEntity);
}
graph.setProperty(config.getRelationshipModel().getRelationshipDescriptor(), property.getName());
// TODO set the owner property
}
graph.persist(getEntityManager(context));
}
}","@Override
public void add(IdentityContext context, AttributedType attributedType) {
attributedType.setId(context.getIdGenerator().generate());
if (IdentityType.class.isInstance(attributedType)) {
IdentityType identityType = (IdentityType) attributedType;
identityType.setPartition(context.getPartition());
}
EntityManager entityManager = getEntityManager(context);
for (EntityMapper entityMapper : getMapperFor(attributedType.getClass())) {
Object entity = entityMapper.createEntity(attributedType, entityManager);
if (entity != null) {
entityManager.persist(entity);
}
if (Relationship.class.isInstance(attributedType)) {
addRelationshipIdentity(attributedType, entityManager);
}
}
entityManager.flush();
}","@ Override public void add  ( IdentityContext context , AttributedType value ) { if ( IdentityType . class . isInstance ( value ) ) { EntityGraph graph = EntityGraph . create ( value , config . getIdentityModel ( ) ) ; graph . setProperty ( config . getIdentityModel ( ) . getIdentityClassProperty ( ) , value . getClass ( ) . getName ( ) ) ; graph . persist ( getEntityManager ( context ) ) ; } else if ( Relationship . class . isInstance ( value ) ) { Relationship relationship = ( Relationship ) value ; EntityGraph graph = EntityGraph . create ( relationship , config . getRelationshipModel ( ) ) ; graph . setProperty ( config . getRelationshipModel ( ) . getRelationshipClassProperty ( ) , relationship . getClass ( ) . getName ( ) ) ; // For each of the identities participating in the relationship, create a new node in the graph Class < ? > relationshipIdentityClass = config . getRelationshipModel ( ) . getRelationshipMember ( ) . getDeclaringClass ( ) ; Set < Property < ? extends IdentityType > > identityProperties = relationshipMetadata . getRelationshipIdentityProperties ( relationship . getClass ( ) ) ; for ( Property < ? extends IdentityType > property : identityProperties ) { Object entity = graph . createEntity ( relationshipIdentityClass ) ; graph . createNode ( entity , false ) ; // If the relationship member property is a String, set the identifier as the value if ( String . class . equals ( config . getRelationshipModel ( ) . getRelationshipMember ( ) . getJavaClass ( ) ) ) { IdentityType relationshipIdentity = property . getValue ( relationship ) ; // We use the convention ""Identity ID:Partition ID"" to store identity references // TODO maybe replace this with an IdentityReference instead? graph . setProperty ( config . getRelationshipModel ( ) . getRelationshipMember ( ) , String . format ( "" %s:%s "" , relationshipIdentity . getId ( ) , relationshipIdentity . getPartition ( ) . getId ( ) ) ) ; } else { // Otherwise we set the value to the entity with the specified identifier AttributedType member = ( AttributedType ) config . getRelationshipModel ( ) . getRelationshipMember ( ) . getValue ( relationship ) ; String identifier = member . getId ( ) ; Object identityEntity = lookupEntityByParameter ( context , config . getIdentityModel ( ) , IdentityType . class , "" id "" , identifier ) ; graph . setProperty ( config . getRelationshipModel ( ) . getRelationshipMember ( ) , identityEntity ) ; } graph . setProperty ( config . getRelationshipModel ( ) . getRelationshipDescriptor ( ) , property . getName ( ) ) ; // <SATD_START> TODO set the owner property <SATD_END> } graph . persist ( getEntityManager ( context ) ) ; } }","@ Override public void add  ( IdentityContext context , AttributedType attributedType ) { attributedType . setId ( context . getIdGenerator ( ) . generate ( ) ) ; if ( IdentityType . class . isInstance ( attributedType ) ) { IdentityType identityType = ( IdentityType ) attributedType ; identityType . setPartition ( context . getPartition ( ) ) ; } EntityManager entityManager = getEntityManager ( context ) ; for ( EntityMapper entityMapper : getMapperFor ( attributedType . getClass ( ) ) ) { Object entity = entityMapper . createEntity ( attributedType , entityManager ) ; if ( entity != null ) { entityManager . persist ( entity ) ; } if ( Relationship . class . isInstance ( attributedType ) ) { addRelationshipIdentity ( attributedType , entityManager ) ; } } entityManager . flush ( ) ; }",2013-07-15 22:12:23 +1000,2013/7/17 22:17,0,0.08196248196248196
272,125,https://www.github.com/apache/aries,setExportIsolationPolicy(AriesSubsystem),NOT_DESIGN,150,150,150,150,TODO Implement export isolation policy for composites.,https://www.github.com/apache/aries/commit/50df644c8b,https://www.github.com/apache/aries/commit/93515a7e9d5eb2dfc0343afebb2b1caf4f2da60f,subsystem/subsystem-core/src/main/java/org/apache/aries/subsystem/core/internal/StartAction.java,"private void setExportIsolationPolicy(AriesSubsystem subsystem) throws InvalidSyntaxException, IOException, BundleException, URISyntaxException, ResolutionException {
if (subsystem.isRoot())
// Nothing to do if this is the root subsystem.
return;
if (!subsystem.isScoped())
// Features share the same isolation as that of their scoped parent.
return;
Region from = ((AriesSubsystem)subsystem.getParents().iterator().next()).getRegion();
Region to = subsystem.getRegion();
RegionFilterBuilder builder = from.getRegionDigraph().createRegionFilterBuilder();
if (subsystem.isComposite()) {
setExportIsolationPolicy(builder, subsystem.getDeploymentManifest().getExportPackageHeader(), subsystem);
setExportIsolationPolicy(builder, subsystem.getDeploymentManifest().getProvideCapabilityHeader(), subsystem);
setExportIsolationPolicy(builder, subsystem.getDeploymentManifest().getSubsystemExportServiceHeader(), subsystem);
// TODO Implement export isolation policy for composites.
}
RegionFilter regionFilter = builder.build();
if (logger.isDebugEnabled())
logger.debug(""Establishing region connection: from="" + from
+ "", to="" + to + "", filter="" + regionFilter);
from.connectRegion(to, regionFilter);
}","private void setExportIsolationPolicy(AriesSubsystem subsystem) throws InvalidSyntaxException, IOException, BundleException, URISyntaxException, ResolutionException {
if (!subsystem.isComposite())
return;
Region from = ((AriesSubsystem)subsystem.getParents().iterator().next()).getRegion();
Region to = subsystem.getRegion();
RegionFilterBuilder builder = from.getRegionDigraph().createRegionFilterBuilder();
setExportIsolationPolicy(builder, subsystem.getDeploymentManifest().getExportPackageHeader(), subsystem);
setExportIsolationPolicy(builder, subsystem.getDeploymentManifest().getProvideCapabilityHeader(), subsystem);
setExportIsolationPolicy(builder, subsystem.getDeploymentManifest().getSubsystemExportServiceHeader(), subsystem);
RegionFilter regionFilter = builder.build();
if (regionFilter.getSharingPolicy().isEmpty())
return;
if (logger.isDebugEnabled())
logger.debug(""Establishing region connection: from="" + from
+ "", to="" + to + "", filter="" + regionFilter);
from.connectRegion(to, regionFilter);
}","private void setExportIsolationPolicy  ( AriesSubsystem subsystem ) throws InvalidSyntaxException , IOException , BundleException , URISyntaxException , ResolutionException { if ( subsystem . isRoot ( ) ) // Nothing to do if this is the root subsystem. return ; if ( ! subsystem . isScoped ( ) ) // Features share the same isolation as that of their scoped parent. return ; Region from = ( ( AriesSubsystem ) subsystem . getParents ( ) . iterator ( ) . next ( ) ) . getRegion ( ) ; Region to = subsystem . getRegion ( ) ; RegionFilterBuilder builder = from . getRegionDigraph ( ) . createRegionFilterBuilder ( ) ; if ( subsystem . isComposite ( ) ) { setExportIsolationPolicy ( builder , subsystem . getDeploymentManifest ( ) . getExportPackageHeader ( ) , subsystem ) ; setExportIsolationPolicy ( builder , subsystem . getDeploymentManifest ( ) . getProvideCapabilityHeader ( ) , subsystem ) ; setExportIsolationPolicy ( builder , subsystem . getDeploymentManifest ( ) . getSubsystemExportServiceHeader ( ) , subsystem ) ; // <SATD_START> TODO Implement export isolation policy for composites. <SATD_END> } RegionFilter regionFilter = builder . build ( ) ; if ( logger . isDebugEnabled ( ) ) logger . debug ( "" Establishing region connection: from= "" + from + "" , to= "" + to + "" , filter= "" + regionFilter ) ; from . connectRegion ( to , regionFilter ) ; }","private void setExportIsolationPolicy  ( AriesSubsystem subsystem ) throws InvalidSyntaxException , IOException , BundleException , URISyntaxException , ResolutionException { if ( ! subsystem . isComposite ( ) ) return ; Region from = ( ( AriesSubsystem ) subsystem . getParents ( ) . iterator ( ) . next ( ) ) . getRegion ( ) ; Region to = subsystem . getRegion ( ) ; RegionFilterBuilder builder = from . getRegionDigraph ( ) . createRegionFilterBuilder ( ) ; setExportIsolationPolicy ( builder , subsystem . getDeploymentManifest ( ) . getExportPackageHeader ( ) , subsystem ) ; setExportIsolationPolicy ( builder , subsystem . getDeploymentManifest ( ) . getProvideCapabilityHeader ( ) , subsystem ) ; setExportIsolationPolicy ( builder , subsystem . getDeploymentManifest ( ) . getSubsystemExportServiceHeader ( ) , subsystem ) ; RegionFilter regionFilter = builder . build ( ) ; if ( regionFilter . getSharingPolicy ( ) . isEmpty ( ) ) return ; if ( logger . isDebugEnabled ( ) ) logger . debug ( "" Establishing region connection: from= "" + from + "" , to= "" + to + "" , filter= "" + regionFilter ) ; from . connectRegion ( to , regionFilter ) ; }",2012-06-24 19:48:40 +0000,2012-07-02 18:24:15 +0000,0,0.1556264964086193
2125,550,https://www.github.com/chariotsolutions/phonegap-nfc,onNewIntent(Intent),DESIGN,294,294,294,294,TODO parseMessage should unset after parsing?,https://www.github.com/chariotsolutions/phonegap-nfc/commit/34136620,https://www.github.com/chariotsolutions/phonegap-nfc/commit/4f1d6d7826a1eb6af498dbf3062b51a8b31739c2,src/com/chariotsolutions/nfc/plugin/NdefPlugin.java,"@Override
public void onNewIntent(Intent intent) {
Log.d(TAG, ""onNewIntent "" + intent);
super.onNewIntent(intent);
ctx.setIntent(intent);
parseMessage();
ctx.setIntent(new Intent()); // TODO parseMessage should unset after parsing?
}","@Override
public void onNewIntent(Intent intent) {
Log.d(TAG, ""onNewIntent "" + intent);
super.onNewIntent(intent);
ctx.setIntent(intent);
parseMessage();
}","@ Override public void onNewIntent  ( Intent intent ) { Log . d ( TAG , "" onNewIntent  "" + intent ) ; super . onNewIntent ( intent ) ; ctx . setIntent ( intent ) ; parseMessage ( ) ; ctx . setIntent ( new Intent ( ) ) ; // <SATD_START> TODO parseMessage should unset after parsing? <SATD_END> }","@ Override public void onNewIntent  ( Intent intent ) { Log . d ( TAG , "" onNewIntent  "" + intent ) ; super . onNewIntent ( intent ) ; ctx . setIntent ( intent ) ; parseMessage ( ) ; }",2011/7/26 2:18,2011/7/26 9:43,0,0.7698744769874477
1619,66,https://www.github.com/apache/wicket,testRenderHomePage(),,57,57,57,57,TODO disable until code from 1_0_0_0 has been merged,https://www.github.com/apache/wicket/commit/b4bd7ebae00,https://www.github.com/apache/wicket/commit/1c57f498ef2d21283b60514608134a76df666b41,wicket/src/test/wicket/markup/html/basic/SimplePageTest.java,"public void testRenderHomePage() throws Exception
{
// TODO disable until code from 1_0_0_0 has been merged
//executeTest(SimplePage.class, ""SimplePageExpectedResult.html"");
}","public void testRenderHomePage() throws Exception
{
executeTest(SimplePage.class, ""SimplePageExpectedResult.html"");
}","public void testRenderHomePage  ( ) throws Exception  { // <SATD_START> TODO disable until code from 1_0_0_0 has been merged <SATD_END> //executeTest(SimplePage.class, ""SimplePageExpectedResult.html""); }","public void testRenderHomePage  ( ) throws Exception  { executeTest ( SimplePage . class , "" SimplePageExpectedResult.html "" ) ; }",2005-05-29 14:07:15 +0000,2005-05-29 17:52:42 +0000,0,0.7267267267267268
835,431,https://www.github.com/kiegroup/optaplanner,"readPatternList(NurseRoster, Element)",,342,342,342,342,TODO shiftType & day etc,https://www.github.com/kiegroup/optaplanner/commit/b040173d679,https://www.github.com/kiegroup/optaplanner/commit/68e810d2930f2872a9b3106df6605fabc1f57514,drools-planner/drools-planner-examples/src/main/java/org/drools/planner/examples/nurserostering/persistence/NurseRosteringSolutionImporter.java,"private void readPatternList(NurseRoster nurseRoster, Element patternsElement) throws JDOMException {
List<Pattern> patternList;
if (patternsElement == null) {
patternList = Collections.emptyList();
} else {
List<Element> patternElementList = (List<Element>) patternsElement.getChildren();
patternList = new ArrayList<Pattern>(patternElementList.size());
patternMap = new HashMap<String, Pattern>(patternElementList.size());
long id = 0L;
for (Element element : patternElementList) {
assertElementName(element, ""Pattern"");
Pattern pattern = new Pattern();
pattern.setId(id);
pattern.setCode(element.getAttribute(""ID"").getValue());
pattern.setWeight(element.getAttribute(""weight"").getIntValue());
List<Element> patternEntryElementList = (List<Element>) element.getChild(""PatternEntries"")
.getChildren();
for (Element patternEntryElement : patternEntryElementList) {
assertElementName(patternEntryElement, ""PatternEntry"");
Element shiftTypeElement = patternEntryElement.getChild(""ShiftType"");
ShiftType shiftType = shiftTypeMap.get(shiftTypeElement.getText());
if (shiftType == null) {
if (shiftTypeElement.getText().equals(""Any"")) {
// TODO
} else if (shiftTypeElement.getText().equals(""None"")) {
// TODO
} else {
throw new IllegalArgumentException(""The shiftType ("" + shiftTypeElement.getText()
+ "") of pattern ("" + pattern.getCode() + "") does not exist."");
}
}
Element dayElement = patternEntryElement.getChild(""Day"");
DayOfWeek dayOfWeek = DayOfWeek.valueOfCode(dayElement.getText());
if (dayOfWeek == null) {
if (dayElement.getText().equals(""Any"")) {
// TODO
} else {
throw new IllegalArgumentException(""The dayOfWeek ("" + dayElement.getText()
+ "") of pattern ("" + pattern.getCode() + "") does not exist."");
}
}
// TODO shiftType & day etc
//        <PatternEntry index=""0"">
//          <ShiftType>None</ShiftType>
//          <Day>Friday</Day>
//        </PatternEntry>
//        <PatternEntry index=""1"">
//          <ShiftType>Any</ShiftType>
//          <Day>Saturday</Day>
//        </PatternEntry>
//        <PatternEntry index=""2"">
//          <ShiftType>Any</ShiftType>
//          <Day>Sunday</Day>
//        </PatternEntry>
}
patternList.add(pattern);
if (patternMap.containsKey(pattern.getCode())) {
throw new IllegalArgumentException(""There are 2 patterns with the same code (""
+ pattern.getCode() + "")."");
}
patternMap.put(pattern.getCode(), pattern);
id++;
}
}
nurseRoster.setPatternList(patternList);
}","private void readPatternList(NurseRoster nurseRoster, Element patternsElement) throws JDOMException {
List<Pattern> patternList;
List<PatternEntry> patternEntryList;
if (patternsElement == null) {
patternList = Collections.emptyList();
patternEntryList = Collections.emptyList();
} else {
List<Element> patternElementList = (List<Element>) patternsElement.getChildren();
patternList = new ArrayList<Pattern>(patternElementList.size());
patternMap = new HashMap<String, Pattern>(patternElementList.size());
long id = 0L;
patternEntryList = new ArrayList<PatternEntry>(patternElementList.size() * 3);
long patternEntryId = 0L;
for (Element element : patternElementList) {
assertElementName(element, ""Pattern"");
Pattern pattern = new Pattern();
pattern.setId(id);
pattern.setCode(element.getAttribute(""ID"").getValue());
pattern.setWeight(element.getAttribute(""weight"").getIntValue());
List<Element> patternEntryElementList = (List<Element>) element.getChild(""PatternEntries"")
.getChildren();
int entryIndex = 0;
for (Element patternEntryElement : patternEntryElementList) {
assertElementName(patternEntryElement, ""PatternEntry"");
Element shiftTypeElement = patternEntryElement.getChild(""ShiftType"");
PatternEntryPropertyWildcard shiftTypeWildcard;
ShiftType shiftType = shiftTypeMap.get(shiftTypeElement.getText());
if (shiftType == null) {
if (shiftTypeElement.getText().equals(""Any"")) {
shiftTypeWildcard = PatternEntryPropertyWildcard.ANY;
} else if (shiftTypeElement.getText().equals(""None"")) {
shiftTypeWildcard = PatternEntryPropertyWildcard.NONE;
} else {
throw new IllegalArgumentException(""The shiftType ("" + shiftTypeElement.getText()
+ "") of pattern ("" + pattern.getCode() + "") does not exist."");
}
} else {
shiftTypeWildcard = PatternEntryPropertyWildcard.SPECIFIC;
}
Element dayElement = patternEntryElement.getChild(""Day"");
PatternEntryPropertyWildcard dayOfWeekWildcard;
DayOfWeek dayOfWeek = DayOfWeek.valueOfCode(dayElement.getText());
if (dayOfWeek == null) {
if (dayElement.getText().equals(""Any"")) {
dayOfWeekWildcard = PatternEntryPropertyWildcard.ANY;
} else {
throw new IllegalArgumentException(""The dayOfWeek ("" + dayElement.getText()
+ "") of pattern ("" + pattern.getCode() + "") does not exist."");
}
} else {
dayOfWeekWildcard = PatternEntryPropertyWildcard.SPECIFIC;
}
PatternEntry patternEntry = new PatternEntry();
patternEntry.setId(patternEntryId);
patternEntry.setPattern(pattern);
patternEntry.setEntryIndex(entryIndex);
patternEntry.setDayOfWeekWildcard(dayOfWeekWildcard);
patternEntry.setDayOfWeek(dayOfWeek);
patternEntry.setShiftTypeWildcard(shiftTypeWildcard);
patternEntry.setShiftType(shiftType);
patternEntryList.add(patternEntry);
patternEntryId++;
entryIndex++;
}
patternList.add(pattern);
if (patternMap.containsKey(pattern.getCode())) {
throw new IllegalArgumentException(""There are 2 patterns with the same code (""
+ pattern.getCode() + "")."");
}
patternMap.put(pattern.getCode(), pattern);
id++;
}
}
nurseRoster.setPatternList(patternList);
nurseRoster.setPatternEntryList(patternEntryList);
}","private void readPatternList  ( NurseRoster nurseRoster , Element patternsElement ) throws JDOMException { List < Pattern > patternList ; if ( patternsElement == null ) { patternList = Collections . emptyList ( ) ; } else { List < Element > patternElementList = ( List < Element > ) patternsElement . getChildren ( ) ; patternList = new ArrayList < Pattern > ( patternElementList . size ( ) ) ; patternMap = new HashMap < String , Pattern > ( patternElementList . size ( ) ) ; long id = 0L ; for ( Element element : patternElementList ) { assertElementName ( element , "" Pattern "" ) ; Pattern pattern = new Pattern ( ) ; pattern . setId ( id ) ; pattern . setCode ( element . getAttribute ( "" ID "" ) . getValue ( ) ) ; pattern . setWeight ( element . getAttribute ( "" weight "" ) . getIntValue ( ) ) ; List < Element > patternEntryElementList = ( List < Element > ) element . getChild ( "" PatternEntries "" ) . getChildren ( ) ; for ( Element patternEntryElement : patternEntryElementList ) { assertElementName ( patternEntryElement , "" PatternEntry "" ) ; Element shiftTypeElement = patternEntryElement . getChild ( "" ShiftType "" ) ; ShiftType shiftType = shiftTypeMap . get ( shiftTypeElement . getText ( ) ) ; if ( shiftType == null ) { if ( shiftTypeElement . getText ( ) . equals ( "" Any "" ) ) { // TODO } else if ( shiftTypeElement . getText ( ) . equals ( "" None "" ) ) { // TODO } else { throw new IllegalArgumentException ( "" The shiftType ( "" + shiftTypeElement . getText ( ) + "" ) of pattern ( "" + pattern . getCode ( ) + "" ) does not exist. "" ) ; } } Element dayElement = patternEntryElement . getChild ( "" Day "" ) ; DayOfWeek dayOfWeek = DayOfWeek . valueOfCode ( dayElement . getText ( ) ) ; if ( dayOfWeek == null ) { if ( dayElement . getText ( ) . equals ( "" Any "" ) ) { // TODO } else { throw new IllegalArgumentException ( "" The dayOfWeek ( "" + dayElement . getText ( ) + "" ) of pattern ( "" + pattern . getCode ( ) + "" ) does not exist. "" ) ; } } // <SATD_START> TODO shiftType & day etc <SATD_END> //        <PatternEntry index=""0""> //          <ShiftType>None</ShiftType> //          <Day>Friday</Day> //        </PatternEntry> //        <PatternEntry index=""1""> //          <ShiftType>Any</ShiftType> //          <Day>Saturday</Day> //        </PatternEntry> //        <PatternEntry index=""2""> //          <ShiftType>Any</ShiftType> //          <Day>Sunday</Day> //        </PatternEntry> } patternList . add ( pattern ) ; if ( patternMap . containsKey ( pattern . getCode ( ) ) ) { throw new IllegalArgumentException ( "" There are 2 patterns with the same code ( "" + pattern . getCode ( ) + "" ). "" ) ; } patternMap . put ( pattern . getCode ( ) , pattern ) ; id ++ ; } } nurseRoster . setPatternList ( patternList ) ; }","private void readPatternList  ( NurseRoster nurseRoster , Element patternsElement ) throws JDOMException { List < Pattern > patternList ; List < PatternEntry > patternEntryList ; if ( patternsElement == null ) { patternList = Collections . emptyList ( ) ; patternEntryList = Collections . emptyList ( ) ; } else { List < Element > patternElementList = ( List < Element > ) patternsElement . getChildren ( ) ; patternList = new ArrayList < Pattern > ( patternElementList . size ( ) ) ; patternMap = new HashMap < String , Pattern > ( patternElementList . size ( ) ) ; long id = 0L ; patternEntryList = new ArrayList < PatternEntry > ( patternElementList . size ( ) * 3 ) ; long patternEntryId = 0L ; for ( Element element : patternElementList ) { assertElementName ( element , "" Pattern "" ) ; Pattern pattern = new Pattern ( ) ; pattern . setId ( id ) ; pattern . setCode ( element . getAttribute ( "" ID "" ) . getValue ( ) ) ; pattern . setWeight ( element . getAttribute ( "" weight "" ) . getIntValue ( ) ) ; List < Element > patternEntryElementList = ( List < Element > ) element . getChild ( "" PatternEntries "" ) . getChildren ( ) ; int entryIndex = 0 ; for ( Element patternEntryElement : patternEntryElementList ) { assertElementName ( patternEntryElement , "" PatternEntry "" ) ; Element shiftTypeElement = patternEntryElement . getChild ( "" ShiftType "" ) ; PatternEntryPropertyWildcard shiftTypeWildcard ; ShiftType shiftType = shiftTypeMap . get ( shiftTypeElement . getText ( ) ) ; if ( shiftType == null ) { if ( shiftTypeElement . getText ( ) . equals ( "" Any "" ) ) { shiftTypeWildcard = PatternEntryPropertyWildcard . ANY ; } else if ( shiftTypeElement . getText ( ) . equals ( "" None "" ) ) { shiftTypeWildcard = PatternEntryPropertyWildcard . NONE ; } else { throw new IllegalArgumentException ( "" The shiftType ( "" + shiftTypeElement . getText ( ) + "" ) of pattern ( "" + pattern . getCode ( ) + "" ) does not exist. "" ) ; } } else { shiftTypeWildcard = PatternEntryPropertyWildcard . SPECIFIC ; } Element dayElement = patternEntryElement . getChild ( "" Day "" ) ; PatternEntryPropertyWildcard dayOfWeekWildcard ; DayOfWeek dayOfWeek = DayOfWeek . valueOfCode ( dayElement . getText ( ) ) ; if ( dayOfWeek == null ) { if ( dayElement . getText ( ) . equals ( "" Any "" ) ) { dayOfWeekWildcard = PatternEntryPropertyWildcard . ANY ; } else { throw new IllegalArgumentException ( "" The dayOfWeek ( "" + dayElement . getText ( ) + "" ) of pattern ( "" + pattern . getCode ( ) + "" ) does not exist. "" ) ; } } else { dayOfWeekWildcard = PatternEntryPropertyWildcard . SPECIFIC ; } PatternEntry patternEntry = new PatternEntry ( ) ; patternEntry . setId ( patternEntryId ) ; patternEntry . setPattern ( pattern ) ; patternEntry . setEntryIndex ( entryIndex ) ; patternEntry . setDayOfWeekWildcard ( dayOfWeekWildcard ) ; patternEntry . setDayOfWeek ( dayOfWeek ) ; patternEntry . setShiftTypeWildcard ( shiftTypeWildcard ) ; patternEntry . setShiftType ( shiftType ) ; patternEntryList . add ( patternEntry ) ; patternEntryId ++ ; entryIndex ++ ; } patternList . add ( pattern ) ; if ( patternMap . containsKey ( pattern . getCode ( ) ) ) { throw new IllegalArgumentException ( "" There are 2 patterns with the same code ( "" + pattern . getCode ( ) + "" ). "" ) ; } patternMap . put ( pattern . getCode ( ) , pattern ) ; id ++ ; } } nurseRoster . setPatternList ( patternList ) ; nurseRoster . setPatternEntryList ( patternEntryList ) ; }",2010-03-28 12:37:40 +0000,2010-05-28 19:46:03 +0000,0,0.7352893499756848
2238,431,https://www.github.com/kiegroup/optaplanner,readProcessList(),,225,225,225,225,TODO move cost,https://www.github.com/kiegroup/optaplanner/commit/b154e0d8799,https://www.github.com/kiegroup/optaplanner/commit/05370f76aaaffd2d4976b14bc2ca857b244607c0,drools-planner-examples/src/main/java/org/drools/planner/examples/machinereassignment/persistence/MachineReassignmentSolutionImporter.java,"private void readProcessList() throws IOException {
int processListSize = readIntegerValue();
List<MrProcess> processList = new ArrayList<MrProcess>(processListSize);
long processId = 0L;
List<MrProcessRequirement> processRequirementList = new ArrayList<MrProcessRequirement>(processListSize * resourceListSize);
long processRequirementId = 0L;
for (int i = 0; i < processListSize; i++) {
String line = readStringValue();
String[] lineTokens = splitBySpace(line, 2 + resourceListSize);
MrProcess process = new MrProcess();
process.setId(processId);
int serviceIndex = Integer.parseInt(lineTokens[0]);
if (serviceIndex >= serviceList.size()) {
throw new IllegalArgumentException(""Process with id ("" + processId
+ "") has a non existing serviceIndex ("" + serviceIndex + "")."");
}
MrService service = serviceList.get(serviceIndex);
process.setService(service);
for (int j = 0; j < resourceListSize; j++) {
MrProcessRequirement processRequirement = new MrProcessRequirement();
processRequirement.setId(processRequirementId);
processRequirement.setProcess(process);
processRequirement.setResource(resourceList.get(j));
processRequirement.setUsage(Integer.parseInt(lineTokens[1 + j]));
processRequirementList.add(processRequirement);
processRequirementId++;
}
// TODO move cost
processList.add(process);
processId++;
}
machineReassignment.setProcessList(processList);
machineReassignment.setProcessRequirementList(processRequirementList);
}","private void readProcessList() throws IOException {
int processListSize = readIntegerValue();
List<MrProcess> processList = new ArrayList<MrProcess>(processListSize);
long processId = 0L;
List<MrProcessRequirement> processRequirementList = new ArrayList<MrProcessRequirement>(processListSize * resourceListSize);
long processRequirementId = 0L;
for (int i = 0; i < processListSize; i++) {
String line = readStringValue();
String[] lineTokens = splitBySpace(line, 2 + resourceListSize);
MrProcess process = new MrProcess();
process.setId(processId);
int serviceIndex = Integer.parseInt(lineTokens[0]);
if (serviceIndex >= serviceList.size()) {
throw new IllegalArgumentException(""Process with id ("" + processId
+ "") has a non existing serviceIndex ("" + serviceIndex + "")."");
}
MrService service = serviceList.get(serviceIndex);
process.setService(service);
for (int j = 0; j < resourceListSize; j++) {
MrProcessRequirement processRequirement = new MrProcessRequirement();
processRequirement.setId(processRequirementId);
processRequirement.setProcess(process);
processRequirement.setResource(resourceList.get(j));
processRequirement.setUsage(Integer.parseInt(lineTokens[1 + j]));
processRequirementList.add(processRequirement);
processRequirementId++;
}
process.setMoveCost(Integer.parseInt(lineTokens[1 + resourceListSize]));
processList.add(process);
processId++;
}
machineReassignment.setProcessList(processList);
machineReassignment.setProcessRequirementList(processRequirementList);
}","private void readProcessList  ( ) throws IOException { int processListSize = readIntegerValue ( ) ; List < MrProcess > processList = new ArrayList < MrProcess > ( processListSize ) ; long processId = 0L ; List < MrProcessRequirement > processRequirementList = new ArrayList < MrProcessRequirement > ( processListSize * resourceListSize ) ; long processRequirementId = 0L ; for ( int i = 0 ; i < processListSize ; i ++ ) { String line = readStringValue ( ) ; String [ ] lineTokens = splitBySpace ( line , 2 + resourceListSize ) ; MrProcess process = new MrProcess ( ) ; process . setId ( processId ) ; int serviceIndex = Integer . parseInt ( lineTokens [ 0 ] ) ; if ( serviceIndex >= serviceList . size ( ) ) { throw new IllegalArgumentException ( "" Process with id ( "" + processId + "" ) has a non existing serviceIndex ( "" + serviceIndex + "" ). "" ) ; } MrService service = serviceList . get ( serviceIndex ) ; process . setService ( service ) ; for ( int j = 0 ; j < resourceListSize ; j ++ ) { MrProcessRequirement processRequirement = new MrProcessRequirement ( ) ; processRequirement . setId ( processRequirementId ) ; processRequirement . setProcess ( process ) ; processRequirement . setResource ( resourceList . get ( j ) ) ; processRequirement . setUsage ( Integer . parseInt ( lineTokens [ 1 + j ] ) ) ; processRequirementList . add ( processRequirement ) ; processRequirementId ++ ; } // <SATD_START> TODO move cost <SATD_END> processList . add ( process ) ; processId ++ ; } machineReassignment . setProcessList ( processList ) ; machineReassignment . setProcessRequirementList ( processRequirementList ) ; }","private void readProcessList  ( ) throws IOException { int processListSize = readIntegerValue ( ) ; List < MrProcess > processList = new ArrayList < MrProcess > ( processListSize ) ; long processId = 0L ; List < MrProcessRequirement > processRequirementList = new ArrayList < MrProcessRequirement > ( processListSize * resourceListSize ) ; long processRequirementId = 0L ; for ( int i = 0 ; i < processListSize ; i ++ ) { String line = readStringValue ( ) ; String [ ] lineTokens = splitBySpace ( line , 2 + resourceListSize ) ; MrProcess process = new MrProcess ( ) ; process . setId ( processId ) ; int serviceIndex = Integer . parseInt ( lineTokens [ 0 ] ) ; if ( serviceIndex >= serviceList . size ( ) ) { throw new IllegalArgumentException ( "" Process with id ( "" + processId + "" ) has a non existing serviceIndex ( "" + serviceIndex + "" ). "" ) ; } MrService service = serviceList . get ( serviceIndex ) ; process . setService ( service ) ; for ( int j = 0 ; j < resourceListSize ; j ++ ) { MrProcessRequirement processRequirement = new MrProcessRequirement ( ) ; processRequirement . setId ( processRequirementId ) ; processRequirement . setProcess ( process ) ; processRequirement . setResource ( resourceList . get ( j ) ) ; processRequirement . setUsage ( Integer . parseInt ( lineTokens [ 1 + j ] ) ) ; processRequirementList . add ( processRequirement ) ; processRequirementId ++ ; } process . setMoveCost ( Integer . parseInt ( lineTokens [ 1 + resourceListSize ] ) ) ; processList . add ( process ) ; processId ++ ; } machineReassignment . setProcessList ( processList ) ; machineReassignment . setProcessRequirementList ( processRequirementList ) ; }",2011-10-22 11:14:05 +0200,2011-10-22 11:15:21 +0200,0,0.9619018591892715
3840,323,https://www.github.com/validator/validator,emitDocField(),NOT_DESIGN,1225,1225,1225,1225,XXX drop last sentence for html5 facet,https://www.github.com/validator/validator/commit/0cad7cb4f,https://www.github.com/validator/validator/commit/2154214a2e64bbc92deafb34ab60f520b81b97b7,src/nu/validator/servlet/VerifierServletTransaction.java,"void emitDocField() throws SAXException {
attrs.clear();
attrs.addAttribute(""type"", ""url"");
attrs.addAttribute(""name"", ""doc"");
attrs.addAttribute(""id"", ""doc"");
attrs.addAttribute(""pattern"", ""(?:https?://.+)?"");
attrs.addAttribute(
                ""title"",
                // XXX drop last sentence for html5 facet
""The document field takes the absolute IRI (http or https only) of the document to be checked. (The document field can also be left blank in order to bookmark settings.)"");
if (document != null) {
attrs.addAttribute(""value"", scrub(document));
}
emitter.startElement(""input"", attrs);
emitter.endElement(""input"");
}","void emitDocField() throws SAXException {
attrs.clear();
attrs.addAttribute(""type"", ""url"");
attrs.addAttribute(""name"", ""doc"");
attrs.addAttribute(""id"", ""doc"");
attrs.addAttribute(""pattern"", ""(?:https?://.+)?"");
attrs.addAttribute(
                ""title"",
                ""Absolute IRI (http or https only) of the document to be checked."");
if (document != null) {
attrs.addAttribute(""value"", scrub(document));
}
emitter.startElement(""input"", attrs);
emitter.endElement(""input"");
}","void emitDocField  ( ) throws SAXException  { attrs . clear ( ) ; attrs . addAttribute ( "" type "" , "" url "" ) ; attrs . addAttribute ( "" name "" , "" doc "" ) ; attrs . addAttribute ( "" id "" , "" doc "" ) ; attrs . addAttribute ( "" pattern "" , "" (?:https?://.+)? "" ) ; attrs . addAttribute ( "" title "" , // <SATD_START> XXX drop last sentence for html5 facet <SATD_END> "" The document field takes the absolute IRI (http or https only) of the document to be checked. (The document field can also be left blank in order to bookmark settings.) "" ) ; if ( document != null ) { attrs . addAttribute ( "" value "" , scrub ( document ) ) ; } emitter . startElement ( "" input "" , attrs ) ; emitter . endElement ( "" input "" ) ; }","void emitDocField  ( ) throws SAXException  { attrs . clear ( ) ; attrs . addAttribute ( "" type "" , "" url "" ) ; attrs . addAttribute ( "" name "" , "" doc "" ) ; attrs . addAttribute ( "" id "" , "" doc "" ) ; attrs . addAttribute ( "" pattern "" , "" (?:https?://.+)? "" ) ; attrs . addAttribute ( "" title "" , "" Absolute IRI (http or https only) of the document to be checked. "" ) ; if ( document != null ) { attrs . addAttribute ( "" value "" , scrub ( document ) ) ; } emitter . startElement ( "" input "" , attrs ) ; emitter . endElement ( "" input "" ) ; }",2007-09-16 17:16:47 +0000,2008-01-16 13:03:42 +0000,0,0.8598726114649682
2021,449,https://www.github.com/movingblocks/terasology,sendNewChunks(NetData.NetMessage.Builder),,165,165,165,165,TODO: probably need to queue and dripfeed these to prevent flooding,https://www.github.com/movingblocks/terasology/commit/6b9ac8b412,https://www.github.com/movingblocks/terasology/commit/caa27eacf32597e80818b6ed70e477fd07f0daa4,src/main/java/org/terasology/network/NetClient.java,"private void sendNewChunks(NetData.NetMessage.Builder message) {
if (!readyChunks.isEmpty()) {
Iterator<Map.Entry<Vector3i, Chunk>> i = readyChunks.entrySet().iterator();
while (i.hasNext()) {
Map.Entry<Vector3i, Chunk> chunkEntry = i.next();
i.remove();
relevantChunks.add(chunkEntry.getKey());
logger.debug(""Sending chunk: {}"", chunkEntry.getKey());
// TODO: probably need to queue and dripfeed these to prevent flooding
message.addChunkInfo(Chunks.getInstance().encode(chunkEntry.getValue())).build();
}
}
}","private void sendNewChunks(NetData.NetMessage.Builder message) {
if (!readyChunks.isEmpty()) {
Vector3i center = new Vector3i();
LocationComponent loc = getEntity().getComponent(ClientComponent.class).character.getComponent(LocationComponent.class);
if (loc != null) {
center.set(TeraMath.calcChunkPos(new Vector3i(loc.getWorldPosition(), 0.5f)));
}
Vector3i pos = null;
int distance = Integer.MAX_VALUE;
for (Vector3i chunkPos : readyChunks.keySet()) {
int chunkDistance = chunkPos.distanceSquared(center);
if (pos == null || chunkDistance < distance) {
pos = chunkPos;
distance = chunkDistance;
}
}
Chunk chunk = readyChunks.remove(pos);
relevantChunks.add(pos);
logger.debug(""Sending chunk: {}"", pos);
message.addChunkInfo(Chunks.getInstance().encode(chunk)).build();
}
}","private void sendNewChunks  ( NetData . NetMessage . Builder message ) { if ( ! readyChunks . isEmpty ( ) ) { Iterator < Map . Entry < Vector3i , Chunk > > i = readyChunks . entrySet ( ) . iterator ( ) ; while ( i . hasNext ( ) ) { Map . Entry < Vector3i , Chunk > chunkEntry = i . next ( ) ; i . remove ( ) ; relevantChunks . add ( chunkEntry . getKey ( ) ) ; logger . debug ( "" Sending chunk: {} "" , chunkEntry . getKey ( ) ) ; // <SATD_START> TODO: probably need to queue and dripfeed these to prevent flooding <SATD_END> message . addChunkInfo ( Chunks . getInstance ( ) . encode ( chunkEntry . getValue ( ) ) ) . build ( ) ; } } }","private void sendNewChunks  ( NetData . NetMessage . Builder message ) { if ( ! readyChunks . isEmpty ( ) ) { Vector3i center = new Vector3i ( ) ; LocationComponent loc = getEntity ( ) . getComponent ( ClientComponent . class ) . character . getComponent ( LocationComponent . class ) ; if ( loc != null ) { center . set ( TeraMath . calcChunkPos ( new Vector3i ( loc . getWorldPosition ( ) , 0.5f ) ) ) ; } Vector3i pos = null ; int distance = Integer . MAX_VALUE ; for ( Vector3i chunkPos : readyChunks . keySet ( ) ) { int chunkDistance = chunkPos . distanceSquared ( center ) ; if ( pos == null || chunkDistance < distance ) { pos = chunkPos ; distance = chunkDistance ; } } Chunk chunk = readyChunks . remove ( pos ) ; relevantChunks . add ( pos ) ; logger . debug ( "" Sending chunk: {} "" , pos ) ; message . addChunkInfo ( Chunks . getInstance ( ) . encode ( chunk ) ) . build ( ) ; } }",2013-03-02 14:23:42 +1100,2013-03-09 16:03:23 +1100,0,0.2999345121152587
817,267,https://www.github.com/coremedia/jangaroo-tools,generateJsCode(JsWriter),DESIGN,53,53,53,53,todo handle directives which are not statements,https://www.github.com/coremedia/jangaroo-tools/commit/f6d3e859c1,https://www.github.com/coremedia/jangaroo-tools/commit/45d4683cf544552901ba1568fd2b6bf5e19e06ac,jangaroo-core/jangaroo-compiler/src/main/java/net/jangaroo/jooc/ClassBody.java,"protected void generateJsCode(JsWriter out) throws IOException {
out.writeSymbolWhitespace(lBrace);
boolean inStaticInitializerBlock = false;
for (Directive directive : directives) {
final boolean isStaticInitializer = !(directive instanceof Declaration); //todo handle directives which are not statements
if (isStaticInitializer) {
inStaticInitializerBlock = beginStaticInitializer(out, inStaticInitializerBlock);
} else {
inStaticInitializerBlock = endStaticInitializer(out, inStaticInitializerBlock);
}
directive.generateJsCode(out);
}
endStaticInitializer(out, inStaticInitializerBlock);
out.writeSymbolWhitespace(rBrace);
}","protected void generateJsCode(JsWriter out) throws IOException {
out.writeSymbolWhitespace(lBrace);
boolean inStaticInitializerBlock = false;
for (Directive directive : directives) {
final boolean isStaticInitializer = directive instanceof Statement && !(directive instanceof Declaration);
if (isStaticInitializer) {
inStaticInitializerBlock = beginStaticInitializer(out, inStaticInitializerBlock);
} else {
inStaticInitializerBlock = endStaticInitializer(out, inStaticInitializerBlock);
}
directive.generateJsCode(out);
}
endStaticInitializer(out, inStaticInitializerBlock);
out.writeSymbolWhitespace(rBrace);
}","protected void generateJsCode  ( JsWriter out ) throws IOException { out . writeSymbolWhitespace ( lBrace ) ; boolean inStaticInitializerBlock = false ; for ( Directive directive : directives ) { final boolean isStaticInitializer = ! ( directive instanceof Declaration ) ; //<SATD_START> todo handle directives which are not statements <SATD_END> if ( isStaticInitializer ) { inStaticInitializerBlock = beginStaticInitializer ( out , inStaticInitializerBlock ) ; } else { inStaticInitializerBlock = endStaticInitializer ( out , inStaticInitializerBlock ) ; } directive . generateJsCode ( out ) ; } endStaticInitializer ( out , inStaticInitializerBlock ) ; out . writeSymbolWhitespace ( rBrace ) ; }","protected void generateJsCode  ( JsWriter out ) throws IOException { out . writeSymbolWhitespace ( lBrace ) ; boolean inStaticInitializerBlock = false ; for ( Directive directive : directives ) { final boolean isStaticInitializer = directive instanceof Statement && ! ( directive instanceof Declaration ) ; if ( isStaticInitializer ) { inStaticInitializerBlock = beginStaticInitializer ( out , inStaticInitializerBlock ) ; } else { inStaticInitializerBlock = endStaticInitializer ( out , inStaticInitializerBlock ) ; } directive . generateJsCode ( out ) ; } endStaticInitializer ( out , inStaticInitializerBlock ) ; out . writeSymbolWhitespace ( rBrace ) ; }",2011/4/8 16:15,2011/4/17 19:08,0,0.9203539823008849
1938,55,https://www.github.com/apache/activemq,testMoveMessages(),DESIGN,103,103,103,103,TODO uncommenting this line causes a hang!,https://www.github.com/apache/activemq/commit/6cd70823cc,https://www.github.com/apache/activemq/commit/47cfa5590bfe5f1015e48ea300c4a8ed9a86e340,activemq-core/src/test/java/org/apache/activemq/broker/jmx/MBeanTest.java,"public void testMoveMessages() throws Exception {
connection = connectionFactory.createConnection();
useConnection(connection);
ObjectName queueViewMBeanName = assertRegisteredObjectName(domain + "":Type=Queue,Destination="" + getDestinationString() + "",BrokerName=localhost"");
QueueViewMBean queue = (QueueViewMBean)MBeanServerInvocationHandler.newProxyInstance(mbeanServer, queueViewMBeanName, QueueViewMBean.class, true);
CompositeData[] compdatalist = queue.browse();
int initialQueueSize = compdatalist.length;
if (initialQueueSize == 0) {
fail(""There is no message in the queue:"");
}
else {
echo(""Current queue size: "" + initialQueueSize);
}
// TODO uncommenting this line causes a hang!
//int messageCount = initialQueueSize;
int messageCount = 10;
String[] messageIDs = new String[messageCount];
for (int i = 0; i < messageCount; i++) {
CompositeData cdata = compdatalist[i];
String messageID = (String) cdata.get(""JMSMessageID"");
assertNotNull(""Should have a message ID for message "" + i, messageID);
messageIDs[i] = messageID;
}
echo(""About to move "" + messageCount + "" messages"");
String newDestination = getSecondDestinationString();
for (String messageID : messageIDs) {
echo(""Moving message: "" + messageID);
queue.moveMessageTo(messageID, newDestination);
}
echo(""Now browsing the queue"");
compdatalist = queue.browse();
int actualCount = compdatalist.length;
echo(""Current queue size: "" + actualCount);
// TODO we seem to have browsed the queue and now there are messages missing!
//assertEquals(""Should now have empty queue but was"", initialQueueSize - messageCount, actualCount);
echo(""Now browsing the second queue"");
queueViewMBeanName = assertRegisteredObjectName(domain + "":Type=Queue,Destination="" + newDestination + "",BrokerName=localhost"");
queue = (QueueViewMBean)MBeanServerInvocationHandler.newProxyInstance(mbeanServer, queueViewMBeanName, QueueViewMBean.class, true);
long newQueuesize = queue.getQueueSize();
echo(""Second queue size: "" + newQueuesize);
assertEquals(""Unexpected number of messages "",messageCount, newQueuesize);
}","public void testMoveMessages() throws Exception {
connection = connectionFactory.createConnection();
useConnection(connection);
ObjectName queueViewMBeanName = assertRegisteredObjectName(domain + "":Type=Queue,Destination="" + getDestinationString() + "",BrokerName=localhost"");
QueueViewMBean queue = (QueueViewMBean)MBeanServerInvocationHandler.newProxyInstance(mbeanServer, queueViewMBeanName, QueueViewMBean.class, true);
CompositeData[] compdatalist = queue.browse();
int initialQueueSize = compdatalist.length;
if (initialQueueSize == 0) {
fail(""There is no message in the queue:"");
}
else {
echo(""Current queue size: "" + initialQueueSize);
}
int messageCount = initialQueueSize;
String[] messageIDs = new String[messageCount];
for (int i = 0; i < messageCount; i++) {
CompositeData cdata = compdatalist[i];
String messageID = (String) cdata.get(""JMSMessageID"");
assertNotNull(""Should have a message ID for message "" + i, messageID);
messageIDs[i] = messageID;
}
echo(""About to move "" + messageCount + "" messages"");
String newDestination = getSecondDestinationString();
for (String messageID : messageIDs) {
echo(""Moving message: "" + messageID);
queue.moveMessageTo(messageID, newDestination);
}
echo(""Now browsing the queue"");
compdatalist = queue.browse();
int actualCount = compdatalist.length;
echo(""Current queue size: "" + actualCount);
assertEquals(""Should now have empty queue but was"", initialQueueSize - messageCount, actualCount);
echo(""Now browsing the second queue"");
queueViewMBeanName = assertRegisteredObjectName(domain + "":Type=Queue,Destination="" + newDestination + "",BrokerName=localhost"");
queue = (QueueViewMBean)MBeanServerInvocationHandler.newProxyInstance(mbeanServer, queueViewMBeanName, QueueViewMBean.class, true);
long newQueuesize = queue.getQueueSize();
echo(""Second queue size: "" + newQueuesize);
assertEquals(""Unexpected number of messages "",messageCount, newQueuesize);
}","public void testMoveMessages  ( ) throws Exception { connection = connectionFactory . createConnection ( ) ; useConnection ( connection ) ; ObjectName queueViewMBeanName = assertRegisteredObjectName ( domain + "" :Type=Queue,Destination= "" + getDestinationString ( ) + "" ,BrokerName=localhost "" ) ; QueueViewMBean queue = ( QueueViewMBean ) MBeanServerInvocationHandler . newProxyInstance ( mbeanServer , queueViewMBeanName , QueueViewMBean . class , true ) ; CompositeData [ ] compdatalist = queue . browse ( ) ; int initialQueueSize = compdatalist . length ; if ( initialQueueSize == 0 ) { fail ( "" There is no message in the queue: "" ) ; } else { echo ( "" Current queue size:  "" + initialQueueSize ) ; } // <SATD_START> TODO uncommenting this line causes a hang! <SATD_END> //int messageCount = initialQueueSize; int messageCount = 10 ; String [ ] messageIDs = new String [ messageCount ] ; for ( int i = 0 ; i < messageCount ; i ++ ) { CompositeData cdata = compdatalist [ i ] ; String messageID = ( String ) cdata . get ( "" JMSMessageID "" ) ; assertNotNull ( "" Should have a message ID for message  "" + i , messageID ) ; messageIDs [ i ] = messageID ; } echo ( "" About to move  "" + messageCount + ""  messages "" ) ; String newDestination = getSecondDestinationString ( ) ; for ( String messageID : messageIDs ) { echo ( "" Moving message:  "" + messageID ) ; queue . moveMessageTo ( messageID , newDestination ) ; } echo ( "" Now browsing the queue "" ) ; compdatalist = queue . browse ( ) ; int actualCount = compdatalist . length ; echo ( "" Current queue size:  "" + actualCount ) ; // TODO we seem to have browsed the queue and now there are messages missing! //assertEquals(""Should now have empty queue but was"", initialQueueSize - messageCount, actualCount); echo ( "" Now browsing the second queue "" ) ; queueViewMBeanName = assertRegisteredObjectName ( domain + "" :Type=Queue,Destination= "" + newDestination + "" ,BrokerName=localhost "" ) ; queue = ( QueueViewMBean ) MBeanServerInvocationHandler . newProxyInstance ( mbeanServer , queueViewMBeanName , QueueViewMBean . class , true ) ; long newQueuesize = queue . getQueueSize ( ) ; echo ( "" Second queue size:  "" + newQueuesize ) ; assertEquals ( "" Unexpected number of messages  "" , messageCount , newQueuesize ) ; }","public void testMoveMessages  ( ) throws Exception { connection = connectionFactory . createConnection ( ) ; useConnection ( connection ) ; ObjectName queueViewMBeanName = assertRegisteredObjectName ( domain + "" :Type=Queue,Destination= "" + getDestinationString ( ) + "" ,BrokerName=localhost "" ) ; QueueViewMBean queue = ( QueueViewMBean ) MBeanServerInvocationHandler . newProxyInstance ( mbeanServer , queueViewMBeanName , QueueViewMBean . class , true ) ; CompositeData [ ] compdatalist = queue . browse ( ) ; int initialQueueSize = compdatalist . length ; if ( initialQueueSize == 0 ) { fail ( "" There is no message in the queue: "" ) ; } else { echo ( "" Current queue size:  "" + initialQueueSize ) ; } int messageCount = initialQueueSize ; String [ ] messageIDs = new String [ messageCount ] ; for ( int i = 0 ; i < messageCount ; i ++ ) { CompositeData cdata = compdatalist [ i ] ; String messageID = ( String ) cdata . get ( "" JMSMessageID "" ) ; assertNotNull ( "" Should have a message ID for message  "" + i , messageID ) ; messageIDs [ i ] = messageID ; } echo ( "" About to move  "" + messageCount + ""  messages "" ) ; String newDestination = getSecondDestinationString ( ) ; for ( String messageID : messageIDs ) { echo ( "" Moving message:  "" + messageID ) ; queue . moveMessageTo ( messageID , newDestination ) ; } echo ( "" Now browsing the queue "" ) ; compdatalist = queue . browse ( ) ; int actualCount = compdatalist . length ; echo ( "" Current queue size:  "" + actualCount ) ; assertEquals ( "" Should now have empty queue but was "" , initialQueueSize - messageCount , actualCount ) ; echo ( "" Now browsing the second queue "" ) ; queueViewMBeanName = assertRegisteredObjectName ( domain + "" :Type=Queue,Destination= "" + newDestination + "" ,BrokerName=localhost "" ) ; queue = ( QueueViewMBean ) MBeanServerInvocationHandler . newProxyInstance ( mbeanServer , queueViewMBeanName , QueueViewMBean . class , true ) ; long newQueuesize = queue . getQueueSize ( ) ; echo ( "" Second queue size:  "" + newQueuesize ) ; assertEquals ( "" Unexpected number of messages  "" , messageCount , newQueuesize ) ; }",2008-08-26 10:33:32 +0000,2008-09-02 06:14:22 +0000,0,0.9563628055745945
423,167,https://www.github.com/bcdev/beam,initialize(),,160,160,160,160,TODO: handle exception,https://www.github.com/bcdev/beam/commit/5811deffb4,https://www.github.com/bcdev/beam/commit/011a429ced6b6fe232897c8446071b78fa0aaa3c,beam-shapefile-reader/src/main/java/org/esa/beam/geospike/MapProjOp.java,"@Override
public void initialize() throws OperatorException {
try {
GeographicCRS baseCRS = DefaultGeographicCRS.WGS84;
final GeoCoding geoCoding = sourceProduct.getGeoCoding();
MathTransform baseToGridMathTransform = new GeoCodingMathTransform(geoCoding, GeoCodingMathTransform.Mode.G2P);
CoordinateReferenceSystem gridCRS = new DefaultDerivedCRS(""The grid CRS"",
                                                                  baseCRS,
                                                                  baseToGridMathTransform,
                                                                  DefaultCartesianCS.DISPLAY);
final GridCoverageFactory factory = CoverageFactoryFinder.getGridCoverageFactory(null);
final Envelope2D sourceEnvelope = new Envelope2D(gridCRS, 0, 0, sourceProduct.getSceneRasterWidth(),
                                                         sourceProduct.getSceneRasterHeight());
final CoordinateReferenceSystem targetCRS = createTargetCRS();
final GridGeometry2D gridGeometry = createGridGeometry(sourceProduct, baseCRS, targetCRS);
Rectangle gridRect = gridGeometry.getGridRange2D();
final Interpolation interpolation = createInterpolation();
targetProduct = new Product(""projected_"" + sourceProduct.getName(),
                                    ""projection of: "" + sourceProduct.getDescription(),
                                    gridRect.width,
                                    gridRect.height);
addMetadataToProduct(targetProduct);
addFlagCodingsToProduct(targetProduct);
addIndexCodingsToProduct(targetProduct);
for (Band sourceBand : sourceProduct.getBands()) {
Band targetBand = targetProduct.addBand(sourceBand.getName(), sourceBand.getDataType());
ProductUtils.copyRasterDataNodeProperties(sourceBand, targetBand);
GridCoverage2D sourceCoverage = createSourceCoverage(factory, sourceEnvelope, sourceBand);
// only the tile size of the image layout is actually taken into account
// by the rasample operation.   Use Operations.DEFAULT if tile size does
// not matter
final Operations operations = new Operations(
                        new Hints(JAI.KEY_IMAGE_LAYOUT, createImageLayout(targetBand)));
GridCoverage2D targetCoverage = (GridCoverage2D) operations.resample(sourceCoverage,
                                                                                     targetCRS,
                                                                                     gridGeometry,
                                                                                     interpolation);
RenderedImage targetImage = targetCoverage.getRenderedImage();
targetBand.setSourceImage(targetImage);
FlagCoding sourceFlagCoding = sourceBand.getFlagCoding();
IndexCoding sourceIndexCoding = sourceBand.getIndexCoding();
if (sourceFlagCoding != null) {
String flagCodingName = sourceFlagCoding.getName();
FlagCoding destFlagCoding = targetProduct.getFlagCodingGroup().get(flagCodingName);
targetBand.setSampleCoding(destFlagCoding);
} else if (sourceIndexCoding != null) {
String indexCodingName = sourceIndexCoding.getName();
IndexCoding destIndexCoding = targetProduct.getIndexCodingGroup().get(indexCodingName);
targetBand.setSampleCoding(destIndexCoding);
}
}
ProductUtils.copyBitmaskDefsAndOverlays(sourceProduct, targetProduct);
copyPlacemarks(sourceProduct.getPinGroup(), targetProduct.getPinGroup(),
                           PlacemarkSymbol.createDefaultPinSymbol());
copyPlacemarks(sourceProduct.getGcpGroup(), targetProduct.getGcpGroup(),
                           PlacemarkSymbol.createDefaultGcpSymbol());
} catch (Throwable e) {
e.printStackTrace();
// TODO: handle exception
}
}","@Override
public void initialize() throws OperatorException {
try {
GeographicCRS baseCRS = DefaultGeographicCRS.WGS84;
final GeoCoding geoCoding = sourceProduct.getGeoCoding();
MathTransform baseToGridMathTransform = new GeoCodingMathTransform(geoCoding,
                                                                               GeoCodingMathTransform.Mode.G2P);
CoordinateReferenceSystem gridCRS = new DefaultDerivedCRS(""The grid CRS"",
                                                                      baseCRS,
                                                                      baseToGridMathTransform,
                                                                      DefaultCartesianCS.DISPLAY);
final GridCoverageFactory factory = CoverageFactoryFinder.getGridCoverageFactory(null);
final Envelope2D sourceEnvelope = new Envelope2D(gridCRS, 0, 0, sourceProduct.getSceneRasterWidth(),
                                                             sourceProduct.getSceneRasterHeight());
final CoordinateReferenceSystem targetCRS = createTargetCRS();
final GridGeometry2D gridGeometry = createGridGeometry(sourceProduct, baseCRS, targetCRS);
Rectangle gridRect = gridGeometry.getGridRange2D();
final Interpolation interpolation = createInterpolation();
targetProduct = new Product(""projected_"" + sourceProduct.getName(),
                                        ""projection of: "" + sourceProduct.getDescription(),
                                        gridRect.width,
                                        gridRect.height);
// TODO: also query operatorContext rendering hints for tile size
final Dimension tileSize = JAIUtils.computePreferredTileSize(gridRect.width, gridRect.height, 1);
targetProduct.setPreferredTileSize(tileSize);
addMetadataToProduct(targetProduct);
addFlagCodingsToProduct(targetProduct);
addIndexCodingsToProduct(targetProduct);
for (Band sourceBand : sourceProduct.getBands()) {
Band targetBand = targetProduct.addBand(sourceBand.getName(), sourceBand.getDataType());
ProductUtils.copyRasterDataNodeProperties(sourceBand, targetBand);
GridCoverage2D sourceCoverage = createSourceCoverage(factory, sourceEnvelope, sourceBand);
// only the tile size of the image layout is actually taken into account
// by the rasample operation.   Use Operations.DEFAULT if tile size does
// not matter
final Operations operations = new Operations(
                        new Hints(JAI.KEY_IMAGE_LAYOUT, createImageLayout(targetBand, tileSize)));
GridCoverage2D targetCoverage = (GridCoverage2D) operations.resample(sourceCoverage,
                                                                                     targetCRS,
                                                                                     gridGeometry,
                                                                                     interpolation);
RenderedImage targetImage = targetCoverage.getRenderedImage();
if (targetImage.getTileHeight() != targetProduct.getPreferredTileSize().getHeight()) {
throw new OperatorException(""tileHeigth = "" + targetImage.getTileHeight());
}
if (targetImage.getTileWidth() != targetProduct.getPreferredTileSize().getWidth()) {
throw new OperatorException(""tileWidth = "" + targetImage.getTileWidth());
}
targetBand.setSourceImage(targetImage);
FlagCoding sourceFlagCoding = sourceBand.getFlagCoding();
IndexCoding sourceIndexCoding = sourceBand.getIndexCoding();
if (sourceFlagCoding != null) {
String flagCodingName = sourceFlagCoding.getName();
FlagCoding destFlagCoding = targetProduct.getFlagCodingGroup().get(flagCodingName);
targetBand.setSampleCoding(destFlagCoding);
} else if (sourceIndexCoding != null) {
String indexCodingName = sourceIndexCoding.getName();
IndexCoding destIndexCoding = targetProduct.getIndexCodingGroup().get(indexCodingName);
targetBand.setSampleCoding(destIndexCoding);
}
}
ProductUtils.copyBitmaskDefsAndOverlays(sourceProduct, targetProduct);
copyPlacemarks(sourceProduct.getPinGroup(), targetProduct.getPinGroup(),
                           PlacemarkSymbol.createDefaultPinSymbol());
copyPlacemarks(sourceProduct.getGcpGroup(), targetProduct.getGcpGroup(),
                           PlacemarkSymbol.createDefaultGcpSymbol());
} catch (OperatorException e) {
throw e;
} catch (Throwable t) {
t.printStackTrace();
throw new OperatorException(t.getMessage(), t);
}
}","@ Override public void initialize  ( ) throws OperatorException { try { GeographicCRS baseCRS = DefaultGeographicCRS . WGS84 ; final GeoCoding geoCoding = sourceProduct . getGeoCoding ( ) ; MathTransform baseToGridMathTransform = new GeoCodingMathTransform ( geoCoding , GeoCodingMathTransform . Mode . G2P ) ; CoordinateReferenceSystem gridCRS = new DefaultDerivedCRS ( "" The grid CRS "" , baseCRS , baseToGridMathTransform , DefaultCartesianCS . DISPLAY ) ; final GridCoverageFactory factory = CoverageFactoryFinder . getGridCoverageFactory ( null ) ; final Envelope2D sourceEnvelope = new Envelope2D ( gridCRS , 0 , 0 , sourceProduct . getSceneRasterWidth ( ) , sourceProduct . getSceneRasterHeight ( ) ) ; final CoordinateReferenceSystem targetCRS = createTargetCRS ( ) ; final GridGeometry2D gridGeometry = createGridGeometry ( sourceProduct , baseCRS , targetCRS ) ; Rectangle gridRect = gridGeometry . getGridRange2D ( ) ; final Interpolation interpolation = createInterpolation ( ) ; targetProduct = new Product ( "" projected_ "" + sourceProduct . getName ( ) , "" projection of:  "" + sourceProduct . getDescription ( ) , gridRect . width , gridRect . height ) ; addMetadataToProduct ( targetProduct ) ; addFlagCodingsToProduct ( targetProduct ) ; addIndexCodingsToProduct ( targetProduct ) ; for ( Band sourceBand : sourceProduct . getBands ( ) ) { Band targetBand = targetProduct . addBand ( sourceBand . getName ( ) , sourceBand . getDataType ( ) ) ; ProductUtils . copyRasterDataNodeProperties ( sourceBand , targetBand ) ; GridCoverage2D sourceCoverage = createSourceCoverage ( factory , sourceEnvelope , sourceBand ) ; // only the tile size of the image layout is actually taken into account // by the rasample operation.   Use Operations.DEFAULT if tile size does // not matter final Operations operations = new Operations ( new Hints ( JAI . KEY_IMAGE_LAYOUT , createImageLayout ( targetBand ) ) ) ; GridCoverage2D targetCoverage = ( GridCoverage2D ) operations . resample ( sourceCoverage , targetCRS , gridGeometry , interpolation ) ; RenderedImage targetImage = targetCoverage . getRenderedImage ( ) ; targetBand . setSourceImage ( targetImage ) ; FlagCoding sourceFlagCoding = sourceBand . getFlagCoding ( ) ; IndexCoding sourceIndexCoding = sourceBand . getIndexCoding ( ) ; if ( sourceFlagCoding != null ) { String flagCodingName = sourceFlagCoding . getName ( ) ; FlagCoding destFlagCoding = targetProduct . getFlagCodingGroup ( ) . get ( flagCodingName ) ; targetBand . setSampleCoding ( destFlagCoding ) ; } else if ( sourceIndexCoding != null ) { String indexCodingName = sourceIndexCoding . getName ( ) ; IndexCoding destIndexCoding = targetProduct . getIndexCodingGroup ( ) . get ( indexCodingName ) ; targetBand . setSampleCoding ( destIndexCoding ) ; } } ProductUtils . copyBitmaskDefsAndOverlays ( sourceProduct , targetProduct ) ; copyPlacemarks ( sourceProduct . getPinGroup ( ) , targetProduct . getPinGroup ( ) , PlacemarkSymbol . createDefaultPinSymbol ( ) ) ; copyPlacemarks ( sourceProduct . getGcpGroup ( ) , targetProduct . getGcpGroup ( ) , PlacemarkSymbol . createDefaultGcpSymbol ( ) ) ; } catch ( Throwable e ) { e . printStackTrace ( ) ; // <SATD_START> TODO: handle exception <SATD_END> } }","@ Override public void initialize  ( ) throws OperatorException { try { GeographicCRS baseCRS = DefaultGeographicCRS . WGS84 ; final GeoCoding geoCoding = sourceProduct . getGeoCoding ( ) ; MathTransform baseToGridMathTransform = new GeoCodingMathTransform ( geoCoding , GeoCodingMathTransform . Mode . G2P ) ; CoordinateReferenceSystem gridCRS = new DefaultDerivedCRS ( "" The grid CRS "" , baseCRS , baseToGridMathTransform , DefaultCartesianCS . DISPLAY ) ; final GridCoverageFactory factory = CoverageFactoryFinder . getGridCoverageFactory ( null ) ; final Envelope2D sourceEnvelope = new Envelope2D ( gridCRS , 0 , 0 , sourceProduct . getSceneRasterWidth ( ) , sourceProduct . getSceneRasterHeight ( ) ) ; final CoordinateReferenceSystem targetCRS = createTargetCRS ( ) ; final GridGeometry2D gridGeometry = createGridGeometry ( sourceProduct , baseCRS , targetCRS ) ; Rectangle gridRect = gridGeometry . getGridRange2D ( ) ; final Interpolation interpolation = createInterpolation ( ) ; targetProduct = new Product ( "" projected_ "" + sourceProduct . getName ( ) , "" projection of:  "" + sourceProduct . getDescription ( ) , gridRect . width , gridRect . height ) ; // TODO: also query operatorContext rendering hints for tile size final Dimension tileSize = JAIUtils . computePreferredTileSize ( gridRect . width , gridRect . height , 1 ) ; targetProduct . setPreferredTileSize ( tileSize ) ; addMetadataToProduct ( targetProduct ) ; addFlagCodingsToProduct ( targetProduct ) ; addIndexCodingsToProduct ( targetProduct ) ; for ( Band sourceBand : sourceProduct . getBands ( ) ) { Band targetBand = targetProduct . addBand ( sourceBand . getName ( ) , sourceBand . getDataType ( ) ) ; ProductUtils . copyRasterDataNodeProperties ( sourceBand , targetBand ) ; GridCoverage2D sourceCoverage = createSourceCoverage ( factory , sourceEnvelope , sourceBand ) ; // only the tile size of the image layout is actually taken into account // by the rasample operation.   Use Operations.DEFAULT if tile size does // not matter final Operations operations = new Operations ( new Hints ( JAI . KEY_IMAGE_LAYOUT , createImageLayout ( targetBand , tileSize ) ) ) ; GridCoverage2D targetCoverage = ( GridCoverage2D ) operations . resample ( sourceCoverage , targetCRS , gridGeometry , interpolation ) ; RenderedImage targetImage = targetCoverage . getRenderedImage ( ) ; if ( targetImage . getTileHeight ( ) != targetProduct . getPreferredTileSize ( ) . getHeight ( ) ) { throw new OperatorException ( "" tileHeigth =  "" + targetImage . getTileHeight ( ) ) ; } if ( targetImage . getTileWidth ( ) != targetProduct . getPreferredTileSize ( ) . getWidth ( ) ) { throw new OperatorException ( "" tileWidth =  "" + targetImage . getTileWidth ( ) ) ; } targetBand . setSourceImage ( targetImage ) ; FlagCoding sourceFlagCoding = sourceBand . getFlagCoding ( ) ; IndexCoding sourceIndexCoding = sourceBand . getIndexCoding ( ) ; if ( sourceFlagCoding != null ) { String flagCodingName = sourceFlagCoding . getName ( ) ; FlagCoding destFlagCoding = targetProduct . getFlagCodingGroup ( ) . get ( flagCodingName ) ; targetBand . setSampleCoding ( destFlagCoding ) ; } else if ( sourceIndexCoding != null ) { String indexCodingName = sourceIndexCoding . getName ( ) ; IndexCoding destIndexCoding = targetProduct . getIndexCodingGroup ( ) . get ( indexCodingName ) ; targetBand . setSampleCoding ( destIndexCoding ) ; } } ProductUtils . copyBitmaskDefsAndOverlays ( sourceProduct , targetProduct ) ; copyPlacemarks ( sourceProduct . getPinGroup ( ) , targetProduct . getPinGroup ( ) , PlacemarkSymbol . createDefaultPinSymbol ( ) ) ; copyPlacemarks ( sourceProduct . getGcpGroup ( ) , targetProduct . getGcpGroup ( ) , PlacemarkSymbol . createDefaultGcpSymbol ( ) ) ; } catch ( OperatorException e ) { throw e ; } catch ( Throwable t ) { t . printStackTrace ( ) ; throw new OperatorException ( t . getMessage ( ) , t ) ; } }",2009-02-19 17:02:46 +0000,2009-02-24 13:17:50 +0000,0,0.8953716690042076
736,624,https://www.github.com/dana-i2cat/opennaas,"executeListCommand(ActionResponse, IProtocolSession)",,30,30,48,48,TODO Check params is in current candidate configuration and has tagged ethernet encapsulation,https://www.github.com/dana-i2cat/opennaas/commit/1b2cfae1a1,https://www.github.com/dana-i2cat/opennaas/commit/e38f427ada2ebf52e22d73c2a4c4ac2fda5d1c92,manticore/bundles/net.i2cat.mantychore.actionsets.junos/src/main/java/net/i2cat/mantychore/actionsets/junos/actions/chassis/RemoveTaggedEthernetEncapsulationAction.java,"@Override
public void executeListCommand(ActionResponse actionResponse, IProtocolSession protocol) throws ActionException {
// TODO Check params is in current candidate configuration and has tagged ethernet encapsulation
// TODO Check params does not have subinterfaces with configured vlan-id
EditNetconfCommand command = new EditNetconfCommand(getVelocityMessage(), CommandNetconfConstants.NONE_OPERATION);
command.initialize();
try {
actionResponse.addResponse(sendCommandToProtocol(command, protocol));
} catch (Exception e) {
throw new ActionException(this.actionID + "": "" + e.getMessage(), e);
}
validateAction(actionResponse);
}","@Override
public void executeListCommand(ActionResponse actionResponse, IProtocolSession protocol) throws ActionException {
try {
Response getInterfaceResponse = getInterfaceFromCandidate((LogicalPort) params, protocol);
actionResponse.addResponse(getInterfaceResponse);
if (getInterfaceResponse.getStatus().equals(Response.Status.OK)) {
// TODO Check params exists in the router.
// checkInterfaceExists("""", getInterfaceResponse);
// Check params has tagged ethernet encapsulation
if (interfaceHasTaggedEthernetEncapsulation((LogicalPort) params, getInterfaceResponse)) {
// Check params does not have subinterfaces with configured vlan-id
checkNoSubInterfaceWithVlanId((LogicalPort) params, getInterfaceResponse);
// remove eth encapsulation
EditNetconfCommand command = new EditNetconfCommand(getVelocityMessage(), CommandNetconfConstants.NONE_OPERATION);
command.initialize();
actionResponse.addResponse(sendCommandToProtocol(command, protocol));
}
}
validateAction(actionResponse);
} catch (Exception e) {
throw new ActionException(this.actionID + "": "" + e.getMessage(), e);
}
}","@ Override public void executeListCommand  ( ActionResponse actionResponse , IProtocolSession protocol ) throws ActionException { // <SATD_START> TODO Check params is in current candidate configuration and has tagged ethernet encapsulation <SATD_END> // TODO Check params does not have subinterfaces with configured vlan-id EditNetconfCommand command = new EditNetconfCommand ( getVelocityMessage ( ) , CommandNetconfConstants . NONE_OPERATION ) ; command . initialize ( ) ; try { actionResponse . addResponse ( sendCommandToProtocol ( command , protocol ) ) ; } catch ( Exception e ) { throw new ActionException ( this . actionID + "" :  "" + e . getMessage ( ) , e ) ; } validateAction ( actionResponse ) ; }","@ Override public void executeListCommand  ( ActionResponse actionResponse , IProtocolSession protocol ) throws ActionException { try { Response getInterfaceResponse = getInterfaceFromCandidate ( ( LogicalPort ) params , protocol ) ; actionResponse . addResponse ( getInterfaceResponse ) ; if ( getInterfaceResponse . getStatus ( ) . equals ( Response . Status . OK ) ) { // TODO Check params exists in the router. // checkInterfaceExists("""", getInterfaceResponse); // Check params has tagged ethernet encapsulation if ( interfaceHasTaggedEthernetEncapsulation ( ( LogicalPort ) params , getInterfaceResponse ) ) { // Check params does not have subinterfaces with configured vlan-id checkNoSubInterfaceWithVlanId ( ( LogicalPort ) params , getInterfaceResponse ) ; // remove eth encapsulation EditNetconfCommand command = new EditNetconfCommand ( getVelocityMessage ( ) , CommandNetconfConstants . NONE_OPERATION ) ; command . initialize ( ) ; actionResponse . addResponse ( sendCommandToProtocol ( command , protocol ) ) ; } } validateAction ( actionResponse ) ; } catch ( Exception e ) { throw new ActionException ( this . actionID + "" :  "" + e . getMessage ( ) , e ) ; } }",2012-03-23 09:16:45 +0100,2012-03-27 13:35:47 +0200,0,0.6001062134891131
1968,361,https://www.github.com/isa-tools/isacreator,"convertISAtab(BIIObjectStore, AllowedConversions, String, String)",DESIGN,237,237,237,237,todo show error panel to say it didn't convert....,https://www.github.com/isa-tools/isacreator/commit/74f4459da,https://www.github.com/isa-tools/isacreator/commit/8b8b26324a2249817ff4fa915a073413b7c6ce9a,src/main/java/org/isatools/isacreator/externalutils/convertvalidate/ValidateUI.java,"private void convertISAtab(BIIObjectStore store, AllowedConversions conversion,
                               String isatabLocation, String outputLocation) {
GUIISATABConverter converter = new GUIISATABConverter();
GUIInvokerResult result = converter.convert(store, isatabLocation, outputLocation, conversion);
if (result == GUIInvokerResult.SUCCESS) {
Box successContainer = Box.createVerticalBox();
successContainer.add(Box.createVerticalStrut(50));
successContainer.add(UIHelper.wrapComponentInPanel(new JLabel(conversionSuccess)));
successContainer.add(UIHelper.wrapComponentInPanel(UIHelper.createLabel(""<html>"" +
""<b>Conversion was a success.</b>"" +
""<p>Files stored in "" + outputLocation + ""</p>"" +
""</html>"", UIHelper.VER_11_PLAIN, UIHelper.DARK_GREEN_COLOR)));
swapContainers(successContainer);
} else {
String topMostError = """";
swapContainers(UIHelper.padComponentVerticalBox(100, UIHelper.createLabel(""<html>Conversion failed. Here is why:</html>"",
                    UIHelper.VER_11_PLAIN, UIHelper.DARK_GREEN_COLOR)));
// todo show error panel to say it didn't convert....
for (TabLoggingEventWrapper tlew : converter.getLog()) {
LoggingEvent le = tlew.getLogEvent();
System.out.println(le.getMessage());
}
}
}","private void convertISAtab(BIIObjectStore store, AllowedConversions conversion,
                               String isatabLocation, String outputLocation) {
GUIISATABConverter converter = new GUIISATABConverter();
GUIInvokerResult result = converter.convert(store, isatabLocation, outputLocation, conversion);
if (result == GUIInvokerResult.SUCCESS) {
Box successContainer = Box.createVerticalBox();
successContainer.add(Box.createVerticalStrut(50));
successContainer.add(UIHelper.wrapComponentInPanel(new JLabel(conversionSuccess)));
successContainer.add(UIHelper.wrapComponentInPanel(UIHelper.createLabel(""<html>"" +
""<b>Conversion was a success.</b>"" +
""<p>Files stored in "" + outputLocation + ""</p>"" +
""</html>"", UIHelper.VER_11_PLAIN, UIHelper.DARK_GREEN_COLOR)));
swapContainers(successContainer);
} else {
List<ErrorMessage> messages = new ArrayList<ErrorMessage>();
for (TabLoggingEventWrapper tlew : converter.getLog()) {
LoggingEvent le = tlew.getLogEvent();
if (le.getLevel() == Level.ERROR) {
messages.add(new ErrorMessage(ErrorLevel.ERROR, le.getMessage().toString()));
}
}
ConversionErrorUI errorContainer = new ConversionErrorUI();
errorContainer.constructErrorPane(messages);
errorContainer.setPreferredSize(new Dimension(750, 440));
swapContainers(errorContainer);
}
}","private void convertISAtab  ( BIIObjectStore store , AllowedConversions conversion , String isatabLocation , String outputLocation ) { GUIISATABConverter converter = new GUIISATABConverter ( ) ; GUIInvokerResult result = converter . convert ( store , isatabLocation , outputLocation , conversion ) ; if ( result == GUIInvokerResult . SUCCESS ) { Box successContainer = Box . createVerticalBox ( ) ; successContainer . add ( Box . createVerticalStrut ( 50 ) ) ; successContainer . add ( UIHelper . wrapComponentInPanel ( new JLabel ( conversionSuccess ) ) ) ; successContainer . add ( UIHelper . wrapComponentInPanel ( UIHelper . createLabel ( "" <html> "" + "" <b>Conversion was a success.</b> "" + "" <p>Files stored in  "" + outputLocation + "" </p> "" + "" </html> "" , UIHelper . VER_11_PLAIN , UIHelper . DARK_GREEN_COLOR ) ) ) ; swapContainers ( successContainer ) ; } else { String topMostError = "" "" ; swapContainers ( UIHelper . padComponentVerticalBox ( 100 , UIHelper . createLabel ( "" <html>Conversion failed. Here is why:</html> "" , UIHelper . VER_11_PLAIN , UIHelper . DARK_GREEN_COLOR ) ) ) ; // <SATD_START> todo show error panel to say it didn't convert.... <SATD_END> for ( TabLoggingEventWrapper tlew : converter . getLog ( ) ) { LoggingEvent le = tlew . getLogEvent ( ) ; System . out . println ( le . getMessage ( ) ) ; } } }","private void convertISAtab  ( BIIObjectStore store , AllowedConversions conversion , String isatabLocation , String outputLocation ) { GUIISATABConverter converter = new GUIISATABConverter ( ) ; GUIInvokerResult result = converter . convert ( store , isatabLocation , outputLocation , conversion ) ; if ( result == GUIInvokerResult . SUCCESS ) { Box successContainer = Box . createVerticalBox ( ) ; successContainer . add ( Box . createVerticalStrut ( 50 ) ) ; successContainer . add ( UIHelper . wrapComponentInPanel ( new JLabel ( conversionSuccess ) ) ) ; successContainer . add ( UIHelper . wrapComponentInPanel ( UIHelper . createLabel ( "" <html> "" + "" <b>Conversion was a success.</b> "" + "" <p>Files stored in  "" + outputLocation + "" </p> "" + "" </html> "" , UIHelper . VER_11_PLAIN , UIHelper . DARK_GREEN_COLOR ) ) ) ; swapContainers ( successContainer ) ; } else { List < ErrorMessage > messages = new ArrayList < ErrorMessage > ( ) ; for ( TabLoggingEventWrapper tlew : converter . getLog ( ) ) { LoggingEvent le = tlew . getLogEvent ( ) ; if ( le . getLevel ( ) == Level . ERROR ) { messages . add ( new ErrorMessage ( ErrorLevel . ERROR , le . getMessage ( ) . toString ( ) ) ) ; } } ConversionErrorUI errorContainer = new ConversionErrorUI ( ) ; errorContainer . constructErrorPane ( messages ) ; errorContainer . setPreferredSize ( new Dimension ( 750 , 440 ) ) ; swapContainers ( errorContainer ) ; } }",2011-09-08 18:57:20 +0100,2011-09-09 12:26:31 +0100,0,0.658669574700109
3786,59,https://www.github.com/apache/poi,drawContent(Graphics2D),,55,55,55,55,TODO: draw specific runtime exception?,https://www.github.com/apache/poi/commit/7afac11f67,https://www.github.com/apache/poi/commit/c6fa344c54b9d820596609d038754671aa4fa427,src/java/org/apache/poi/sl/draw/DrawPictureShape.java,"@Override
public void drawContent(Graphics2D graphics) {
PictureData data = getShape().getPictureData();
if(data == null) return;
Rectangle2D anchor = getAnchor(graphics, getShape());
Insets insets = getShape().getClipping();
try {
ImageRenderer renderer = getImageRenderer(graphics, data.getContentType());
renderer.loadImage(data.getData(), data.getContentType());
renderer.drawImage(graphics, anchor, insets);
} catch (IOException e) {
// TODO: draw specific runtime exception?
throw new RuntimeException(e);
}
}","@Override
public void drawContent(Graphics2D graphics) {
PictureData data = getShape().getPictureData();
if(data == null) return;
Rectangle2D anchor = getAnchor(graphics, getShape());
Insets insets = getShape().getClipping();
try {
ImageRenderer renderer = getImageRenderer(graphics, data.getContentType());
renderer.loadImage(data.getData(), data.getContentType());
renderer.drawImage(graphics, anchor, insets);
} catch (IOException e) {
LOG.log(POILogger.ERROR, ""image can't be loaded/rendered."", e);
}
}","@ Override public void drawContent  ( Graphics2D graphics ) { PictureData data = getShape ( ) . getPictureData ( ) ; if ( data == null ) return ; Rectangle2D anchor = getAnchor ( graphics , getShape ( ) ) ; Insets insets = getShape ( ) . getClipping ( ) ; try { ImageRenderer renderer = getImageRenderer ( graphics , data . getContentType ( ) ) ; renderer . loadImage ( data . getData ( ) , data . getContentType ( ) ) ; renderer . drawImage ( graphics , anchor , insets ) ; } catch ( IOException e ) { // <SATD_START> TODO: draw specific runtime exception? <SATD_END> throw new RuntimeException ( e ) ; } }","@ Override public void drawContent  ( Graphics2D graphics ) { PictureData data = getShape ( ) . getPictureData ( ) ; if ( data == null ) return ; Rectangle2D anchor = getAnchor ( graphics , getShape ( ) ) ; Insets insets = getShape ( ) . getClipping ( ) ; try { ImageRenderer renderer = getImageRenderer ( graphics , data . getContentType ( ) ) ; renderer . loadImage ( data . getData ( ) , data . getContentType ( ) ) ; renderer . drawImage ( graphics , anchor , insets ) ; } catch ( IOException e ) { LOG . log ( POILogger . ERROR , "" image can't be loaded/rendered. "" , e ) ; } }",2015-03-07 23:35:40 +0000,2016-02-24 22:43:51 +0000,0,0.864592094196804
3372,361,https://www.github.com/isa-tools/isacreator,createStudyAssaysSubForm(),DESIGN,207,207,207,207,"todo create a panel to display this in, or make it appear...",https://www.github.com/isa-tools/isacreator/commit/1a2f10bcb,https://www.github.com/isa-tools/isacreator/commit/eaa47b0b7ca3bf208cca5c49b5e807a5a3646b8e,src/main/java/org/isatools/isacreator/gui/StudyDataEntry.java,"private Container createStudyAssaysSubForm() {
Map<String, List<String>> measToAllowedTechnologies = getDataEntryEnvironment().getParentFrame().getAllowedTechnologiesPerEndpoint();
assayContainer = new JPanel(new FlowLayout(FlowLayout.LEFT));
assayContainer.setBackground(UIHelper.BG_COLOR);
for (Assay assay : study.getAssays().values()) {
assayContainer.add(new AssayInformationPanel(assay));
}
JScrollPane assayScroller = new JScrollPane(assayContainer,
                JScrollPane.VERTICAL_SCROLLBAR_NEVER, JScrollPane.HORIZONTAL_SCROLLBAR_AS_NEEDED);
IAppWidgetFactory.makeIAppScrollPane(assayScroller);
JPanel container = new JPanel(new BorderLayout());
container.setPreferredSize(new Dimension(300, 170));
container.setBorder(new TitledBorder(
                new RoundedBorder(UIHelper.LIGHT_GREEN_COLOR, 6), InvestigationFileSection.STUDY_ASSAYS.toString(),
                TitledBorder.DEFAULT_JUSTIFICATION,
                TitledBorder.CENTER,
                UIHelper.VER_12_BOLD, UIHelper.DARK_GREEN_COLOR));
final JLabel addRecord = new JLabel(""add new assay(s)"", addRecordIcon, JLabel.LEFT);
UIHelper.renderComponent(addRecord, UIHelper.VER_12_BOLD, UIHelper.DARK_GREEN_COLOR, false);
addRecord.addMouseListener(new MouseAdapter() {
            public void mousePressed(MouseEvent mouseEvent) {
// todo display the add assay panel
if (assaySelectionUI == null) {
// todo create a panel to display this in, or make it appear...
// assaySelectionUI = new AssaySelectionUI(measToAllowedTechnologies);
// assaySelectionUI.createGUI();
}
addRecord.setIcon(addRecordIcon);
}
public void mouseEntered(MouseEvent mouseEvent) {
addRecord.setIcon(addRecordIconOver);
}
public void mouseExited(MouseEvent mouseEvent) {
addRecord.setIcon(addRecordIcon);
}
        });
container.add(addRecord, BorderLayout.NORTH);
container.add(assayScroller, BorderLayout.CENTER);
return container;
}","private Container createStudyAssaysSubForm() {
assayContainer = new JPanel(new FlowLayout(FlowLayout.LEFT));
assayContainer.setBackground(UIHelper.BG_COLOR);
for (Assay assay : study.getAssays().values()) {
assayContainer.add(new AssayInformationPanel(assay));
}
JScrollPane assayScroller = new JScrollPane(assayContainer,
                JScrollPane.VERTICAL_SCROLLBAR_NEVER, JScrollPane.HORIZONTAL_SCROLLBAR_AS_NEEDED);
IAppWidgetFactory.makeIAppScrollPane(assayScroller);
JPanel container = new JPanel(new BorderLayout());
container.setPreferredSize(new Dimension(300, 170));
container.setBorder(new TitledBorder(
                new RoundedBorder(UIHelper.LIGHT_GREEN_COLOR, 6), InvestigationFileSection.STUDY_ASSAYS.toString(),
                TitledBorder.DEFAULT_JUSTIFICATION,
                TitledBorder.CENTER,
                UIHelper.VER_12_BOLD, UIHelper.DARK_GREEN_COLOR));
final JLabel addRecord = new JLabel(""add new assay(s)"", addRecordIcon, JLabel.LEFT);
UIHelper.renderComponent(addRecord, UIHelper.VER_12_BOLD, UIHelper.DARK_GREEN_COLOR, false);
addRecord.addMouseListener(new MouseAdapter() {
            public void mousePressed(MouseEvent mouseEvent) {
SwingUtilities.invokeLater(new Runnable() {
                    public void run() {
getDataEntryEnvironment().getParentFrame().showJDialogAsSheet(assaySelectionUI);
addRecord.setIcon(addRecordIcon);
}
                });
}
public void mouseEntered(MouseEvent mouseEvent) {
addRecord.setIcon(addRecordIconOver);
}
public void mouseExited(MouseEvent mouseEvent) {
addRecord.setIcon(addRecordIcon);
}
        });
container.add(addRecord, BorderLayout.NORTH);
container.add(assayScroller, BorderLayout.CENTER);
return container;
}","private Container createStudyAssaysSubForm  ( ) { Map < String , List < String > > measToAllowedTechnologies = getDataEntryEnvironment ( ) . getParentFrame ( ) . getAllowedTechnologiesPerEndpoint ( ) ; assayContainer = new JPanel ( new FlowLayout ( FlowLayout . LEFT ) ) ; assayContainer . setBackground ( UIHelper . BG_COLOR ) ; for ( Assay assay : study . getAssays ( ) . values ( ) ) { assayContainer . add ( new AssayInformationPanel ( assay ) ) ; } JScrollPane assayScroller = new JScrollPane ( assayContainer , JScrollPane . VERTICAL_SCROLLBAR_NEVER , JScrollPane . HORIZONTAL_SCROLLBAR_AS_NEEDED ) ; IAppWidgetFactory . makeIAppScrollPane ( assayScroller ) ; JPanel container = new JPanel ( new BorderLayout ( ) ) ; container . setPreferredSize ( new Dimension ( 300 , 170 ) ) ; container . setBorder ( new TitledBorder ( new RoundedBorder ( UIHelper . LIGHT_GREEN_COLOR , 6 ) , InvestigationFileSection . STUDY_ASSAYS . toString ( ) , TitledBorder . DEFAULT_JUSTIFICATION , TitledBorder . CENTER , UIHelper . VER_12_BOLD , UIHelper . DARK_GREEN_COLOR ) ) ; final JLabel addRecord = new JLabel ( "" add new assay(s) "" , addRecordIcon , JLabel . LEFT ) ; UIHelper . renderComponent ( addRecord , UIHelper . VER_12_BOLD , UIHelper . DARK_GREEN_COLOR , false ) ; addRecord . addMouseListener ( new MouseAdapter ( ) { public void mousePressed ( MouseEvent mouseEvent ) { // todo display the add assay panel if ( assaySelectionUI == null ) { // <SATD_START> todo create a panel to display this in, or make it appear... <SATD_END> // assaySelectionUI = new AssaySelectionUI(measToAllowedTechnologies); // assaySelectionUI.createGUI(); } addRecord . setIcon ( addRecordIcon ) ; } public void mouseEntered ( MouseEvent mouseEvent ) { addRecord . setIcon ( addRecordIconOver ) ; } public void mouseExited ( MouseEvent mouseEvent ) { addRecord . setIcon ( addRecordIcon ) ; } } ) ; container . add ( addRecord , BorderLayout . NORTH ) ; container . add ( assayScroller , BorderLayout . CENTER ) ; return container ; }","private Container createStudyAssaysSubForm  ( ) { assayContainer = new JPanel ( new FlowLayout ( FlowLayout . LEFT ) ) ; assayContainer . setBackground ( UIHelper . BG_COLOR ) ; for ( Assay assay : study . getAssays ( ) . values ( ) ) { assayContainer . add ( new AssayInformationPanel ( assay ) ) ; } JScrollPane assayScroller = new JScrollPane ( assayContainer , JScrollPane . VERTICAL_SCROLLBAR_NEVER , JScrollPane . HORIZONTAL_SCROLLBAR_AS_NEEDED ) ; IAppWidgetFactory . makeIAppScrollPane ( assayScroller ) ; JPanel container = new JPanel ( new BorderLayout ( ) ) ; container . setPreferredSize ( new Dimension ( 300 , 170 ) ) ; container . setBorder ( new TitledBorder ( new RoundedBorder ( UIHelper . LIGHT_GREEN_COLOR , 6 ) , InvestigationFileSection . STUDY_ASSAYS . toString ( ) , TitledBorder . DEFAULT_JUSTIFICATION , TitledBorder . CENTER , UIHelper . VER_12_BOLD , UIHelper . DARK_GREEN_COLOR ) ) ; final JLabel addRecord = new JLabel ( "" add new assay(s) "" , addRecordIcon , JLabel . LEFT ) ; UIHelper . renderComponent ( addRecord , UIHelper . VER_12_BOLD , UIHelper . DARK_GREEN_COLOR , false ) ; addRecord . addMouseListener ( new MouseAdapter ( ) { public void mousePressed ( MouseEvent mouseEvent ) { SwingUtilities . invokeLater ( new Runnable ( ) { public void run ( ) { getDataEntryEnvironment ( ) . getParentFrame ( ) . showJDialogAsSheet ( assaySelectionUI ) ; addRecord . setIcon ( addRecordIcon ) ; } } ) ; } public void mouseEntered ( MouseEvent mouseEvent ) { addRecord . setIcon ( addRecordIconOver ) ; } public void mouseExited ( MouseEvent mouseEvent ) { addRecord . setIcon ( addRecordIcon ) ; } } ) ; container . add ( addRecord , BorderLayout . NORTH ) ; container . add ( assayScroller , BorderLayout . CENTER ) ; return container ; }",2011-08-11 22:17:52 +0100,2011-08-12 11:48:23 +0100,0,0.8395453343906952
336,59,https://www.github.com/apache/poi,setCurrentRow(HSSFRow),,366,366,366,366,TODO - external functions,https://www.github.com/apache/poi/commit/478ec9eabf,https://www.github.com/apache/poi/commit/2ea7bc5eef9b7ec2ab26263e091f9cdb77aac699,src/java/org/apache/poi/hssf/usermodel/HSSFFormulaEvaluator.java,"private static ValueEval evaluateCell(HSSFWorkbook workbook, HSSFSheet sheet, 
            int srcRowNum, short srcColNum, String cellFormulaText) {
Ptg[] ptgs = FormulaParser.parse(cellFormulaText, workbook);
Stack stack = new Stack();
for (int i = 0, iSize = ptgs.length; i < iSize; i++) {
// since we don't know how to handle these yet :(
Ptg ptg = ptgs[i];
if (ptg instanceof ControlPtg) {
// skip Parentheses, Attr, etc
continue;
}
if (ptg instanceof MemErrPtg) { continue; }
if (ptg instanceof MissingArgPtg) { continue; }
if (ptg instanceof NamePtg) {
// named ranges, macro functions
NamePtg namePtg = (NamePtg) ptg;
stack.push(new NameEval(namePtg.getIndex()));
continue;
}
if (ptg instanceof NameXPtg) {
// TODO - external functions
continue;
}
if (ptg instanceof UnknownPtg) { continue; }
if (ptg instanceof OperationPtg) {
OperationPtg optg = (OperationPtg) ptg;
if (optg instanceof UnionPtg) { continue; }
OperationEval operation = OperationEvaluatorFactory.create(optg);
int numops = operation.getNumberOfOperands();
Eval[] ops = new Eval[numops];
// storing the ops in reverse order since they are popping
for (int j = numops - 1; j >= 0; j--) {
Eval p = (Eval) stack.pop();
ops[j] = p;
}
Eval opresult = invokeOperation(operation, ops, srcRowNum, srcColNum, workbook, sheet);
stack.push(opresult);
}
else if (ptg instanceof RefPtg) {
RefPtg refPtg = (RefPtg) ptg;
int colIx = refPtg.getColumn();
int rowIx = refPtg.getRow();
HSSFRow row = sheet.getRow(rowIx);
HSSFCell cell = (row != null) ? row.getCell(colIx) : null;
stack.push(createRef2DEval(refPtg, cell, sheet, workbook));
}
else if (ptg instanceof Ref3DPtg) {
Ref3DPtg refPtg = (Ref3DPtg) ptg;
int colIx = refPtg.getColumn();
int rowIx = refPtg.getRow();
Workbook wb = workbook.getWorkbook();
HSSFSheet xsheet = workbook.getSheetAt(wb.getSheetIndexFromExternSheetIndex(refPtg.getExternSheetIndex()));
HSSFRow row = xsheet.getRow(rowIx);
HSSFCell cell = (row != null) ? row.getCell(colIx) : null;
stack.push(createRef3DEval(refPtg, cell, xsheet, workbook));
}
else if (ptg instanceof AreaPtg) {
AreaPtg ap = (AreaPtg) ptg;
AreaEval ae = evaluateAreaPtg(sheet, workbook, ap);
stack.push(ae);
}
else if (ptg instanceof Area3DPtg) {
Area3DPtg a3dp = (Area3DPtg) ptg;
AreaEval ae = evaluateArea3dPtg(workbook, a3dp);
stack.push(ae);
}
else {
Eval ptgEval = getEvalForPtg(ptg);
stack.push(ptgEval);
}
}
ValueEval value = ((ValueEval) stack.pop());
if (!stack.isEmpty()) {
throw new IllegalStateException(""evaluation stack not empty"");
}
value = dereferenceValue(value, srcRowNum, srcColNum);
if (value instanceof BlankEval) {
// Note Excel behaviour here. A blank final final value is converted to zero.  
return NumberEval.ZERO;
// Formulas _never_ evaluate to blank.  If a formula appears to have evaluated to 
// blank, the actual value is empty string. This can be verified with ISBLANK().
}
return value;
}","private static ValueEval evaluateCell(HSSFWorkbook workbook, HSSFSheet sheet,
            int srcRowNum, short srcColNum, String cellFormulaText) {
Ptg[] ptgs = FormulaParser.parse(cellFormulaText, workbook);
Stack stack = new Stack();
for (int i = 0, iSize = ptgs.length; i < iSize; i++) {
// since we don't know how to handle these yet :(
Ptg ptg = ptgs[i];
if (ptg instanceof ControlPtg) {
// skip Parentheses, Attr, etc
continue;
}
if (ptg instanceof MemErrPtg) { continue; }
if (ptg instanceof MissingArgPtg) { continue; }
if (ptg instanceof NamePtg) {
// named ranges, macro functions
NamePtg namePtg = (NamePtg) ptg;
stack.push(new NameEval(namePtg.getIndex()));
continue;
}
if (ptg instanceof NameXPtg) {
NameXPtg nameXPtg = (NameXPtg) ptg;
stack.push(new NameXEval(nameXPtg.getSheetRefIndex(), nameXPtg.getNameIndex()));
continue;
}
if (ptg instanceof UnknownPtg) { continue; }
if (ptg instanceof OperationPtg) {
OperationPtg optg = (OperationPtg) ptg;
if (optg instanceof UnionPtg) { continue; }
OperationEval operation = OperationEvaluatorFactory.create(optg);
int numops = operation.getNumberOfOperands();
Eval[] ops = new Eval[numops];
// storing the ops in reverse order since they are popping
for (int j = numops - 1; j >= 0; j--) {
Eval p = (Eval) stack.pop();
ops[j] = p;
}
Eval opresult = invokeOperation(operation, ops, srcRowNum, srcColNum, workbook, sheet);
stack.push(opresult);
}
else if (ptg instanceof RefPtg) {
RefPtg refPtg = (RefPtg) ptg;
int colIx = refPtg.getColumn();
int rowIx = refPtg.getRow();
HSSFRow row = sheet.getRow(rowIx);
HSSFCell cell = (row != null) ? row.getCell(colIx) : null;
stack.push(createRef2DEval(refPtg, cell, sheet, workbook));
}
else if (ptg instanceof Ref3DPtg) {
Ref3DPtg refPtg = (Ref3DPtg) ptg;
int colIx = refPtg.getColumn();
int rowIx = refPtg.getRow();
Workbook wb = workbook.getWorkbook();
HSSFSheet xsheet = workbook.getSheetAt(wb.getSheetIndexFromExternSheetIndex(refPtg.getExternSheetIndex()));
HSSFRow row = xsheet.getRow(rowIx);
HSSFCell cell = (row != null) ? row.getCell(colIx) : null;
stack.push(createRef3DEval(refPtg, cell, xsheet, workbook));
}
else if (ptg instanceof AreaPtg) {
AreaPtg ap = (AreaPtg) ptg;
AreaEval ae = evaluateAreaPtg(sheet, workbook, ap);
stack.push(ae);
}
else if (ptg instanceof Area3DPtg) {
Area3DPtg a3dp = (Area3DPtg) ptg;
AreaEval ae = evaluateArea3dPtg(workbook, a3dp);
stack.push(ae);
}
else {
Eval ptgEval = getEvalForPtg(ptg);
stack.push(ptgEval);
}
}
ValueEval value = ((ValueEval) stack.pop());
if (!stack.isEmpty()) {
throw new IllegalStateException(""evaluation stack not empty"");
}
value = dereferenceValue(value, srcRowNum, srcColNum);
if (value instanceof BlankEval) {
// Note Excel behaviour here. A blank final final value is converted to zero.
return NumberEval.ZERO;
// Formulas _never_ evaluate to blank.  If a formula appears to have evaluated to
// blank, the actual value is empty string. This can be verified with ISBLANK().
}
return value;
}","private static ValueEval evaluateCell  ( HSSFWorkbook workbook , HSSFSheet sheet , int srcRowNum , short srcColNum , String cellFormulaText ) { Ptg [ ] ptgs = FormulaParser . parse ( cellFormulaText , workbook ) ; Stack stack = new Stack ( ) ; for ( int i = 0 , iSize = ptgs . length ; i < iSize ; i ++ ) { // since we don't know how to handle these yet :( Ptg ptg = ptgs [ i ] ; if ( ptg instanceof ControlPtg ) { // skip Parentheses, Attr, etc continue ; } if ( ptg instanceof MemErrPtg ) { continue ; } if ( ptg instanceof MissingArgPtg ) { continue ; } if ( ptg instanceof NamePtg ) { // named ranges, macro functions NamePtg namePtg = ( NamePtg ) ptg ; stack . push ( new NameEval ( namePtg . getIndex ( ) ) ) ; continue ; } if ( ptg instanceof NameXPtg ) { // <SATD_START> TODO - external functions <SATD_END> continue ; } if ( ptg instanceof UnknownPtg ) { continue ; } if ( ptg instanceof OperationPtg ) { OperationPtg optg = ( OperationPtg ) ptg ; if ( optg instanceof UnionPtg ) { continue ; } OperationEval operation = OperationEvaluatorFactory . create ( optg ) ; int numops = operation . getNumberOfOperands ( ) ; Eval [ ] ops = new Eval [ numops ] ; // storing the ops in reverse order since they are popping for ( int j = numops - 1 ; j >= 0 ; j -- ) { Eval p = ( Eval ) stack . pop ( ) ; ops [ j ] = p ; } Eval opresult = invokeOperation ( operation , ops , srcRowNum , srcColNum , workbook , sheet ) ; stack . push ( opresult ) ; } else if ( ptg instanceof RefPtg ) { RefPtg refPtg = ( RefPtg ) ptg ; int colIx = refPtg . getColumn ( ) ; int rowIx = refPtg . getRow ( ) ; HSSFRow row = sheet . getRow ( rowIx ) ; HSSFCell cell = ( row != null ) ? row . getCell ( colIx ) : null ; stack . push ( createRef2DEval ( refPtg , cell , sheet , workbook ) ) ; } else if ( ptg instanceof Ref3DPtg ) { Ref3DPtg refPtg = ( Ref3DPtg ) ptg ; int colIx = refPtg . getColumn ( ) ; int rowIx = refPtg . getRow ( ) ; Workbook wb = workbook . getWorkbook ( ) ; HSSFSheet xsheet = workbook . getSheetAt ( wb . getSheetIndexFromExternSheetIndex ( refPtg . getExternSheetIndex ( ) ) ) ; HSSFRow row = xsheet . getRow ( rowIx ) ; HSSFCell cell = ( row != null ) ? row . getCell ( colIx ) : null ; stack . push ( createRef3DEval ( refPtg , cell , xsheet , workbook ) ) ; } else if ( ptg instanceof AreaPtg ) { AreaPtg ap = ( AreaPtg ) ptg ; AreaEval ae = evaluateAreaPtg ( sheet , workbook , ap ) ; stack . push ( ae ) ; } else if ( ptg instanceof Area3DPtg ) { Area3DPtg a3dp = ( Area3DPtg ) ptg ; AreaEval ae = evaluateArea3dPtg ( workbook , a3dp ) ; stack . push ( ae ) ; } else { Eval ptgEval = getEvalForPtg ( ptg ) ; stack . push ( ptgEval ) ; } } ValueEval value = ( ( ValueEval ) stack . pop ( ) ) ; if ( ! stack . isEmpty ( ) ) { throw new IllegalStateException ( "" evaluation stack not empty "" ) ; } value = dereferenceValue ( value , srcRowNum , srcColNum ) ; if ( value instanceof BlankEval ) { // Note Excel behaviour here. A blank final final value is converted to zero.   return NumberEval . ZERO ; // Formulas _never_ evaluate to blank.  If a formula appears to have evaluated to  // blank, the actual value is empty string. This can be verified with ISBLANK(). } return value ; }","private static ValueEval evaluateCell  ( HSSFWorkbook workbook , HSSFSheet sheet , int srcRowNum , short srcColNum , String cellFormulaText ) { Ptg [ ] ptgs = FormulaParser . parse ( cellFormulaText , workbook ) ; Stack stack = new Stack ( ) ; for ( int i = 0 , iSize = ptgs . length ; i < iSize ; i ++ ) { // since we don't know how to handle these yet :( Ptg ptg = ptgs [ i ] ; if ( ptg instanceof ControlPtg ) { // skip Parentheses, Attr, etc continue ; } if ( ptg instanceof MemErrPtg ) { continue ; } if ( ptg instanceof MissingArgPtg ) { continue ; } if ( ptg instanceof NamePtg ) { // named ranges, macro functions NamePtg namePtg = ( NamePtg ) ptg ; stack . push ( new NameEval ( namePtg . getIndex ( ) ) ) ; continue ; } if ( ptg instanceof NameXPtg ) { NameXPtg nameXPtg = ( NameXPtg ) ptg ; stack . push ( new NameXEval ( nameXPtg . getSheetRefIndex ( ) , nameXPtg . getNameIndex ( ) ) ) ; continue ; } if ( ptg instanceof UnknownPtg ) { continue ; } if ( ptg instanceof OperationPtg ) { OperationPtg optg = ( OperationPtg ) ptg ; if ( optg instanceof UnionPtg ) { continue ; } OperationEval operation = OperationEvaluatorFactory . create ( optg ) ; int numops = operation . getNumberOfOperands ( ) ; Eval [ ] ops = new Eval [ numops ] ; // storing the ops in reverse order since they are popping for ( int j = numops - 1 ; j >= 0 ; j -- ) { Eval p = ( Eval ) stack . pop ( ) ; ops [ j ] = p ; } Eval opresult = invokeOperation ( operation , ops , srcRowNum , srcColNum , workbook , sheet ) ; stack . push ( opresult ) ; } else if ( ptg instanceof RefPtg ) { RefPtg refPtg = ( RefPtg ) ptg ; int colIx = refPtg . getColumn ( ) ; int rowIx = refPtg . getRow ( ) ; HSSFRow row = sheet . getRow ( rowIx ) ; HSSFCell cell = ( row != null ) ? row . getCell ( colIx ) : null ; stack . push ( createRef2DEval ( refPtg , cell , sheet , workbook ) ) ; } else if ( ptg instanceof Ref3DPtg ) { Ref3DPtg refPtg = ( Ref3DPtg ) ptg ; int colIx = refPtg . getColumn ( ) ; int rowIx = refPtg . getRow ( ) ; Workbook wb = workbook . getWorkbook ( ) ; HSSFSheet xsheet = workbook . getSheetAt ( wb . getSheetIndexFromExternSheetIndex ( refPtg . getExternSheetIndex ( ) ) ) ; HSSFRow row = xsheet . getRow ( rowIx ) ; HSSFCell cell = ( row != null ) ? row . getCell ( colIx ) : null ; stack . push ( createRef3DEval ( refPtg , cell , xsheet , workbook ) ) ; } else if ( ptg instanceof AreaPtg ) { AreaPtg ap = ( AreaPtg ) ptg ; AreaEval ae = evaluateAreaPtg ( sheet , workbook , ap ) ; stack . push ( ae ) ; } else if ( ptg instanceof Area3DPtg ) { Area3DPtg a3dp = ( Area3DPtg ) ptg ; AreaEval ae = evaluateArea3dPtg ( workbook , a3dp ) ; stack . push ( ae ) ; } else { Eval ptgEval = getEvalForPtg ( ptg ) ; stack . push ( ptgEval ) ; } } ValueEval value = ( ( ValueEval ) stack . pop ( ) ) ; if ( ! stack . isEmpty ( ) ) { throw new IllegalStateException ( "" evaluation stack not empty "" ) ; } value = dereferenceValue ( value , srcRowNum , srcColNum ) ; if ( value instanceof BlankEval ) { // Note Excel behaviour here. A blank final final value is converted to zero. return NumberEval . ZERO ; // Formulas _never_ evaluate to blank.  If a formula appears to have evaluated to // blank, the actual value is empty string. This can be verified with ISBLANK(). } return value ; }",2008-05-27 00:57:23 +0000,2008-08-25 08:09:02 +0000,0,0.9718353450943981
747,736,https://www.github.com/chocoteam/choco-solver,main(String[]),,73,73,73,73,ConstraintFactory TODO Lex,https://www.github.com/chocoteam/choco-solver/commit/8a6dbf49ad,https://www.github.com/chocoteam/choco-solver/commit/134e8a5cdcb15b1efdc0a3fc275f88331818716d,solver/src/main/java/samples/Dobble.java,"public static void main(String[] args) {
int nbSymbCarte=3;
int nbCarte=4;
int nbSymbTotal=6;
Solver solver = new Solver();
IntVar[][] jeu = new IntVar[nbCarte][];
for(int i=0;i<nbCarte;i++) {
jeu[i] = VariableFactory.enumeratedArray(""Carte_""+i, nbSymbCarte, 1, nbSymbTotal, solver);
}
for(int i=0;i<nbCarte;i++) {
for(int j=0;j<nbSymbCarte;j++) {//pour tout couple de carte :
System.out.println(jeu[i][j]);
}
System.out.println();
}
for(int i=0;i<nbCarte;i++) {
solver.post(new AllDifferent(jeu[i], solver,AllDifferent.Type.AC));//chaque carte a des symboles distinctes
for(int j=0; j<nbSymbCarte-1;j++){
solver.post(ConstraintFactory.lt(jeu[i][j], jeu[i][j + 1], solver));
//ConstraintFactory TODO Lex
}
for(int j=i+1;j<nbCarte;j++) {//pour tout couple de carte :
IntVar nbNValues = VariableFactory.enumerated(""nbEnCommun"", nbSymbCarte * 2 - 1, nbSymbCarte * 2 - 1, solver);//au total de 2 cartes, il doit y avoir 2n - 1 valeurs, car 1 est en commun, et une seule.
System.out.println(nbNValues);
IntVar[] regroup = ArrayUtils.append(jeu[i], jeu[j]);
for(int k=0;k<regroup.length;k++)
System.out.println(regroup[k]);
System.out.println(regroup.length);
solver.post(new NValues(regroup, nbNValues, solver));
}
}
//solver.set(StrategyFactory.minDomMinVal(vars, solver.getEnvironment()));
solver.set(StrategyFactory.inputOrderMinVal(ArrayUtils.flatten(jeu),solver.getEnvironment()));
SearchMonitorFactory.log(solver, true, false);
solver.getSearchLoop().getLimitsBox().setTimeLimit(600*1000);
solver.findSolution();
}","public static void main(String[] args) {
int nbSymbCarte=5;
int nbCarte=21;
int nbSymbTotal=21;
Solver solver = new Solver();
IntVar[][] jeu = new IntVar[nbCarte][];
IntVar nValTotal = VariableFactory.bounded(""total"",0,nbSymbTotal,solver);
for(int i=0;i<nbCarte;i++) {
jeu[i] = VariableFactory.enumeratedArray(""Carte_""+i, nbSymbCarte, 1, nbSymbTotal, solver);
}
IntVar nbNValues = VariableFactory.enumerated(""nbEnCommun"", nbSymbCarte * 2 - 1, nbSymbCarte * 2 - 1, solver);
for(int i=0;i<nbCarte;i++) {
solver.post(new AllDifferent(jeu[i], solver,AllDifferent.Type.AC));//chaque carte a des symboles distinctes
for(int j=0; j<nbSymbCarte-1;j++){
solver.post(ConstraintFactory.lt(jeu[i][j], jeu[i][j + 1], solver));
}
for(int j=i+1;j<nbCarte;j++) {//pour tout couple de carte :
//au total de 2 cartes, il doit y avoir 2n - 1 valeurs, car 1 est en commun, et une seule.
solver.post(new NValues(ArrayUtils.append(jeu[i], jeu[j]), nbNValues, solver));
}
}
for(int i=0;i<nbCarte-1;i++) {
solver.post(ConstraintFactory.leq(jeu[i][0], jeu[i + 1][0], solver));
}
solver.post(new NValues(ArrayUtils.flatten(jeu),nValTotal,solver));
// TODO conjonction differences par carte / nvalue => passer par des graphes!!!
//		solver.set(StrategyFactory.minDomMinVal(ArrayUtils.flatten(jeu), solver.getEnvironment()));
solver.set(StrategyFactory.inputOrderMinVal(ArrayUtils.flatten(jeu),solver.getEnvironment()));
SearchMonitorFactory.log(solver, true, false);
solver.getSearchLoop().getLimitsBox().setTimeLimit(600*1000);
solver.findSolution();
}","public static void main  ( String [ ] args ) { int nbSymbCarte = 3 ; int nbCarte = 4 ; int nbSymbTotal = 6 ; Solver solver = new Solver ( ) ; IntVar [ ] [ ] jeu = new IntVar [ nbCarte ] [ ] ; for ( int i = 0 ; i < nbCarte ; i ++ ) { jeu [ i ] = VariableFactory . enumeratedArray ( "" Carte_ "" + i , nbSymbCarte , 1 , nbSymbTotal , solver ) ; } for ( int i = 0 ; i < nbCarte ; i ++ ) { for ( int j = 0 ; j < nbSymbCarte ; j ++ ) { //pour tout couple de carte : System . out . println ( jeu [ i ] [ j ] ) ; } System . out . println ( ) ; } for ( int i = 0 ; i < nbCarte ; i ++ ) { solver . post ( new AllDifferent ( jeu [ i ] , solver , AllDifferent . Type . AC ) ) ; //chaque carte a des symboles distinctes for ( int j = 0 ; j < nbSymbCarte - 1 ; j ++ ) { solver . post ( ConstraintFactory . lt ( jeu [ i ] [ j ] , jeu [ i ] [ j + 1 ] , solver ) ) ; //<SATD_START> ConstraintFactory TODO Lex <SATD_END> } for ( int j = i + 1 ; j < nbCarte ; j ++ ) { //pour tout couple de carte : IntVar nbNValues = VariableFactory . enumerated ( "" nbEnCommun "" , nbSymbCarte * 2 - 1 , nbSymbCarte * 2 - 1 , solver ) ; //au total de 2 cartes, il doit y avoir 2n - 1 valeurs, car 1 est en commun, et une seule. System . out . println ( nbNValues ) ; IntVar [ ] regroup = ArrayUtils . append ( jeu [ i ] , jeu [ j ] ) ; for ( int k = 0 ; k < regroup . length ; k ++ ) System . out . println ( regroup [ k ] ) ; System . out . println ( regroup . length ) ; solver . post ( new NValues ( regroup , nbNValues , solver ) ) ; } } //solver.set(StrategyFactory.minDomMinVal(vars, solver.getEnvironment())); solver . set ( StrategyFactory . inputOrderMinVal ( ArrayUtils . flatten ( jeu ) , solver . getEnvironment ( ) ) ) ; SearchMonitorFactory . log ( solver , true , false ) ; solver . getSearchLoop ( ) . getLimitsBox ( ) . setTimeLimit ( 600 * 1000 ) ; solver . findSolution ( ) ; }","public static void main  ( String [ ] args ) { int nbSymbCarte = 5 ; int nbCarte = 21 ; int nbSymbTotal = 21 ; Solver solver = new Solver ( ) ; IntVar [ ] [ ] jeu = new IntVar [ nbCarte ] [ ] ; IntVar nValTotal = VariableFactory . bounded ( "" total "" , 0 , nbSymbTotal , solver ) ; for ( int i = 0 ; i < nbCarte ; i ++ ) { jeu [ i ] = VariableFactory . enumeratedArray ( "" Carte_ "" + i , nbSymbCarte , 1 , nbSymbTotal , solver ) ; } IntVar nbNValues = VariableFactory . enumerated ( "" nbEnCommun "" , nbSymbCarte * 2 - 1 , nbSymbCarte * 2 - 1 , solver ) ; for ( int i = 0 ; i < nbCarte ; i ++ ) { solver . post ( new AllDifferent ( jeu [ i ] , solver , AllDifferent . Type . AC ) ) ; //chaque carte a des symboles distinctes for ( int j = 0 ; j < nbSymbCarte - 1 ; j ++ ) { solver . post ( ConstraintFactory . lt ( jeu [ i ] [ j ] , jeu [ i ] [ j + 1 ] , solver ) ) ; } for ( int j = i + 1 ; j < nbCarte ; j ++ ) { //pour tout couple de carte : //au total de 2 cartes, il doit y avoir 2n - 1 valeurs, car 1 est en commun, et une seule. solver . post ( new NValues ( ArrayUtils . append ( jeu [ i ] , jeu [ j ] ) , nbNValues , solver ) ) ; } } for ( int i = 0 ; i < nbCarte - 1 ; i ++ ) { solver . post ( ConstraintFactory . leq ( jeu [ i ] [ 0 ] , jeu [ i + 1 ] [ 0 ] , solver ) ) ; } solver . post ( new NValues ( ArrayUtils . flatten ( jeu ) , nValTotal , solver ) ) ; // TODO conjonction differences par carte / nvalue => passer par des graphes!!! //		solver.set(StrategyFactory.minDomMinVal(ArrayUtils.flatten(jeu), solver.getEnvironment())); solver . set ( StrategyFactory . inputOrderMinVal ( ArrayUtils . flatten ( jeu ) , solver . getEnvironment ( ) ) ) ; SearchMonitorFactory . log ( solver , true , false ) ; solver . getSearchLoop ( ) . getLimitsBox ( ) . setTimeLimit ( 600 * 1000 ) ; solver . findSolution ( ) ; }",2012-11-14 16:49:43 +0100,2012-11-15 12:57:48 +0100,0,0.4841248303934871
3430,196,https://www.github.com/ruboto/ruboto-irb,onCreate(),DESIGN,29,29,29,29,FIXME(uwe):  What to do if the Ruboto Core platform cannot be found?,https://www.github.com/ruboto/ruboto-irb/commit/28b8d8d5,https://www.github.com/ruboto/ruboto-irb/commit/1250046a55445526e716e35d4001e1f275b6d9a2,src/org/ruboto/RubotoService.java,"@Override
public void onCreate() {
if (ScriptLoader.isCalledFromJRuby()) {
super.onCreate();
return;
}
System.out.println(""RubotoService.onCreate()"");
if (JRubyAdapter.setUpJRuby(this)) {
ScriptLoader.loadScript(this);
} else {
// FIXME(uwe):  What to do if the Ruboto Core platform cannot be found?
}
}","@Override
public void onCreate() {
System.out.println(""RubotoService onCreate(): "" + getClass().getName());
if (ScriptLoader.isCalledFromJRuby()) {
super.onCreate();
return;
}
if (JRubyAdapter.isInitialized() && scriptInfo.isReadyToLoad()) {
ScriptLoader.loadScript(this);
} else {
super.onCreate();
}
}","@ Override public void onCreate  ( ) { if ( ScriptLoader . isCalledFromJRuby ( ) ) { super . onCreate ( ) ; return ; } System . out . println ( "" RubotoService.onCreate() "" ) ; if ( JRubyAdapter . setUpJRuby ( this ) ) { ScriptLoader . loadScript ( this ) ; } else { // <SATD_START> FIXME(uwe):  What to do if the Ruboto Core platform cannot be found? <SATD_END> } }","@ Override public void onCreate  ( ) { System . out . println ( "" RubotoService onCreate():  "" + getClass ( ) . getName ( ) ) ; if ( ScriptLoader . isCalledFromJRuby ( ) ) { super . onCreate ( ) ; return ; } if ( JRubyAdapter . isInitialized ( ) && scriptInfo . isReadyToLoad ( ) ) { ScriptLoader . loadScript ( this ) ; } else { super . onCreate ( ) ; } }",2012-08-16 00:19:07 +0200,2012/12/8 15:19,0,0.4487534626038781
328,492,https://www.github.com/sonatype/nexus,initializeTasks(Scheduler),,126,126,126,126,FIXME simple name hack,https://www.github.com/sonatype/nexus/commit/20174afe005,https://www.github.com/sonatype/nexus/commit/3a4c15a2043007a8fe65354a1f90fe1848324b7c,nexus/nexus-configuration/src/main/java/org/sonatype/scheduling/DefaultTaskConfigManager.java,"public void initializeTasks( Scheduler scheduler )
{
List<CScheduledTask> tasks = new ArrayList<CScheduledTask>( applicationConfiguration
.getConfiguration().getTasks() );
if ( tasks != null )
{
List<CScheduledTask> tempList = new ArrayList<CScheduledTask>( tasks );
getLogger().info( tempList.size() + "" task(s) to load."" );
for ( CScheduledTask task : tempList )
{
getLogger().info( ""Loading task - "" + task.getName() );
try
                {
SchedulerTask<?> nexusTask = (SchedulerTask<?>) plexusContainer.lookup( SchedulerTask.ROLE, task
.getType() );
for ( Iterator iter = task.getProperties().iterator(); iter.hasNext(); )
{
CProps prop = (CProps) iter.next();
nexusTask.addParameter( prop.getKey(), prop.getValue() );
}
scheduler.initialize(
                        task.getId(),
                        task.getName(),
                        nexusTask.getClass().getSimpleName(), //FIXME simple name hack
nexusTask,
                        translateFrom( task.getSchedule(), task.getNextRun() ),
                        translateFrom( task.getProperties() ) ).setEnabled( task.isEnabled() );
}
catch ( ComponentLookupException e )
{
// this is bad, Plexus did not find the component, possibly the task.getType() contains bad class
// name
getLogger()
.error(
                            ""Unable to initialize task "" + task.getName() + "", couldn't load service class ""
+ task.getId() );
}
}
}
}","public void initializeTasks( Scheduler scheduler )
{
List<CScheduledTask> tasks = new ArrayList<CScheduledTask>( applicationConfiguration
.getConfiguration().getTasks() );
if ( tasks != null )
{
List<CScheduledTask> tempList = new ArrayList<CScheduledTask>( tasks );
getLogger().info( tempList.size() + "" task(s) to load."" );
for ( CScheduledTask task : tempList )
{
getLogger().info( ""Loading task - "" + task.getName() );
try
                {
SchedulerTask<?> nexusTask = (SchedulerTask<?>) plexusContainer.lookup( SchedulerTask.ROLE, task
.getType() );
for ( Iterator iter = task.getProperties().iterator(); iter.hasNext(); )
{
CProps prop = (CProps) iter.next();
nexusTask.addParameter( prop.getKey(), prop.getValue() );
}
scheduler.initialize(
                        task.getId(),
                        task.getName(),
                        task.getType(),
                        nexusTask,
                        translateFrom( task.getSchedule(), task.getNextRun() ),
                        translateFrom( task.getProperties() ) ).setEnabled( task.isEnabled() );
}
catch ( ComponentLookupException e )
{
// this is bad, Plexus did not find the component, possibly the task.getType() contains bad class
// name
getLogger()
.error(
                            ""Unable to initialize task "" + task.getName() + "", couldn't load service class ""
+ task.getId() );
}
}
}
}","public void initializeTasks  ( Scheduler scheduler ) { List < CScheduledTask > tasks = new ArrayList < CScheduledTask > ( applicationConfiguration . getConfiguration ( ) . getTasks ( ) ) ; if ( tasks != null ) { List < CScheduledTask > tempList = new ArrayList < CScheduledTask > ( tasks ) ; getLogger ( ) . info ( tempList . size ( ) + ""  task(s) to load. "" ) ; for ( CScheduledTask task : tempList ) { getLogger ( ) . info ( "" Loading task -  "" + task . getName ( ) ) ; try { SchedulerTask < ? > nexusTask = ( SchedulerTask < ? > ) plexusContainer . lookup ( SchedulerTask . ROLE , task . getType ( ) ) ; for ( Iterator iter = task . getProperties ( ) . iterator ( ) ; iter . hasNext ( ) ; ) { CProps prop = ( CProps ) iter . next ( ) ; nexusTask . addParameter ( prop . getKey ( ) , prop . getValue ( ) ) ; } scheduler . initialize ( task . getId ( ) , task . getName ( ) , nexusTask . getClass ( ) . getSimpleName ( ) , //<SATD_START> FIXME simple name hack <SATD_END> nexusTask , translateFrom ( task . getSchedule ( ) , task . getNextRun ( ) ) , translateFrom ( task . getProperties ( ) ) ) . setEnabled ( task . isEnabled ( ) ) ; } catch ( ComponentLookupException e ) { // this is bad, Plexus did not find the component, possibly the task.getType() contains bad class // name getLogger ( ) . error ( "" Unable to initialize task  "" + task . getName ( ) + "" , couldn't load service class  "" + task . getId ( ) ) ; } } } }","public void initializeTasks  ( Scheduler scheduler ) { List < CScheduledTask > tasks = new ArrayList < CScheduledTask > ( applicationConfiguration . getConfiguration ( ) . getTasks ( ) ) ; if ( tasks != null ) { List < CScheduledTask > tempList = new ArrayList < CScheduledTask > ( tasks ) ; getLogger ( ) . info ( tempList . size ( ) + ""  task(s) to load. "" ) ; for ( CScheduledTask task : tempList ) { getLogger ( ) . info ( "" Loading task -  "" + task . getName ( ) ) ; try { SchedulerTask < ? > nexusTask = ( SchedulerTask < ? > ) plexusContainer . lookup ( SchedulerTask . ROLE , task . getType ( ) ) ; for ( Iterator iter = task . getProperties ( ) . iterator ( ) ; iter . hasNext ( ) ; ) { CProps prop = ( CProps ) iter . next ( ) ; nexusTask . addParameter ( prop . getKey ( ) , prop . getValue ( ) ) ; } scheduler . initialize ( task . getId ( ) , task . getName ( ) , task . getType ( ) , nexusTask , translateFrom ( task . getSchedule ( ) , task . getNextRun ( ) ) , translateFrom ( task . getProperties ( ) ) ) . setEnabled ( task . isEnabled ( ) ) ; } catch ( ComponentLookupException e ) { // this is bad, Plexus did not find the component, possibly the task.getType() contains bad class // name getLogger ( ) . error ( "" Unable to initialize task  "" + task . getName ( ) + "" , couldn't load service class  "" + task . getId ( ) ) ; } } } }",2008-09-17 21:34:08 +0000,2008-09-18 14:35:25 +0000,0,0.6765023389708529
324,13,https://www.github.com/aosp-mirror/platform_packages_apps_settings,onCreate(Bundle),,115,115,115,115,TODO: Factor out spinner creation in a method in Utils class. See: http://b/16645615,https://www.github.com/aosp-mirror/platform_packages_apps_settings/commit/a6145a656af1,https://www.github.com/aosp-mirror/platform_packages_apps_settings/commit/80e1f1bfdb814a08fb8b07b2e279285d495042e9,src/com/android/settings/notification/AppNotificationSettings.java,"@Override
public void onViewCreated(View view, Bundle savedInstanceState) {
super.onViewCreated(view, savedInstanceState);
final UserManager um = (UserManager) getActivity().getSystemService(Context.USER_SERVICE);
List<UserHandle> userProfiles = um.getUserProfiles();
if (userProfiles.size() >= 2) {
Spinner spinner = (Spinner) getActivity().getLayoutInflater().inflate(
                    R.layout.spinner_view, null);
// TODO: Factor out spinner creation in a method in Utils class. See: http://b/16645615
UserHandle myUserHandle = new UserHandle(UserHandle.myUserId());
userProfiles.remove(myUserHandle);
userProfiles.add(0, myUserHandle);
ArrayList<UserDetails> userDetails = new ArrayList<UserDetails>(userProfiles.size());
final int count = userProfiles.size();
for (int i = 0; i < count; i++) {
userDetails.add(new UserDetails(userProfiles.get(i), um, mContext));
}
mProfileSpinnerAdapter = new UserSpinnerAdapter(mContext, userDetails);
spinner.setAdapter(mProfileSpinnerAdapter);
spinner.setOnItemSelectedListener(this);
setPinnedHeaderView(spinner);
}
}","@Override
public void onViewCreated(View view, Bundle savedInstanceState) {
super.onViewCreated(view, savedInstanceState);
final UserManager um = (UserManager) getActivity().getSystemService(Context.USER_SERVICE);
mProfileSpinnerAdapter = Utils.createUserSpinnerAdapter(um, mContext);
if (mProfileSpinnerAdapter != null) {
Spinner spinner = (Spinner) getActivity().getLayoutInflater().inflate(
                    R.layout.spinner_view, null);
spinner.setAdapter(mProfileSpinnerAdapter);
spinner.setOnItemSelectedListener(this);
setPinnedHeaderView(spinner);
}
}","@ Override public void onViewCreated  ( View view , Bundle savedInstanceState ) { super . onViewCreated ( view , savedInstanceState ) ; final UserManager um = ( UserManager ) getActivity ( ) . getSystemService ( Context . USER_SERVICE ) ; List < UserHandle > userProfiles = um . getUserProfiles ( ) ; if ( userProfiles . size ( ) >= 2 ) { Spinner spinner = ( Spinner ) getActivity ( ) . getLayoutInflater ( ) . inflate ( R . layout . spinner_view , null ) ; // <SATD_START> TODO: Factor out spinner creation in a method in Utils class. See: http://b/16645615 <SATD_END> UserHandle myUserHandle = new UserHandle ( UserHandle . myUserId ( ) ) ; userProfiles . remove ( myUserHandle ) ; userProfiles . add ( 0 , myUserHandle ) ; ArrayList < UserDetails > userDetails = new ArrayList < UserDetails > ( userProfiles . size ( ) ) ; final int count = userProfiles . size ( ) ; for ( int i = 0 ; i < count ; i ++ ) { userDetails . add ( new UserDetails ( userProfiles . get ( i ) , um , mContext ) ) ; } mProfileSpinnerAdapter = new UserSpinnerAdapter ( mContext , userDetails ) ; spinner . setAdapter ( mProfileSpinnerAdapter ) ; spinner . setOnItemSelectedListener ( this ) ; setPinnedHeaderView ( spinner ) ; } }","@ Override public void onViewCreated  ( View view , Bundle savedInstanceState ) { super . onViewCreated ( view , savedInstanceState ) ; final UserManager um = ( UserManager ) getActivity ( ) . getSystemService ( Context . USER_SERVICE ) ; mProfileSpinnerAdapter = Utils . createUserSpinnerAdapter ( um , mContext ) ; if ( mProfileSpinnerAdapter != null ) { Spinner spinner = ( Spinner ) getActivity ( ) . getLayoutInflater ( ) . inflate ( R . layout . spinner_view , null ) ; spinner . setAdapter ( mProfileSpinnerAdapter ) ; spinner . setOnItemSelectedListener ( this ) ; setPinnedHeaderView ( spinner ) ; } }",2014-07-29 14:08:24 +0100,2014-07-31 18:38:47 +0000,0,0.2740781507980187
1672,442,https://www.github.com/proofpoint/platform,main(String[]),NOT_DESIGN,229,229,229,229,todo - uncomment when last command moved out of Ruby,https://www.github.com/proofpoint/platform/commit/a83cd2d3f8,https://www.github.com/proofpoint/platform/commit/23476050da14c96677721d88b1c96079eb4dc31e,launcher/src/main/java/com/proofpoint/launcher/Main.java,"@Override
public final void run()
{
if (verbose) {
launcherArgs.add(""-v"");
}
if (node_properties_path == null) {
node_properties_path = install_path + ""/etc/node.properties"";
}
else {
launcherArgs.add(""--node-config"");
launcherArgs.add(new File(node_properties_path).getAbsolutePath());
}
if (jvm_config_path == null) {
jvm_config_path = install_path + ""/etc/jvm.config"";
}
else {
launcherArgs.add(""--jvm-config"");
launcherArgs.add(new File(jvm_config_path).getAbsolutePath());
}
if (config_path == null) {
config_path = install_path + ""/etc/config.properties"";
}
else {
launcherArgs.add(""--config"");
launcherArgs.add(new File(config_path).getAbsolutePath());
}
if (data_dir == null) {
data_dir = install_path;
}
else {
launcherArgs.add(""--data"");
launcherArgs.add(new File(data_dir).getAbsolutePath());
}
launcherArgs.add(""--log-levels-file"");
launcherArgs.add(new File(log_levels_path).getAbsolutePath());
try (BufferedReader nodeReader = new BufferedReader(new FileReader(node_properties_path))) {
String line;
while ((line = nodeReader.readLine()) != null) {
if (!line.matches(""\\s*#.*"")) {
String[] split = line.split(""="", 2);
system_properties.put(split[0], split[1]);
}
}
}
catch (FileNotFoundException ignore) {
}
catch (IOException e) {
throw new RuntimeException(""Error reading node properties file: "" + e);
}
for (String s : property) {
launcherArgs.add(""-D"");
launcherArgs.add(s);
String[] split = s.split(""="", 2);
String key = split[0];
if (key.equals(""config"")) {
System.out.print(""Config can not be passed in a -D argument. Use --config instead\n"");
System.exit(STATUS_INVALID_ARGS);
}
system_properties.put(key, split[1]);
}
if (system_properties.containsKey(""node.data-dir"")) {
data_dir = system_properties.get(""node.data_dir"");
}
if (pid_file_path == null) {
pid_file_path = data_dir + ""/var/run/launcher.pid"";
}
else {
launcherArgs.add(""--pid-file"");
launcherArgs.add(new File(pid_file_path).getAbsolutePath());
}
if (log_path == null) {
log_path = data_dir + ""/var/log/launcher.log"";
}
else {
launcherArgs.add(""--log-file"");
launcherArgs.add(new File(log_path).getAbsolutePath());
}
if (verbose) {
// todo - uncomment when last command moved out of Ruby
//                for (Entry<String, String> entry : system_properties.entrySet()) {
//                    System.out.print(entry.getKey() + ""="" + entry.getValue() + ""\n"");
//                }
}
execute();
}","@Override
public final void run()
{
if (verbose) {
launcherArgs.add(""-v"");
}
if (node_properties_path == null) {
node_properties_path = install_path + ""/etc/node.properties"";
}
else {
launcherArgs.add(""--node-config"");
launcherArgs.add(new File(node_properties_path).getAbsolutePath());
}
if (jvm_config_path == null) {
jvm_config_path = install_path + ""/etc/jvm.config"";
}
else {
launcherArgs.add(""--jvm-config"");
launcherArgs.add(new File(jvm_config_path).getAbsolutePath());
}
if (config_path == null) {
config_path = install_path + ""/etc/config.properties"";
}
else {
launcherArgs.add(""--config"");
launcherArgs.add(new File(config_path).getAbsolutePath());
}
if (data_dir == null) {
data_dir = install_path;
}
else {
launcherArgs.add(""--data"");
launcherArgs.add(new File(data_dir).getAbsolutePath());
}
launcherArgs.add(""--log-levels-file"");
launcherArgs.add(new File(log_levels_path).getAbsolutePath());
try (BufferedReader nodeReader = new BufferedReader(new FileReader(node_properties_path))) {
String line;
while ((line = nodeReader.readLine()) != null) {
if (!line.matches(""\\s*#.*"")) {
String[] split = line.split(""="", 2);
system_properties.put(split[0], split[1]);
}
}
}
catch (FileNotFoundException ignore) {
}
catch (IOException e) {
throw new RuntimeException(""Error reading node properties file: "" + e);
}
for (String s : property) {
launcherArgs.add(""-D"");
launcherArgs.add(s);
String[] split = s.split(""="", 2);
String key = split[0];
if (key.equals(""config"")) {
System.out.print(""Config can not be passed in a -D argument. Use --config instead\n"");
System.exit(STATUS_INVALID_ARGS);
}
system_properties.put(key, split[1]);
}
if (system_properties.containsKey(""node.data-dir"")) {
data_dir = system_properties.get(""node.data_dir"");
}
if (pid_file_path == null) {
pid_file_path = data_dir + ""/var/run/launcher.pid"";
}
else {
launcherArgs.add(""--pid-file"");
launcherArgs.add(new File(pid_file_path).getAbsolutePath());
}
if (log_path == null) {
log_path = data_dir + ""/var/log/launcher.log"";
}
else {
launcherArgs.add(""--log-file"");
launcherArgs.add(new File(log_path).getAbsolutePath());
}
if (verbose) {
for (Entry<String, String> entry : system_properties.entrySet()) {
System.out.print(entry.getKey() + ""="" + entry.getValue() + ""\n"");
}
}
execute();
}","@ Override public final void run  ( ) { if ( verbose ) { launcherArgs . add ( "" -v "" ) ; } if ( node_properties_path == null ) { node_properties_path = install_path + "" /etc/node.properties "" ; } else { launcherArgs . add ( "" --node-config "" ) ; launcherArgs . add ( new File ( node_properties_path ) . getAbsolutePath ( ) ) ; } if ( jvm_config_path == null ) { jvm_config_path = install_path + "" /etc/jvm.config "" ; } else { launcherArgs . add ( "" --jvm-config "" ) ; launcherArgs . add ( new File ( jvm_config_path ) . getAbsolutePath ( ) ) ; } if ( config_path == null ) { config_path = install_path + "" /etc/config.properties "" ; } else { launcherArgs . add ( "" --config "" ) ; launcherArgs . add ( new File ( config_path ) . getAbsolutePath ( ) ) ; } if ( data_dir == null ) { data_dir = install_path ; } else { launcherArgs . add ( "" --data "" ) ; launcherArgs . add ( new File ( data_dir ) . getAbsolutePath ( ) ) ; } launcherArgs . add ( "" --log-levels-file "" ) ; launcherArgs . add ( new File ( log_levels_path ) . getAbsolutePath ( ) ) ; try ( BufferedReader nodeReader = new BufferedReader ( new FileReader ( node_properties_path ) ) ) { String line ; while ( ( line = nodeReader . readLine ( ) ) != null ) { if ( ! line . matches ( "" \\ s*#.* "" ) ) { String [ ] split = line . split ( "" = "" , 2 ) ; system_properties . put ( split [ 0 ] , split [ 1 ] ) ; } } } catch ( FileNotFoundException ignore ) { } catch ( IOException e ) { throw new RuntimeException ( "" Error reading node properties file:  "" + e ) ; } for ( String s : property ) { launcherArgs . add ( "" -D "" ) ; launcherArgs . add ( s ) ; String [ ] split = s . split ( "" = "" , 2 ) ; String key = split [ 0 ] ; if ( key . equals ( "" config "" ) ) { System . out . print ( "" Config can not be passed in a -D argument. Use --config instead \n "" ) ; System . exit ( STATUS_INVALID_ARGS ) ; } system_properties . put ( key , split [ 1 ] ) ; } if ( system_properties . containsKey ( "" node.data-dir "" ) ) { data_dir = system_properties . get ( "" node.data_dir "" ) ; } if ( pid_file_path == null ) { pid_file_path = data_dir + "" /var/run/launcher.pid "" ; } else { launcherArgs . add ( "" --pid-file "" ) ; launcherArgs . add ( new File ( pid_file_path ) . getAbsolutePath ( ) ) ; } if ( log_path == null ) { log_path = data_dir + "" /var/log/launcher.log "" ; } else { launcherArgs . add ( "" --log-file "" ) ; launcherArgs . add ( new File ( log_path ) . getAbsolutePath ( ) ) ; } if ( verbose ) { // <SATD_START> todo - uncomment when last command moved out of Ruby <SATD_END> //                for (Entry<String, String> entry : system_properties.entrySet()) { //                    System.out.print(entry.getKey() + ""="" + entry.getValue() + ""\n""); //                } } execute ( ) ; }","@ Override public final void run  ( ) { if ( verbose ) { launcherArgs . add ( "" -v "" ) ; } if ( node_properties_path == null ) { node_properties_path = install_path + "" /etc/node.properties "" ; } else { launcherArgs . add ( "" --node-config "" ) ; launcherArgs . add ( new File ( node_properties_path ) . getAbsolutePath ( ) ) ; } if ( jvm_config_path == null ) { jvm_config_path = install_path + "" /etc/jvm.config "" ; } else { launcherArgs . add ( "" --jvm-config "" ) ; launcherArgs . add ( new File ( jvm_config_path ) . getAbsolutePath ( ) ) ; } if ( config_path == null ) { config_path = install_path + "" /etc/config.properties "" ; } else { launcherArgs . add ( "" --config "" ) ; launcherArgs . add ( new File ( config_path ) . getAbsolutePath ( ) ) ; } if ( data_dir == null ) { data_dir = install_path ; } else { launcherArgs . add ( "" --data "" ) ; launcherArgs . add ( new File ( data_dir ) . getAbsolutePath ( ) ) ; } launcherArgs . add ( "" --log-levels-file "" ) ; launcherArgs . add ( new File ( log_levels_path ) . getAbsolutePath ( ) ) ; try ( BufferedReader nodeReader = new BufferedReader ( new FileReader ( node_properties_path ) ) ) { String line ; while ( ( line = nodeReader . readLine ( ) ) != null ) { if ( ! line . matches ( "" \\ s*#.* "" ) ) { String [ ] split = line . split ( "" = "" , 2 ) ; system_properties . put ( split [ 0 ] , split [ 1 ] ) ; } } } catch ( FileNotFoundException ignore ) { } catch ( IOException e ) { throw new RuntimeException ( "" Error reading node properties file:  "" + e ) ; } for ( String s : property ) { launcherArgs . add ( "" -D "" ) ; launcherArgs . add ( s ) ; String [ ] split = s . split ( "" = "" , 2 ) ; String key = split [ 0 ] ; if ( key . equals ( "" config "" ) ) { System . out . print ( "" Config can not be passed in a -D argument. Use --config instead \n "" ) ; System . exit ( STATUS_INVALID_ARGS ) ; } system_properties . put ( key , split [ 1 ] ) ; } if ( system_properties . containsKey ( "" node.data-dir "" ) ) { data_dir = system_properties . get ( "" node.data_dir "" ) ; } if ( pid_file_path == null ) { pid_file_path = data_dir + "" /var/run/launcher.pid "" ; } else { launcherArgs . add ( "" --pid-file "" ) ; launcherArgs . add ( new File ( pid_file_path ) . getAbsolutePath ( ) ) ; } if ( log_path == null ) { log_path = data_dir + "" /var/log/launcher.log "" ; } else { launcherArgs . add ( "" --log-file "" ) ; launcherArgs . add ( new File ( log_path ) . getAbsolutePath ( ) ) ; } if ( verbose ) { for ( Entry < String , String > entry : system_properties . entrySet ( ) ) { System . out . print ( entry . getKey ( ) + "" = "" + entry . getValue ( ) + "" \n "" ) ; } } execute ( ) ; }",2013/4/12 15:33,2013/4/12 15:33,0,0.9438870308435526
3660,116,https://www.github.com/jpmoresmau/eclipsefp,getFile(ITextViewer),DESIGN,50,50,45,45,TODO what to do when there isn't a file editor opened?,https://www.github.com/jpmoresmau/eclipsefp/commit/320be9943,https://www.github.com/jpmoresmau/eclipsefp/commit/2e1df175e24a9f9141f14e2b9d1f005c3a3cd6bf,net.sf.eclipsefp.haskell.ui/src/net/sf/eclipsefp/haskell/ui/internal/editors/haskell/codeassist/WorkbenchHaskellCompletionContext.java,"private static IFile getFile(final ITextViewer viewer) {
IDocument currentDocument = viewer.getDocument();
IWorkbenchWindow window = PlatformUI.getWorkbench().getActiveWorkbenchWindow();
IEditorReference editorReferences[] = window.getActivePage().getEditorReferences();
IEditorInput input = null;
for (int i = 0; i < editorReferences.length; i++) {
IEditorPart editor = editorReferences[i].getEditor(false);
if (editor instanceof ITextEditor) {
ITextEditor textEditor = (ITextEditor) editor;
IDocument doc = textEditor.getDocumentProvider().getDocument(textEditor.getEditorInput());
if (currentDocument.equals(doc)) {
input = textEditor.getEditorInput();
break;
}
}
}
if (input instanceof IFileEditorInput) {
IFileEditorInput fileInput = (IFileEditorInput) input;
return fileInput.getFile();
}
//TODO what to do when there isn't a file editor opened?
return null;
}","private static IFile getFile(final ITextViewer viewer) {
IDocument currentDocument = viewer.getDocument();
IWorkbenchWindow window = PlatformUI.getWorkbench().getActiveWorkbenchWindow();
IEditorReference editorReferences[] = window.getActivePage().getEditorReferences();
IEditorInput input = null;
for (int i = 0; i < editorReferences.length; i++) {
IEditorPart editor = editorReferences[i].getEditor(false);
if (editor instanceof ITextEditor) {
ITextEditor textEditor = (ITextEditor) editor;
IDocument doc = textEditor.getDocumentProvider().getDocument(textEditor.getEditorInput());
if (currentDocument.equals(doc)) {
input = textEditor.getEditorInput();
if (input instanceof IFileEditorInput) {
IFileEditorInput fileInput = (IFileEditorInput) input;
return fileInput.getFile();
}
}
}
}
// Return a null IFile, which is handled in HaskellCompletionContext.
return null;
}",private static IFile getFile  ( final ITextViewer viewer ) { IDocument currentDocument = viewer . getDocument ( ) ; IWorkbenchWindow window = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) ; IEditorReference editorReferences [ ] = window . getActivePage ( ) . getEditorReferences ( ) ; IEditorInput input = null ; for ( int i = 0 ; i < editorReferences . length ; i ++ ) { IEditorPart editor = editorReferences [ i ] . getEditor ( false ) ; if ( editor instanceof ITextEditor ) { ITextEditor textEditor = ( ITextEditor ) editor ; IDocument doc = textEditor . getDocumentProvider ( ) . getDocument ( textEditor . getEditorInput ( ) ) ; if ( currentDocument . equals ( doc ) ) { input = textEditor . getEditorInput ( ) ; break ; } } } if ( input instanceof IFileEditorInput ) { IFileEditorInput fileInput = ( IFileEditorInput ) input ; return fileInput . getFile ( ) ; } //<SATD_START> TODO what to do when there isn't a file editor opened? <SATD_END> return null ; },"private static IFile getFile  ( final ITextViewer viewer ) { IDocument currentDocument = viewer . getDocument ( ) ; IWorkbenchWindow window = PlatformUI . getWorkbench ( ) . getActiveWorkbenchWindow ( ) ; IEditorReference editorReferences [ ] = window . getActivePage ( ) . getEditorReferences ( ) ; IEditorInput input = null ; for ( int i = 0 ; i < editorReferences . length ; i ++ ) { IEditorPart editor = editorReferences [ i ] . getEditor ( false ) ; if ( editor instanceof ITextEditor ) { ITextEditor textEditor = ( ITextEditor ) editor ; IDocument doc = textEditor . getDocumentProvider ( ) . getDocument ( textEditor . getEditorInput ( ) ) ; if ( currentDocument . equals ( doc ) ) { input = textEditor . getEditorInput ( ) ; if ( input instanceof IFileEditorInput ) { IFileEditorInput fileInput = ( IFileEditorInput ) input ; return fileInput . getFile ( ) ; } } } } // Return a null IFile, which is handled in HaskellCompletionContext. return null ; }",2007-09-15 22:47:47 +0200,2010/8/16 12:37,0,0.7921609076843734
1903,423,https://www.github.com/operasoftware/operaprestodriver,testStart(),,16,16,16,16,TODO make work everywhere,https://www.github.com/operasoftware/operaprestodriver/commit/c22d3cc18,https://www.github.com/operasoftware/operaprestodriver/commit/4790b66bf515016a1db75a13118d6728d05a71f2,test/com/opera/core/systems/OperaPathsTest.java,"@Test
public void testStart() throws Exception {
OperaDriverSettings settings = new OperaDriverSettings();
settings.setRunOperaLauncherFromOperaDriver(true);
// TODO make work everywhere
settings.setOperaBinaryLocation(""/usr/bin/opera"");
settings.setOperaLauncherBinary(""/home/stuart/bin/opera-launcher"");
// FIXME -nosession doesn't work on Windows
settings.setOperaBinaryArguments(""opera:debug"");
OperaDriver driver = new OperaDriver(settings);
driver.get(""http://example.com/"");
assertEquals(""http://example.com/"", driver.getCurrentUrl());
driver.shutdown();
}","@Test
public void testStart() throws Exception {
OperaDriver driver = new OperaDriver();
driver.get(""http://t/core/README"");
assertEquals(""http://t/core/README"", driver.getCurrentUrl());
driver.shutdown();
}","@ Test public void testStart  ( ) throws Exception  { OperaDriverSettings settings = new OperaDriverSettings ( ) ; settings . setRunOperaLauncherFromOperaDriver ( true ) ; // <SATD_START> TODO make work everywhere <SATD_END> settings . setOperaBinaryLocation ( "" /usr/bin/opera "" ) ; settings . setOperaLauncherBinary ( "" /home/stuart/bin/opera-launcher "" ) ; // FIXME -nosession doesn't work on Windows settings . setOperaBinaryArguments ( "" opera:debug "" ) ; OperaDriver driver = new OperaDriver ( settings ) ; driver . get ( "" http://example.com/ "" ) ; assertEquals ( "" http://example.com/ "" , driver . getCurrentUrl ( ) ) ; driver . shutdown ( ) ; }","@ Test public void testStart  ( ) throws Exception  { OperaDriver driver = new OperaDriver ( ) ; driver . get ( "" http://t/core/README "" ) ; assertEquals ( "" http://t/core/README "" , driver . getCurrentUrl ( ) ) ; driver . shutdown ( ) ; }",2011-02-02 10:34:32 +0100,2011-02-02 11:27:54 +0100,0,0.1726457399103139
1225,38,https://www.github.com/freenet/fred,generateIdentityFromPubkey(),,2784,2784,2784,2784,FIXME: We should not update VERIFIED unless we HANDSHAKE WITH THE NODE,https://www.github.com/freenet/fred/commit/0be0b16f93f,https://www.github.com/freenet/fred/commit/57e7601659ba71cbe97ae55593c6044abf3e91ad,src/freenet/node/PeerNode.java,"synchronized void updateShouldDisconnectNow() {
//FIXME: We should not update VERIFIED unless we HANDSHAKE WITH THE NODE
if (isConnected() || verifiedIncompatibleOlderVersion || verifiedIncompatibleNewerVersion) {
verifiedIncompatibleOlderVersion = forwardInvalidVersion();
verifiedIncompatibleNewerVersion = reverseInvalidVersion();
}
}","synchronized void updateShouldDisconnectNow() {
verifiedIncompatibleOlderVersion = forwardInvalidVersion();
verifiedIncompatibleNewerVersion = reverseInvalidVersion();
}",synchronized void updateShouldDisconnectNow  ( ) { //<SATD_START> FIXME: We should not update VERIFIED unless we HANDSHAKE WITH THE NODE <SATD_END> if ( isConnected ( ) || verifiedIncompatibleOlderVersion || verifiedIncompatibleNewerVersion ) { verifiedIncompatibleOlderVersion = forwardInvalidVersion ( ) ; verifiedIncompatibleNewerVersion = reverseInvalidVersion ( ) ; } },synchronized void updateShouldDisconnectNow  ( ) { verifiedIncompatibleOlderVersion = forwardInvalidVersion ( ) ; verifiedIncompatibleNewerVersion = reverseInvalidVersion ( ) ; },2007-12-29 01:41:06 +0000,2008-01-03 18:06:15 +0000,0,0.644927536231884
