{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# urgent satd characterization process",
   "id": "8670047ff945d265"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.随机从 output_file_gai.csv 文件中，分别抽取 50 条 surive_time=0 和 surive_time=1 的数据，且保证 function_before_tokenized 和 function_after_tokenized 字段不为空。",
   "id": "ccc2755c30330972"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:03:57.559775Z",
     "start_time": "2024-10-10T10:03:56.443939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 读取CSV文件\n",
    "output_df = pd.read_csv('output_file_gai.csv')\n",
    "\n",
    "# 过滤掉 `function_before_tokenized` 和 `function_after_tokenized` 为空的行\n",
    "filtered_df = output_df[(output_df['function_before_tokenized'].notna()) & (output_df['function_after_tokenized'].notna())]\n",
    "\n",
    "# 分别提取 `surive_time=0` 和 `surive_time=1` 的数据\n",
    "surive_time_0 = filtered_df[filtered_df['survive_time'] == 0]\n",
    "surive_time_1 = filtered_df[filtered_df['survive_time'] >= 1]\n",
    "\n",
    "# 随机抽取50条数据\n",
    "sample_0 = surive_time_0.sample(n=50, random_state=42)  # random_state 是为了保证可重复性\n",
    "sample_1 = surive_time_1.sample(n=50, random_state=42)\n",
    "\n",
    "# 保存抽取的数据到文件（可选）\n",
    "sample_0.to_csv('sample_0.csv', index=False)\n",
    "sample_1.to_csv('sample_1.csv', index=False)\n",
    "\n",
    "print(\"Sample extraction complete.\")"
   ],
   "id": "1e4ca70de0c2b26f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample extraction complete.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.提取特征\n",
    "<img src=\"特征维度.png\" width=1200>\n",
    "\n",
    "- Churn Workload：改动的代码量，根据token化之后比较function_before and function_after的相似度，然后显著性检验 \n",
    "- Commit Goal: SATD注释是否清晰，目标明确\n",
    "- Working on release: 离上一次发布的版本的时间\n",
    "- Project Startup: 离项目刚开始的时间\n",
    "- Commit workload: 提交次数，代表开发人员做出的不同贡献的数量\n",
    "- Tenure：作者关于这个项目的经验"
   ],
   "id": "331378f779aee127"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Churn Workload",
   "id": "12a78841e32e173c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 读取CSV文件：从 sample_0.csv 和 sample_1.csv 文件中读取数据。\n",
    "- 相似度计算函数：使用 difflib.SequenceMatcher 函数来计算两个字符串的相似度。该函数返回值介于 0 到 1 之间，1 表示完全相同，0 表示完全不同。\n",
    "- 应用相似度计算：使用 apply() 方法逐行应用相似度计算，并将结果存储到新的 similarity 列中。\n",
    "- 保存结果：将包含相似度的结果保存到新的 CSV 文件中（sample_0_with_similarity.csv 和 sample_1_with_similarity.csv）。"
   ],
   "id": "9b3014408375d845"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:05:29.735911Z",
     "start_time": "2024-10-10T10:05:29.395065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "# 读取CSV文件\n",
    "sample_0 = pd.read_csv('sample_0.csv')\n",
    "sample_1 = pd.read_csv('sample_1.csv')\n",
    "\n",
    "# 定义计算相似度的函数\n",
    "def calculate_similarity(str1, str2):\n",
    "    return difflib.SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "# 计算 sample_0 的相似度\n",
    "sample_0['similarity'] = sample_0.apply(lambda row: calculate_similarity(row['function_before_tokenized'], row['function_after_tokenized']), axis=1)\n",
    "\n",
    "# 计算 sample_1 的相似度\n",
    "sample_1['similarity'] = sample_1.apply(lambda row: calculate_similarity(row['function_before_tokenized'], row['function_after_tokenized']), axis=1)\n",
    "\n",
    "# 保存结果到新文件\n",
    "sample_0.to_csv('sample_0_with_similarity.csv', index=False)\n",
    "sample_1.to_csv('sample_1_with_similarity.csv', index=False)\n",
    "\n",
    "print(\"Similarity calculation complete.\")"
   ],
   "id": "84d49ef516ab6da1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity calculation complete.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 读取 CSV 文件：使用 pandas 库读取 sample_0.csv 和 sample_1.csv 文件。\n",
    "- 获取相似度数据：假设你已经计算了相似度，并将相似度存储在 similarity 列中。我们通过 dropna() 方法确保没有缺失值。\n",
    "- t 检验：使用 scipy.stats.ttest_ind() 函数对 survive_time=0 和 survive_time=1 的相似度数据进行独立样本 t 检验。\n",
    "- 显著性检验：根据 p 值判断是否有显著性差异，通常使用的显著性水平为 0.05。"
   ],
   "id": "5bb7c53ae2942a34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:05:47.109481Z",
     "start_time": "2024-10-10T10:05:46.378729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy import stats\n",
    "\n",
    "# 读取 CSV 文件\n",
    "sample_0 = pd.read_csv('sample_0_with_similarity.csv')\n",
    "sample_1 = pd.read_csv('sample_1_with_similarity.csv')\n",
    "\n",
    "# 假设相似度数据存储在 \"similarity\" 列\n",
    "survive_time_0 = sample_0['similarity'].dropna()  # 确保数据中没有缺失值\n",
    "survive_time_1 = sample_1['similarity'].dropna()\n",
    "\n",
    "# 进行独立样本 t 检验\n",
    "t_statistic, p_value = stats.ttest_ind(survive_time_0, survive_time_1)\n",
    "\n",
    "# 输出结果\n",
    "print(f'T-statistic: {t_statistic}')\n",
    "print(f'P-value: {p_value}')\n",
    "\n",
    "# 检查显著性水平 (通常使用 alpha = 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"两个数据集之间存在显著差异。\")\n",
    "else:\n",
    "    print(\"两个数据集之间不存在显著差异。\")"
   ],
   "id": "6dbabb95dfca14aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -2.1048953643854884\n",
      "P-value: 0.03785823687703119\n",
      "两个数据集之间存在显著差异。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 结果：\n",
    "> T-statistic: -2.1048953643854884\n",
    "> P-value: 0.03785823687703119\n",
    "> 两个数据集之间存在显著差异。"
   ],
   "id": "809c96ebb4ccc3d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "计算平均值和中位数",
   "id": "5a53b17a9c667214"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:06:43.961785Z",
     "start_time": "2024-10-10T10:06:43.916250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "sample_0 = pd.read_csv('sample_0_with_similarity.csv')\n",
    "sample_1 = pd.read_csv('sample_1_with_similarity.csv')\n",
    "\n",
    "# 假设相似度数据存储在 \"similarity\" 列\n",
    "survive_time_0 = sample_0['similarity'].dropna()  # 确保没有缺失值\n",
    "survive_time_1 = sample_1['similarity'].dropna()\n",
    "\n",
    "# 计算平均值和中位数\n",
    "mean_0 = survive_time_0.mean()\n",
    "median_0 = survive_time_0.median()\n",
    "\n",
    "mean_1 = survive_time_1.mean()\n",
    "median_1 = survive_time_1.median()\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Survive_time=0 的平均值: {mean_0}\")\n",
    "print(f\"Survive_time=0 的中位数: {median_0}\")\n",
    "\n",
    "print(f\"Survive_time=1 的平均值: {mean_1}\")\n",
    "print(f\"Survive_time=1 的中位数: {median_1}\")"
   ],
   "id": "83daa72eb13ec549",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survive_time=0 的平均值: 0.6833865717347414\n",
      "Survive_time=0 的中位数: 0.7542094756904894\n",
      "Survive_time=1 的平均值: 0.7800271740024162\n",
      "Survive_time=1 的中位数: 0.868339775028901\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Commit Goal",
   "id": "eeecafa110e424d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 计算单词数量：使用 apply(lambda x: len(str(x).split())) 计算每条 comment 的单词数量。\n",
    "- 保存结果：将包含单词数量的结果保存到新的 CSV 文件中，分别为 sample_0_with_word_count.csv 和 sample_1_with_word_count.csv（这一步是可选的）。\n",
    "- 统计单词数量：对两个数据集中的单词数量分别计算平均值和中位数。\n",
    "- 显著性检验：通过 t 检验分析两个数据集中 comment_word_count 是否存在显著差异。"
   ],
   "id": "c534dbf0050f14a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:07:20.957319Z",
     "start_time": "2024-10-10T10:07:20.800931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# 读取 CSV 文件\n",
    "sample_0 = pd.read_csv('sample_0.csv')\n",
    "sample_1 = pd.read_csv('sample_1.csv')\n",
    "\n",
    "# 假设 comment 数据存储在 \"comment\" 列，计算单词数量\n",
    "sample_0['comment_word_count'] = sample_0['comment'].apply(lambda x: len(str(x).split()))\n",
    "sample_1['comment_word_count'] = sample_1['comment'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# 保存带有 comment_word_count 列的新文件（可选）\n",
    "sample_0.to_csv('sample_0_with_word_count.csv', index=False)\n",
    "sample_1.to_csv('sample_1_with_word_count.csv', index=False)\n",
    "\n",
    "# 提取 comment_word_count 列\n",
    "comment_word_count_0 = sample_0['comment_word_count'].dropna()  # 确保没有缺失值\n",
    "comment_word_count_1 = sample_1['comment_word_count'].dropna()\n",
    "\n",
    "# 计算平均值和中位数\n",
    "mean_word_count_0 = comment_word_count_0.mean()\n",
    "median_word_count_0 = comment_word_count_0.median()\n",
    "\n",
    "mean_word_count_1 = comment_word_count_1.mean()\n",
    "median_word_count_1 = comment_word_count_1.median()\n",
    "\n",
    "# 输出平均值和中位数\n",
    "print(f\"Survive_time=0 的评论平均单词数: {mean_word_count_0}\")\n",
    "print(f\"Survive_time=0 的评论中位数单词数: {median_word_count_0}\")\n",
    "\n",
    "print(f\"Survive_time=1 的评论平均单词数: {mean_word_count_1}\")\n",
    "print(f\"Survive_time=1 的评论中位数单词数: {median_word_count_1}\")\n",
    "\n",
    "# 进行独立样本 t 检验\n",
    "t_statistic, p_value = stats.ttest_ind(comment_word_count_0, comment_word_count_1)\n",
    "\n",
    "# 输出 t 检验结果\n",
    "print(f'T-statistic: {t_statistic}')\n",
    "print(f'P-value: {p_value}')\n",
    "\n",
    "# 检查显著性水平 (通常使用 alpha = 0.05)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"两个数据集之间存在显著差异。\")\n",
    "else:\n",
    "    print(\"两个数据集之间不存在显著差异。\")"
   ],
   "id": "d4009ceb7989edb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survive_time=0 的评论平均单词数: 8.06\n",
      "Survive_time=0 的评论中位数单词数: 7.0\n",
      "Survive_time=1 的评论平均单词数: 8.06\n",
      "Survive_time=1 的评论中位数单词数: 7.0\n",
      "T-statistic: 0.0\n",
      "P-value: 1.0\n",
      "两个数据集之间不存在显著差异。\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 使用LLM，星火认知大模型，`isClear()` 判别SATD的目标是否明确",
   "id": "ab9acfdcdb6faa1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sparkai.llm.llm import ChatSparkLLM, ChunkPrintHandler\n",
    "from sparkai.core.messages import ChatMessage\n",
    "import time\n",
    "\n",
    "\n",
    "def isClear(comment):\n",
    "    #星火认知大模型Spark Max的URL值，其他版本大模型URL值请前往文档（https://www.xfyun.cn/doc/spark/Web.html）查看\n",
    "    SPARKAI_URL = 'wss://spark-api.xf-yun.com/v1.1/chat'\n",
    "    #星火认知大模型调用秘钥信息，请前往讯飞开放平台控制台（https://console.xfyun.cn/services/bm35）查看\n",
    "    SPARKAI_APP_ID = 'c3ad6fa7'\n",
    "    SPARKAI_API_SECRET = 'MmFhNmY4ZDZiZDEwMjkzYmUxZDc5NTlh'\n",
    "    SPARKAI_API_KEY = '3da9a6c9584eb9db8959b4e651ff1322'\n",
    "    #星火认知大模型Spark Max的domain值，其他版本大模型domain值请前往文档（https://www.xfyun.cn/doc/spark/Web.html）查看\n",
    "    SPARKAI_DOMAIN = 'general'\n",
    "    spark = ChatSparkLLM(\n",
    "        spark_api_url=SPARKAI_URL,\n",
    "        spark_app_id=SPARKAI_APP_ID,\n",
    "        spark_api_key=SPARKAI_API_KEY,\n",
    "        spark_api_secret=SPARKAI_API_SECRET,\n",
    "        spark_llm_domain=SPARKAI_DOMAIN,\n",
    "        streaming=False,\n",
    "    )\n",
    "    \"\"\"\n",
    "        判断SATD注释是否清晰，目标明确。\n",
    "        \n",
    "        Args:\n",
    "        comment: SATD注释字符串。\n",
    "        \n",
    "        Returns:\n",
    "        True or False。\n",
    "    \"\"\"\n",
    "    messages = [ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=f'你是一个程序员，你认为注释{comment}的目的含义是否清晰, 你只需要回答Yes or No'\n",
    "    )]\n",
    "    handler = ChunkPrintHandler()\n",
    "    # time.sleep(1)  # 休眠\n",
    "    answer = spark.generate([messages], callbacks=[handler]).generations[0][0].text\n",
    "    return len(answer) >= 10 or answer == \"Yes\""
   ],
   "id": "1ca9a165719fdc40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "分别对sample.csv文件进行判定",
   "id": "3ea6bf866490f4e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 读取csv文件\n",
    "df_0 = pd.read_csv('sample_0.csv')  # 将'sample_0.csv'替换为你的文件名\n",
    "df_1 = pd.read_csv('sample_1.csv')  # 将'sample_1.csv'替换为你的文件名\n",
    "\n",
    "# 对comment列进行判定\n",
    "df_0['isClear'] = df_0['comment'].apply(isClear)\n",
    "df_1['isClear'] = df_1['comment'].apply(isClear)\n",
    "\n",
    "# 打印结果\n",
    "print(\"sample_0.csv:\")\n",
    "print(df_0[['comment', 'isClear']])\n",
    "\n",
    "print(\"\\nsample_1.csv:\")\n",
    "print(df_1[['comment', 'isClear']])\n",
    "\n",
    "# 保存结果\n",
    "df_0.to_csv('sample_0.csv', index=False)\n",
    "df_1.to_csv('sample_1.csv', index=False)"
   ],
   "id": "1146abfa6e41c2fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "对 sample_0.csv 和 sample_1.csv 中的 isClear 列进行显著性统计\n",
    "\n",
    "看看 survive_time 为 0 和 1 的两组样本，它们的技术债务注释清晰度的比例是否有显著差异。\n",
    "\n",
    "由于 isClear 是一个二元变量（True 或 False），我们可以使用 **卡方检验** 来进行显著性统计。"
   ],
   "id": "e34b403833f8b029"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# 读取csv文件\n",
    "df_0 = pd.read_csv('sample_0.csv')  # 将'sample_0_with_isClear.csv'替换为你的文件名\n",
    "df_1 = pd.read_csv('sample_1.csv')  # 将'sample_1_with_isClear.csv'替换为你的文件名\n",
    "\n",
    "# 统计 isClear 的数量\n",
    "count_0 = df_0['isClear'].value_counts()\n",
    "count_1 = df_1['isClear'].value_counts()\n",
    "\n",
    "# 构建列联表\n",
    "contingency_table = pd.DataFrame({\n",
    "    'survive_time_0': count_0,\n",
    "    'survive_time_1': count_1\n",
    "}).fillna(0)  # 用0填充缺失值\n",
    "\n",
    "# 进行卡方检验\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# 打印结果\n",
    "print('卡方检验结果:')\n",
    "print(f'卡方值: {chi2}')\n",
    "print(f'p值: {p_value}')\n",
    "print(f'自由度: {dof}')\n",
    "print('期望频数:\\n', expected)\n",
    "\n",
    "# 解释p值\n",
    "alpha = 0.05  # 设置显著性水平\n",
    "if p_value < alpha:\n",
    "    print('拒绝原假设，两组样本的 isClear 比例存在显著差异。')\n",
    "else:\n",
    "    print('无法拒绝原假设，两组样本的 isClear 比例不存在显著差异。')"
   ],
   "id": "99dfead419bf675f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
